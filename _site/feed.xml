<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>FuzzyBlog</title>
    <description>Scott Johnson writing about the usual array of nerd stuff.  Ruby / Rails / Elixir.
</description>
    <link>https://fuzzygroup.github.io/blog/</link>
    <atom:link href="https://fuzzygroup.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 16 Oct 2016 09:33:48 -0400</pubDate>
    <lastBuildDate>Sun, 16 Oct 2016 09:33:48 -0400</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>Understanding Systems By Observation - Dropbox</title>
        <description>&lt;p&gt;One of the best bits of computer science I ever learned, I learned in 1989 from my first business partner, Brian Giedt.  We were at a Society for Technical Communications (stc) conference on Technical Documentation and my partner was trying to impress a pretty girl.  And I watch him look at an animation product and pretty much instantly &lt;strong&gt;grok&lt;/strong&gt; how it was doing the animation.  Where I saw a pretty flow of images, he looked at it and understood how the animation was being done.  That was the very first time I saw someone really understand something about the &lt;em&gt;internals&lt;/em&gt; from its &lt;em&gt;externals&lt;/em&gt;.  And once I knew it was possible – I’ve striven to do it as often as I can.  Very often, if you set up the right set of circumstances, you’ll realize exactly how something has to be implemented internally.&lt;/p&gt;

&lt;p&gt;Let’s use Dropbox as an example.  We all know that Dropbox transfers the content you put in it to all other machines you have hooked up to it.  And that’s a simple 1 to many transfer.  But how does Dropbox work when you already have content in it and you re-arrange it?  Does it resend everything or does it figure out what it has to do and send a command stream to do it instead?&lt;/p&gt;

&lt;p&gt;A few minutes ago I:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;created a folder within a folder in Dropbox&lt;/li&gt;
  &lt;li&gt;moved about 15 gb of video files in initial folder to the new folder&lt;/li&gt;
  &lt;li&gt;checked on my iPad about a minute later&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And all the files I moved were in the new folder already.  Here’s what this tells me&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;There’s no way that Dropbox deleted and re-transmitted the files in that time; it is simply impossible&lt;/li&gt;
  &lt;li&gt;What Dropbox has to be doing is sending commands that amount to move THIS from HERE to THERE&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The best I’ve seen to do this is you set up conditions that you know can’t be argued with by physical constraints.  I knew that 15 gb of video data was a big arse chunk of data.  If I had used say a megabyte, well, I wouldn’t have really known if it was a full bandwidth re-arrange or a command stream.  By setting up such a large test, well, I knew something smarter had to be going on.&lt;/p&gt;
</description>
        <pubDate>Sun, 16 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/software_engineering/2016/10/16/understanding-systems-by-observation-dropbox.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/software_engineering/2016/10/16/understanding-systems-by-observation-dropbox.html</guid>
        
        <category>software_engineering</category>
        
        
        <category>software_engineering</category>
        
      </item>
    
      <item>
        <title>AWS Tutorial 19 - Back to the Basics, Let's Talk AMIs and EC2 basics</title>
        <description>&lt;p&gt;I just used Hyde to examine my blog and I realized that I have written almost 20,000 words on AWS since 8/23/16 (note some of that is still unfinished and in draft form).  Using my standard writer metric of 250 words per page, that’s 78 printed pages.  Wow.  And, alas, I realize that there are still things I haven’t written about.  And some of them are the sort of basic things that you either just ignore or that you accept by rote - “I know, we’ll use Ubuntu, we love Ubuntu!”.  And, yes, that would be me.  So let’s take a deeper dive here at some of the basic options when you build an EC2 instance.&lt;/p&gt;

&lt;h1 id=&quot;what-is-an-ec2-instance&quot;&gt;What is an EC2 Instance?&lt;/h1&gt;

&lt;p&gt;An EC2 instance is just a server in Amazon’s cloud.  And, from what I can tell, pretty much everything AWS offers comes down to a server somehow.  When you build an EC2 instance you have to base it on an operating system which is called an AMI and there are a bunch of options that define what AMI you want to pick:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Quick Start - the most popular options&lt;/li&gt;
  &lt;li&gt;My AMIs - these are amis that you have saved from a machine you already built&lt;/li&gt;
  &lt;li&gt;AWS Marketplace - these are commercial offerings from vendors&lt;/li&gt;
  &lt;li&gt;Community AMIs - these are generally open source AMIs and the number is enormous – more than 50,000 when I checked&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here’s a picture of the initial EC2 instance selection web page:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/aws/aws_ami_ec2.png&quot; alt=&quot;aws_ami_ec2.png.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are a few basic options that you really want to keep in mind:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Linux Distro&lt;/strong&gt;.  This is important but can’t be written in a bullet point so it is discussed below.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;32 / 64 bit&lt;/strong&gt;.  There’s no real reason to not go 64 bit.  And if you have a reason then you should be writing this not reading it.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Virtualization Type&lt;/strong&gt;.  This should always be HVM as PVM is being phased out.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Root Device Type&lt;/strong&gt;.  This should pretty much always be set to EBS.  EBS allows you to turn off the volume without losing the data on the instance and thus allows you to resize your instance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;the-linux-distro-question&quot;&gt;The Linux Distro Question&lt;/h1&gt;

&lt;p&gt;Asking anyone in the Open Source world what is the best Linux flavor or “distro” (that’s short for distribution) is a bit like asking someone their favorite color – the answer is always different and always subjective.  And while there are differences, in the end, it is all Linux and if you can use one Linux then you can use a different Linux.  I know there are serious Linux folk that read this line and are gnashing their teeth and I apologize.&lt;/p&gt;

&lt;p&gt;Personally I’ve used at different times:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Red Hat&lt;/li&gt;
  &lt;li&gt;Gentoo (I even had a whole data center of more than 100 Gentoo boxes)&lt;/li&gt;
  &lt;li&gt;Ubuntu 12&lt;/li&gt;
  &lt;li&gt;Ubuntu 14&lt;/li&gt;
  &lt;li&gt;Mandriva&lt;/li&gt;
  &lt;li&gt;Suse&lt;/li&gt;
  &lt;li&gt;Debian&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And I’m pretty sure there were some others; that’s just want I can remember using.  The short answer is you want to pick a Linux distribution that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;matches what you want to do&lt;/li&gt;
  &lt;li&gt;is well supported&lt;/li&gt;
  &lt;li&gt;is something you understand&lt;/li&gt;
  &lt;li&gt;has a package manager that you can deal with&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;the-amazon-linux-distribution&quot;&gt;The Amazon Linux Distribution&lt;/h1&gt;

&lt;p&gt;Interestingly Amazon has their own Linux distribution.  I don’t have a ton of experience with it yet but I’m keenly interested in it and I really like their focus on performance.&lt;/p&gt;

&lt;p&gt;Pros:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Good support for Docker&lt;/li&gt;
  &lt;li&gt;Good support for at least somewhat modern development tools; Ruby, PHP and Python all installed right from the start&lt;/li&gt;
  &lt;li&gt;Good package support for the basics - mysql, postgres, etc&lt;/li&gt;
  &lt;li&gt;AWS command line tools installed standard&lt;/li&gt;
  &lt;li&gt;Good support for the AWS ECS&lt;/li&gt;
  &lt;li&gt;Cool text mode EC2 login logo that makes me smile whenever I see it&lt;/li&gt;
  &lt;li&gt;They seem to really care about performance.  The 2016.09 release notes specifically call out the &lt;a href=&quot;https://aws.amazon.com/amazon-linux-ami/2016.09-release-notes/&quot;&gt;7 seconds of boot time&lt;/a&gt; that they cut out.  Sounds silly but its a big deal when you have a lot of machines.  And given that they write the billing rules, they could easily use that 7 seconds in their favor.  The fact that they don’t gives me an incredible amount of confidence in AWS’s billing practices.  Go AWS!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cons:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It can’t run anywhere but Amazon.&lt;/li&gt;
  &lt;li&gt;It can’t run on Vagrant for local development&lt;/li&gt;
  &lt;li&gt;Yum / RPM as package managers; this is a personal choice but I vastly prefer apt-get&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;how-important-is-this-with-automated-provisioning&quot;&gt;How Important Is this With Automated Provisioning?&lt;/h1&gt;

&lt;p&gt;In the days where you configured Linux manually, picking the right distribution was actually quite important.  Thanks to automated provisioning tools like Ansible, I’m not so sure now.  I’ve already used Ansible to move from one version of Linux to another and its just not that hard.  If you write your Ansible playbook properly and abstract things like the username into variables, you can modify it pretty easily to go between distros.&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In the end you likely want to pick:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A well supported Linux distro.  I’d recommend either Ubuntu, RedHat or the Amazon Linux AMI&lt;/li&gt;
  &lt;li&gt;64 Bit&lt;/li&gt;
  &lt;li&gt;HVM Virtualization&lt;/li&gt;
  &lt;li&gt;EBS Root Device&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sun, 16 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/aws/2016/10/16/aws-tutorial-19-back-to-the-basics-let-s-talk-amis.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/aws/2016/10/16/aws-tutorial-19-back-to-the-basics-let-s-talk-amis.html</guid>
        
        <category>aws</category>
        
        <category>ami</category>
        
        <category>linux</category>
        
        <category>ec2</category>
        
        
        <category>aws</category>
        
      </item>
    
      <item>
        <title>AWS Tutorial 18 - When You've Lost You Web Server, How to Find an AWS Resource</title>
        <description>&lt;p&gt;I find myself, at the time of this writing, in the middle of an embarrassing situtation for a web professional.  You see, the situation is this:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;I wrote a new feature&lt;/li&gt;
  &lt;li&gt;I deployed my new feature&lt;/li&gt;
  &lt;li&gt;I refreshed my page&lt;/li&gt;
  &lt;li&gt;My feature isn’t there&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Great Googly Moogly!  I’ve lost my web server!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Let me explain one of the things about cloud hosting that’s disconcerting.  When you first move to the cloud, your impulse is to organize your computing resources the way you used to.  So if you used to have say 3 clusters of powerful machines, that’s what you do.  Then you realize just how mind blowingly powerful a platform like AWS actually is and you start to think about &lt;strong&gt;Single Purpose Servers&lt;/strong&gt;.  A single purpose server is just what it sounds like – it does one thing.  And that’s fantastic because it makes trouble shooting so much easier.  When a server does only one thing, well, its easy to know if its broken.  And that’s great but do you know what the side effect of that is?  You don’t have a handful of servers anymore, you have a lot.  Me?  I’ve got over &lt;strong&gt;20&lt;/strong&gt; right now.  And somewhere in there is my web server.  But I can’t find it.  In this tutorial we’re going to quickly and easily figure this out.&lt;/p&gt;

&lt;h1 id=&quot;start-with-a-hypothesis&quot;&gt;Start with a Hypothesis&lt;/h1&gt;

&lt;p&gt;As normal we’re going to start with a theory - that is one of these three boxes:  fimariadb, ficrawler1, ficrawler2.  So our diagnostic dance, crude tho it may be, is:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;ssh into one of the boxes&lt;/li&gt;
  &lt;li&gt;sudo su -&lt;/li&gt;
  &lt;li&gt;apache2ctl stop&lt;/li&gt;
  &lt;li&gt;reload the page&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If the page comes up, well, we know it wasn’t that one box.  So you then lather, rinse, repeat for each of the other 2 boxes.  And, at the end, we’re going to find out that it was none of these.&lt;/p&gt;

&lt;p&gt;You might be saying “Hey wait a minute – why would a web front end be on a box that does crawling?”  Well I’m still feeling all this out and I initially went for the old model where every box could do everything.  And that was a bad decision but I still have to live it for at least a little while longer.&lt;/p&gt;

&lt;h1 id=&quot;formulate-a-new-hypothesis---lets-use-ping&quot;&gt;Formulate a New Hypothesis - Let’s Use Ping!&lt;/h1&gt;

&lt;p&gt;Since our first plan failed, we need a new plan.  The program ping is a basic IP networking tool which lets us send a packet to a destination and if it answers, well, that means its alive.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ping banks.finavd.com
PING web-1166333941.us-west-2.elb.amazonaws.com (52.41.182.115): 56 data bytes
64 bytes from 52.41.182.115: icmp_seq=0 ttl=47 time=67.589 ms
64 bytes from 52.41.182.115: icmp_seq=1 ttl=47 time=67.301 ms
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Ah ha!  We have an ip address of 52.41.182.115.  I know! I know!  I know!  I’ll just search for that ip address on EC2 dashboard.  And it will fail.  Now the smart kids in the back are already chuckling to themselves and they know the answer.&lt;/p&gt;

&lt;h1 id=&quot;hypothesis-3-elb-is-being-used&quot;&gt;Hypothesis 3: ELB Is Being Used&lt;/h1&gt;

&lt;p&gt;If you look at the url that responded, NOT the ip address, the answer is revealed:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;web-1166333941.us-west-2.elb.amazonaws.com
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;You see the text string “.elb.”?  That means that a piece of software called an Elastic Load Balancer is sitting in front of the http request and distributing the load out to one or more EC2 instances.  If you’ve ever used HAProxy, well, ELB is that only far, far better.  Let’s goto the AWS Console and select the Load Balancers option from the choices on the left:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/aws/aws_elb_01_overview.png&quot; alt=&quot;aws_elb_01_overview.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here we’ll see an overview of all of our load balancers and their basic settings.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/aws/aws_elb_02_instances.png&quot; alt=&quot;aws_elb_02_instances.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Clicking the instances tab shows us where the HTTP request is being sent.  We can now goto the ec2 console and figure out what we need.  If you put the machine names into your &lt;a href=&quot;https://fuzzygroup.github.io/blog/aws/2016/09/20/aws-tutorial-08-using-ssh-s-config-file-with-your-aws-boxes.html&quot;&gt;SSH Config as I recommended&lt;/a&gt; then you might not even need to goto the console.  In my case I just needed to know the names worker2 and worker2a and I know that they’re in my ssh config file and I can just add those boxes to my Capistrano deploy process.  And the “bug” is fixed!&lt;/p&gt;

&lt;h1 id=&quot;conclusion-and-suggestion&quot;&gt;Conclusion and Suggestion&lt;/h1&gt;

&lt;p&gt;I know that it must seem like I’m a bit of a buffoon – how can you lost a web server after all?  Well, things do happen when you move fast.  You start with one plan and then it doesn’t work and before you know it you have something working but its not where you originally planned.  And you mean to fix it but you get busy and then the next &lt;a href=&quot;https://fuzzygroup.github.io/blog/aws/2016/10/01/aws-tutorial-10-diagnosing-ssh-failures-or-when-ping-works-but-ssh-fails.html&quot;&gt;crisis&lt;/a&gt; happens and you’re not even in the same head space any more.  And by the time you return to it over 10 days have passed.&lt;/p&gt;

&lt;p&gt;Here are some suggestions for setting up your AWS architecture to avoid this kind of silliness:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Name things well.&lt;/li&gt;
  &lt;li&gt;Name things logically.&lt;/li&gt;
  &lt;li&gt;Use the key value options when you set up your EC2 servers.  For example, having keys for both name and role might have helped.&lt;/li&gt;
  &lt;li&gt;Remember that there are often abstractions around everything.&lt;/li&gt;
  &lt;li&gt;Try and use single purpose servers from the start.  Yes the number of discrete servers increases complexity but their very single purpose nature makes debugging vastly easier.  And keep in mind that Amazon offers free servers.  Even a t2.micro free instance has 1 gig of ram and 8 gigs of storage.  I know that sounds funny but travel back in your head 5 years and that’s a beefy server and its &lt;strong&gt;FREE&lt;/strong&gt;.  If you’re just running something small, say Redis, Memcached, sendmail, etc that might be enough for a lot of applications.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 16 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/aws/2016/10/16/aws-tutorial-18-when-you-ve-lost-you-web-server-how-to-find-an-aws-resource.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/aws/2016/10/16/aws-tutorial-18-when-you-ve-lost-you-web-server-how-to-find-an-aws-resource.html</guid>
        
        <category>aws</category>
        
        
        <category>aws</category>
        
      </item>
    
      <item>
        <title>AWS Tutorial 17 - Wrapping Up Our SSH Issues By Using Monit For Process Monitoring</title>
        <description>&lt;p&gt;So the solution to our SSH issues is actually fairly simple:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ruby code is using too much memory / cpu; memory leak?  bad code?  who knows.&lt;/li&gt;
  &lt;li&gt;A watchdog process needs to look out for processes using too many resources and shut them down so that the underlying init / service system can restart them&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://fuzzygroup.github.io/blog/ruby/2016/10/10/a-conversation-with-mike-perham.html&quot;&gt;Mike Perham&lt;/a&gt; helpfully pointed out the right approach to solving this - use a systems monitoring tool like &lt;a href=&quot;https://github.com/mperham/inspeqtor&quot;&gt;Inspeqtor&lt;/a&gt; or &lt;a href=&quot;https://mmonit.com/monit/&quot;&gt;Monit&lt;/a&gt;.  I don’t normally do devops to the level that I am now so getting this perspective was key.  Given that its a 50 / 50 choice, I flipped a coin and chose Monit.&lt;/p&gt;

&lt;p&gt;In the rest of this post, I’ll go over how I used Ansible to configure Monit.&lt;/p&gt;

&lt;h1 id=&quot;the-role&quot;&gt;The Role&lt;/h1&gt;

&lt;p&gt;The first thing we need is a role for monit so we’re going to build out our role structure as follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mkdir -p your_ansible_root_path/roles/monit/tasks
mkdir -p your_ansible_root_path/roles/monit/templates
touch your_ansible_root_path/roles/monit/tasks/main.yml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Then we’re going to need a few things in our role (main.yml):&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;---
- name: install monit
  apt: pkg=monit state=present
  
- name: start monit
  service: name=monit state=started

- name: install monit sidekiq config file
  template: src=roles/monit/templates/sidekiq.j2 dest=/etc/monit/conf.d/sidekiq
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Our template for monitoring sidekiq is going to rely on a handful of variables that for simplicity’s sake, I’ve defined in the file all in groupvars:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;app_base: /var/www/apps/banks/
app_path: /var/www/apps/banks/current/
server_env: production
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Since I have sidekiq running on two different machines with different configurations, I used variables in the inventory file to define the number of threads and the max ram:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[crawler]
ficrawlerbig ansible_ssh_host=BLAH1.compute.amazonaws.com  ansible_ssh_private_key_file=/Users/sjohnson/.ssh/fi_nav_sitecrawl.pem  max_sidekiq_memory=&quot;50 GB&quot; max_sidekiq_threads=50
ficrawler3 ansible_ssh_host=BLAH2.compute.amazonaws.com ansible_ssh_private_key_file=/Users/sjohnson/.ssh/fi_nav_sitecrawl.pem max_sidekiq_memory=&quot;13 GB&quot; max_sidekiq_threads=25
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here’s what that template looks like:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;check process sidekiq
  with pidfile shared/tmp/pids/sidekiq.pid
  start program = &quot;cd  &amp;amp;&amp;amp; bundle exec ./bin/sidekiq -C ./config/sidekiq.yml -e &quot;
  
  stop program = &quot;/bin/bash -l -c 'cd  &amp;amp;&amp;amp; bundle exec sidekiqctl stop shared/tmp/pids/sidekiq.pid 10'&quot;
  if totalmem is greater than  for 3 cycles then restart
  
  if 3 restarts within 5 cycles then timeout
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And here’s the playbook routine which calls the monit role:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- { role: monit, tags: monit}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Once you put that all together, you’ll have monit watching the sidekiq process on a regular basis.  One thing I didn’t cover above is that we need to modify the config/sidekiq.yml file in the Rails root directory to use the right number of threads.  This is left as an exercise for the reader.&lt;/p&gt;

&lt;h1 id=&quot;conclusion-to-this-series-of-posts-on-ssh-trauma-and-thank-you-time-2&quot;&gt;Conclusion to this Series of Posts on SSH Trauma and Thank You Time 2&lt;/h1&gt;

&lt;p&gt;When I started this series of posts, 16 days ago, I really didn’t think all that much about SSH.  To an Internet developer, ssh is like &lt;em&gt;oxygen&lt;/em&gt;, you only notice it when it is &lt;strong&gt;gone&lt;/strong&gt;.  By having such a fundamental part of the infrastructure go away unexpectedly, it brought me new depths of understanding.  And, all of this occurred, while daily data processing and data crunching was going on.  Even with all the failures, our boxes stopped working.  Yes they would die periodically but I would just restart them while I explored my next hypothesis.  In the real world, business needs don’t stop even though things aren’t working correctly – you still have to get the job done.  And I did.&lt;/p&gt;

&lt;p&gt;Two people were absolutely essential to sorting this all out:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://nickjanetakis.com&quot;&gt;Nick Janetakis&lt;/a&gt;.  I initially met Nick thru his outstandingly excellent &lt;a href=&quot;http://www.udemy.com&quot;&gt;Udemy&lt;/a&gt; &lt;a href=&quot;http://nickjanetakis.com/courses/&quot;&gt;course on Docker&lt;/a&gt; and I’ve since gotten to know him a bit and hired him twice for &lt;a href=&quot;https://fuzzygroup.github.io/blog/aws/2016/10/06/aws-tutorial-14-diagnosing-ssh-failures-take-2.html&quot;&gt;ad hoc consulting&lt;/a&gt;.  Nick is a smart guy, knows Docker like the back of his hand and can think.  Thinking always sounds easy but it never is.  Recommended.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.mikeperham.com&quot;&gt;Mike Perham&lt;/a&gt;.  I’ve known of Mike Perham’s work intellectually for years and years and always described him as &lt;em&gt;the best guy in known space for Ruby threading&lt;/em&gt;.  I only met him recently when we adopted sidekiq as a partial solution for this problem.  In Mike’s weekly Happy Hour where he provides &lt;em&gt;free&lt;/em&gt; support to the Ruby community for Sidekiq, &lt;a href=&quot;https://fuzzygroup.github.io/blog/ruby/2016/10/10/a-conversation-with-mike-perham.html&quot;&gt;he correctly analyzed the problem and suggested a solution&lt;/a&gt;.  And you can bet that I’ve made sure that we purchased the &lt;a href=&quot;http://sidekiq.org/products/pro&quot;&gt;commercial version of Sidekiq&lt;/a&gt; in order to ensure that we have access to Mike should any future Sidekiq issues come up.  And don’t forget that the commercial version of Sidekiq includes more features as well as support.  Recommended as well.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thank you Nick; thank you Mike.&lt;/p&gt;
</description>
        <pubDate>Sun, 16 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/aws/2016/10/16/aws-tutorial-17-wrapping-up-our-ssh-issues-by-using-monit-for-process-monitoring.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/aws/2016/10/16/aws-tutorial-17-wrapping-up-our-ssh-issues-by-using-monit-for-process-monitoring.html</guid>
        
        <category>aws</category>
        
        <category>ssh</category>
        
        <category>monit</category>
        
        <category>ansible</category>
        
        
        <category>aws</category>
        
      </item>
    
      <item>
        <title>Brew XZ and Nokogiri and Tmux - An Unmitigated Disaster</title>
        <description>&lt;p&gt;It has been one really, really bad day this past 24 hours.  While my AWS stability problems have gone away entirely, I had to get a new Rails code base up and running locally today, one done by another developer here.  This required Gem install and since it was Rails, that meant a Nokogiri install.  And I love what Nokogiri does but I &lt;em&gt;hate&lt;/em&gt;, &lt;em&gt;loathe&lt;/em&gt;, &lt;em&gt;despise&lt;/em&gt; the installation process.  In every single repo I work on there is a top level docs directory and then a file called gems.txt which lists what I internally refer to as &lt;em&gt;the incantations&lt;/em&gt;.  These are those crap ass command lines that are so long you just can’t remember them.  Here’s the list of the tricks that I use to install Nokogiri when it inevitably fails:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gem install nokogumbo -- --with-xml2-include=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk/usr/include/libxml2 --use-system-libraries
gem install nokogiri -- --with-xml2-include=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk/usr/include/libxml2 --use-system-libraries
gem install nokogiri -- --with-xml2-include=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk/usr/include/libxml2 --use-system-libraries --with-pkg-config=/usr/local/bin/pkg-config
gem install nokogiri -- --with-xml2-include=/usr/local/opt/libxml2/lib --use-system-libraries --with-pkg-config=/usr/local/bin/pkg-config
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And not one of those worked.  The one that usually works without fail is:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gem install nokogiri -- --with-xml2-include=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.11.sdk/usr/include/libxml2 --use-system-libraries
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;but not today.  I knew this was going to be a bad day.  I told the other guy here “your code, doesn’t install; give me solution”.  He found this &lt;a href=&quot;https://github.com/sparklemotion/nokogiri/issues/1483&quot;&gt;nugget of disturbing truth&lt;/a&gt;.  Apparently there is an incompatibility between Nokogiri and xz.  His suggestion was uninstall xz and I did that.  And Nokogiri was then fine – but I had to also reinstall ruby.   And that did work – until about an hour ago when I had a late night desire to write about Docker (hey - it is my Friday night; I can spend it however I please) – and I started getting this little gem of an error:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jekyll post &quot;Learning From a Docker Captain - Nick Janetakis - Making AWS Monitor Run Under Docker&quot;
Your bundle is locked to i18n (0.7.0), but that version could not be found in any of the sources listed in your Gemfile. If you haven't changed sources, that means the author of i18n (0.7.0) has removed it. You'll need to update your bundle to a different version of i18n (0.7.0) that hasn't been removed in order to install.
Run `bundle install` to install missing gems.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And this led to the inevitable cavalcade of swearing, muttering and normal gyrations when something absolutely essential to you is broken and you have no idea why.  Brew wouldn’t work, Gem wouldn’t work, Bundler wouldn’t work, etc.  Here was the problem:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;I run jekyll under a Tmuxinator/Tmux shell which runs the server in one window, runs the command line in another and a 3rd tab to remind me to migrate my old Radio Userland blog into Jekyll.&lt;/li&gt;
  &lt;li&gt;Remember that ruby re-install?  Well Tmuxinator knows what the Ruby is and that ruby had gone away.&lt;/li&gt;
  &lt;li&gt;So everything was trying to reference an executable that was no longer there and apparently the normal error for that is something about i18n.  Sheesh.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And I do get it, this was an exceptional set of circumstances but it still did cost me about half a man day on a day when I can ill afford it.  And it made me surly, nasty and unresponsive to my family and while that’s on me, that’s definitely not cool.&lt;/p&gt;

&lt;h1 id=&quot;what-to-do&quot;&gt;What to Do?&lt;/h1&gt;

&lt;p&gt;This is a hard one.  I rely on brew as does, well, every developer I know on OSX.  And since xz is a required part of brew (as well as the miraculous ag), getting rid of it is likely bad.  What I should have done is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;brew unlink xz BEFORE my nokogiri install&lt;/li&gt;
  &lt;li&gt;nokogiri install (with one of my incantations)&lt;/li&gt;
  &lt;li&gt;brew link xz&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But, honestly, it is 2016 after all, doesn’t that feel, well, &lt;em&gt;dated&lt;/em&gt;?  I don’t know about anybody else out there but it feels like this is my Murtagh Moment, the &lt;em&gt;I’m too old for this shite&lt;/em&gt; point of a technology transition.  &lt;a href=&quot;http://nickjanetakis.com&quot;&gt;Nick&lt;/a&gt; has been pushing me for a while to make the Docker transition for development and I think it is time.  &lt;a href=&quot;http://dasari.me&quot;&gt;Dv&lt;/a&gt; and I tried this back in 2014 and failed miserably at it but Docker is loads better now.  And since I can’t run my monitoring code on the machine that is permanently hooked up to the internet (again a Nokogiri failure), well, I guess I’ll make that work first and then figure this all out.  Sigh.  What a craptastic day here in the “what’s broken today world”.&lt;/p&gt;

&lt;p&gt;And I am sure that this will get fixed at some point but the question:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;when will it be fixed&lt;/li&gt;
  &lt;li&gt;will I then even update to that version&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If I move to Docker for my development then I skip the whole bundle install crap fest and everything will run under Linux.  I’m finding it harder and hard to object to that.&lt;/p&gt;

&lt;h1 id=&quot;a-great-docker-resource&quot;&gt;A Great Docker Resource&lt;/h1&gt;

&lt;p&gt;Obligatory disclaimer – Nick Janetakis is now a friend of mine.  But he is a bona fide Docker expert, a Docker Captain.  He also has a good course on &lt;a href=&quot;http://bit.ly/2ecakFU&quot;&gt;Docker for Devops&lt;/a&gt; hosted on Udemy.  he has a few others too but this one I’ve taken parts of and I know is excellent.  Recommended.&lt;/p&gt;

</description>
        <pubDate>Sat, 15 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/ruby/2016/10/15/brew-xz-and-nokogiri-and-tmux-an-unmitigated-disaster.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/ruby/2016/10/15/brew-xz-and-nokogiri-and-tmux-an-unmitigated-disaster.html</guid>
        
        <category>ruby</category>
        
        <category>nokogiri</category>
        
        <category>rvm</category>
        
        <category>brew</category>
        
        <category>tmux</category>
        
        
        <category>ruby</category>
        
      </item>
    
      <item>
        <title>To Every U.S. Workaholic Out There</title>
        <description>&lt;p&gt;Reminder to every U.S. Workaholic - https://www.redcort.com/us-federal-bank-holidays/&lt;/p&gt;
</description>
        <pubDate>Thu, 13 Oct 2016 22:07:36 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/2016/10/13/to-every-u-s-workaholic-out-there.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/2016/10/13/to-every-u-s-workaholic-out-there.html</guid>
        
        
      </item>
    
      <item>
        <title>Moving AWS Monitor to Docker or Troubleshooting Docker Bit By Bit</title>
        <description>&lt;p&gt;So now that my monitoring code is actually working, I need to move it to my MacBook Pro.  Unfortunately this machine is, inexplicably, unable to natively install Nokogiri.  I’ve tried, &lt;a href=&quot;http://dasari.me&quot;&gt;Dv&lt;/a&gt; has tried and so has &lt;a href=&quot;http://winstonkotzan.com/blog/&quot;&gt;Winston&lt;/a&gt;.  And no matter what we do, it seems that this machine is just hosed for Rails development.  Or is it – I know what &lt;a href=&quot;http://www.nickjanetakis.com&quot;&gt;Nick&lt;/a&gt; would say:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Use Docker&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;And he’s a Docker Captain so he should know.  And while I’ve been a fan of Docker so far for treating almost any app as an API, I’ve never been a fan for my own code base.  But now its time.  Happily I did build this using my derivative of &lt;a href=&quot;https://github.com/nickjj/orats&quot;&gt;Nick’s Orats Gem&lt;/a&gt; so I’m actually ok as a starting point.&lt;/p&gt;

&lt;h1 id=&quot;getting-started-with-docker&quot;&gt;Getting Started with Docker&lt;/h1&gt;

&lt;p&gt;The first step was to replace my docker-compose.yml with the official Orats one.  A quick trip over to github gave me this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;version: '2'

services:
  postgres:
    image: 'postgres:9.5'
    environment:
      POSTGRES_USER: 'orats_base'
      POSTGRES_PASSWORD: 'yourpassword'
    ports:
      - '5432:5432'
    volumes:
      - 'postgres:/var/lib/postgresql/data'

  redis:
    image: 'redis:3.2-alpine'
    command: redis-server --requirepass yourpassword
    ports:
      - '6379:6379'
    volumes:
      - 'redis:/var/lib/redis/data'

  website:
    depends_on:
      - 'postgres'
      - 'redis'
    build: .
    ports:
      - '3000:3000'
    volumes:
      - '.:/orats_base'
    env_file:
      - '.env'

  sidekiq:
    depends_on:
      - 'postgres'
      - 'redis'
    build: .
    command: sidekiq -C config/sidekiq.yml.erb
    volumes:
      - '.:/orats_base'
    env_file:
      - '.env'

  cable:
    depends_on:
      - 'redis'
    build: .
    command: puma -p 28080 cable/config.ru
    ports:
      - '28080:28080'
    volumes:
      - '.:/orats_base'
    env_file:
      - '.env'

volumes:
  redis:
  postgres:
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The reason for replacing it is that I had wanted to make a version of Orats with MySQL support but I never had the chance to finish it.  It is likely faster to use Nick’s postgres approach over my own half baked one.&lt;/p&gt;

&lt;p&gt;The next step is to compile everything using docker-compose:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker-compose up --build
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now what happened next is a bit puzzling:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Installing pg 0.19.0 with native extensions

Gem::Ext::BuildError: ERROR: Failed to build gem native extension.

    current directory: /usr/local/bundle/gems/pg-0.19.0/ext
/usr/local/bin/ruby -r ./siteconf20161013-6-1sug58s.rb extconf.rb
checking for pg_config... no
No pg_config... trying anyway. If building fails, please try again with
 --with-pg-config=/path/to/pg_config
checking for libpq-fe.h... no
Can't find the 'libpq-fe.h header
*** extconf.rb failed ***
Could not create Makefile due to some reason, probably lack of necessary
libraries and/or headers.  Check the mkmf.log file for more details.  You may
need configuration options.

Provided configuration options:
	--with-opt-dir
	--without-opt-dir
	--with-opt-include
	--without-opt-include=${opt-dir}/include
	--with-opt-lib
	--without-opt-lib=${opt-dir}/lib
	--with-make-prog
	--without-make-prog
	--srcdir=.
	--curdir
	--ruby=/usr/local/bin/$(RUBY_BASE_NAME)
	--with-pg
	--without-pg
	--enable-windows-cross
	--disable-windows-cross
	--with-pg-config
	--without-pg-config
	--with-pg_config
	--without-pg_config
	--with-pg-dir
	--without-pg-dir
	--with-pg-include
	--without-pg-include=${pg-dir}/include
	--with-pg-lib
	--without-pg-lib=${pg-dir}/lib

To see why this extension failed to compile, please check the mkmf.log which can be found here:

  /usr/local/bundle/extensions/x86_64-linux/2.3.0-static/pg-0.19.0/mkmf.log

extconf failed, exit code 1

Gem files will remain installed in /usr/local/bundle/gems/pg-0.19.0 for inspection.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;So now the question becomes how do you debug a Ruby gem failure inside a Docker container.  I honestly don’t know so I reached out to Nick for clarification:&lt;/p&gt;

&lt;p&gt;Now I have to admit that I rushed thru this but that’s still not a reason – its an excuse.  Nick, in about a minute, pointed out that I was missing libpq so the Postgres gem wouldn’t build.&lt;/p&gt;

</description>
        <pubDate>Thu, 13 Oct 2016 21:20:28 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/aws/2016/10/13/moving-aws-monitor-to-docker-or-troubleshooting-docker-bit-by-bit.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/aws/2016/10/13/moving-aws-monitor-to-docker-or-troubleshooting-docker-bit-by-bit.html</guid>
        
        <category>aws</category>
        
        <category>rails</category>
        
        <category>docker</category>
        
        
        <category>aws</category>
        
      </item>
    
      <item>
        <title>Sidekiq - Graceful Versus Forceful</title>
        <description>&lt;p&gt;So now that I’m using Sidekiq for background processes, I need to be able to start it up, shut it down and I need to understand the difference between forceful and graceful.&lt;/p&gt;

&lt;h1 id=&quot;running-sidekiq-interactively&quot;&gt;Running Sidekiq Interactively&lt;/h1&gt;

&lt;p&gt;This is easy and we all should know this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /my_rails_app/where_ever_that_is
bundle exec sidekiq
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This will run Sidekiq interactively.  Now if you want it to run even if your connection to the remote box drops then you need to use Tmux or something similar.&lt;/p&gt;

&lt;h1 id=&quot;running-it-as-a-service&quot;&gt;Running it as a Service&lt;/h1&gt;

&lt;p&gt;See my last blog post on using Ansible to configure Sidekiq and I think that will become clear.&lt;/p&gt;

&lt;h1 id=&quot;forceful-versus-graceful&quot;&gt;Forceful versus Graceful&lt;/h1&gt;

&lt;p&gt;Forceful versus Graceful defines how you want Sidekiq to shut down and it basically boils down to the speed of the shutdown.  Sidekiq runs “jobs” which basically means “long running methods” and here’s the difference:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;forceful – shut down NOW; abandon all work in process&lt;/li&gt;
  &lt;li&gt;graceful – tell sidekiq to shut down when each of its threads is done processing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let’s use an analogy here to make this clear.  Imagine that sidekiq was a hitchhiker you picked up on the side of the road.  Forceful would be you opening the door and kicking the hitchhiker out while the car is still moving.  Graceful would be you saying “I think you need to get out at the next exit and the hitchhiker saying - &lt;em&gt;I’m sorry but I need a bit more time; I’ll get out when I’m ready&lt;/em&gt;”.&lt;/p&gt;

&lt;p&gt;There isn’t a right answer here whether or not to use Forceful or Graceful – it really depends on your context.  If you use Sidekiq to handle short lived asynchronous tasks like, say, sending a welcome email then you probably want to use Graceful since it shouldn’t take that long for each thread to idle down.  I, on the other hand, use sidekiq to handle tasks that might take hours or even a whole day to finish so I usually use Forceful.  Given that my tasks have their own journal, this isn’t terrible.  It isn’t great but it isn’t terrible.&lt;/p&gt;

&lt;p&gt;Here’s an example of a Forceful shutdown:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ps -ef | grep sidekiq | grep -v grep | awk '{print $2}' | xargs kill -9
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here’s an example of a Graceful shutdown:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ps auwwx | grep sidekiq  # and give the pid value to the next command where &amp;lt;pid&amp;gt; is
sidekiqctl stop &amp;lt;pid&amp;gt; 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;My thanks to the fine community at &lt;a href=&quot;http://www.sidekiq.com/&quot;&gt;Stack Overflow&lt;/a&gt; for these &lt;a href=&quot;http://stackoverflow.com/questions/12143350/gracefully-shutting-down-sidekiq-processes&quot;&gt;Sidekiq Graceful answers&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Thu, 13 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/ruby/2016/10/13/sidekiq-graceful-versus-forceful.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/ruby/2016/10/13/sidekiq-graceful-versus-forceful.html</guid>
        
        <category>rails</category>
        
        <category>ruby</category>
        
        <category>sidekiq</category>
        
        <category>unix</category>
        
        
        <category>ruby</category>
        
      </item>
    
      <item>
        <title>AWS Tutorial 16 - SSH Failures Take 4 - Time to Write Some Monitoring Code</title>
        <description>&lt;p&gt;&lt;img src=&quot;/blog/assets/ood_not_oom.jpg&quot; alt=&quot;ood_not_oom.jpg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;My apologies to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Tenth_Doctor&quot;&gt;Good Doctor&lt;/a&gt; but when &lt;a href=&quot;https://linux-mm.org/OOM_Killer&quot;&gt;OOM&lt;/a&gt; is failing you, you have to make an &lt;a href=&quot;https://en.wikipedia.org/wiki/Ood&quot;&gt;OOD&lt;/a&gt; joke.  We’re nerdy over here.  Every one of us.&lt;/p&gt;

&lt;p&gt;Well crap.  I just ran my ansible df -h test which checks to make sure my boxes are up and running and I got complete failure:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;fiweb1 | UNREACHABLE! =&amp;gt; {
    &quot;changed&quot;: false,
    &quot;msg&quot;: &quot;Failed to connect to the host via ssh.&quot;,
    &quot;unreachable&quot;: true
}
fiansible2 | UNREACHABLE! =&amp;gt; {
    &quot;changed&quot;: false,
    &quot;msg&quot;: &quot;Failed to connect to the host via ssh.&quot;,
    &quot;unreachable&quot;: true
}
ficrawlerbig | UNREACHABLE! =&amp;gt; {
    &quot;changed&quot;: false,
    &quot;msg&quot;: &quot;Failed to connect to the host via ssh.&quot;,
    &quot;unreachable&quot;: true
}
ficrawler3 | UNREACHABLE! =&amp;gt; {
    &quot;changed&quot;: false,
    &quot;msg&quot;: &quot;Failed to connect to the host via ssh.&quot;,
    &quot;unreachable&quot;: true
}
ficrawler4 | UNREACHABLE! =&amp;gt; {
    &quot;changed&quot;: false,
    &quot;msg&quot;: &quot;Failed to connect to the host via ssh.&quot;,
    &quot;unreachable&quot;: true
}
ficrawler5 | UNREACHABLE! =&amp;gt; {
    &quot;changed&quot;: false,
    &quot;msg&quot;: &quot;Failed to connect to the host via ssh.&quot;,
    &quot;unreachable&quot;: true
}
ficrawler6 | UNREACHABLE! =&amp;gt; {
    &quot;changed&quot;: false,
    &quot;msg&quot;: &quot;Failed to connect to the host via ssh.&quot;,
    &quot;unreachable&quot;: true
}
ficrawler7 | UNREACHABLE! =&amp;gt; {
    &quot;changed&quot;: false,
    &quot;msg&quot;: &quot;Failed to connect to the host via ssh.&quot;,
    &quot;unreachable&quot;: true
}
ficrawler8 | UNREACHABLE! =&amp;gt; {
    &quot;changed&quot;: false,
    &quot;msg&quot;: &quot;Failed to connect to the host via ssh.&quot;,
    &quot;unreachable&quot;: true
}
ficrawler9 | UNREACHABLE! =&amp;gt; {
    &quot;changed&quot;: false,
    &quot;msg&quot;: &quot;Failed to connect to the host via ssh.&quot;,
    &quot;unreachable&quot;: true
}
ficrawler10 | UNREACHABLE! =&amp;gt; {
    &quot;changed&quot;: false,
    &quot;msg&quot;: &quot;Failed to connect to the host via ssh.&quot;,
    &quot;unreachable&quot;: true
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Curiouser and curiouser said Alice.  The interesting thing here is that two of these boxes ARE NOT running our crawler code.  They’re actually doing nothing at all.  So what does this tell us:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Perhaps the issue has nothing to do with our code at all.&lt;/li&gt;
  &lt;li&gt;Perhaps it is an underlying Linux problem on AWS w/ Ubuntu.&lt;/li&gt;
  &lt;li&gt;It seems to be related to resource consumption but that’s a guess not a true statement.&lt;/li&gt;
  &lt;li&gt;There is no damn way to monitor this (&amp;amp;$#($&lt;em&gt;#()$&lt;/em&gt;#)) problem since it no one monitors SSH failures.  Sigh.&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;writing-your-own-monitoring-tool&quot;&gt;Writing Your Own Monitoring Tool&lt;/h1&gt;

&lt;p&gt;And so I now get to time travel back to 2007, the first time I wrote a monitoring tool in Ruby.  I was working for the late, not-lamented eduFire and there wasn’t money to sign up for a monitoring tool.  Ah life in startup land.  My children can and do tell the tale of Dad’s computer waking up in the middle of the night screaming “eduFire IS DOWN!!!”.  And then there was the incarnation that, a few years later, would plain Billy Idol’s White Wedding at top volume.  So this is old territory for me.  But maybe we can do a bit better.  So what do we need to do?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Run forever&lt;/li&gt;
  &lt;li&gt;Run reliably - this is Ruby after all&lt;/li&gt;
  &lt;li&gt;Read from the ansible hosts file and get a list of resources to monitor&lt;/li&gt;
  &lt;li&gt;Loop over the hosts&lt;/li&gt;
  &lt;li&gt;Establish an ssh connection&lt;/li&gt;
  &lt;li&gt;If successful then do nothing&lt;/li&gt;
  &lt;li&gt;If unsuccessful increment a failure counter&lt;/li&gt;
  &lt;li&gt;If failure ctr &amp;gt; a threshold then fire off an alert by playing White Wedding and also send an alert to my phone&lt;/li&gt;
  &lt;li&gt;Optionally incorporate AWS API calls to restart the instance if this is possible and it has failed more times than a restart threshold&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;run-forever&quot;&gt;Run Forever&lt;/h2&gt;

&lt;p&gt;This can be nothing more than a while(true) loop construct.  It isn’t elegant but it will work.&lt;/p&gt;

&lt;h2 id=&quot;run-reliably&quot;&gt;Run Reliably&lt;/h2&gt;

&lt;p&gt;We can wrap this within daemon tools supervise to make sure it stays running.&lt;/p&gt;

&lt;h2 id=&quot;read-from-ansible-hosts-file&quot;&gt;Read from Ansible Hosts file&lt;/h2&gt;

&lt;p&gt;This can be done with any of a number of gems which read from an INI file.  No matter what we use, the Ansible INI syntax is funky so we’re likely to need some parsing.&lt;/p&gt;

&lt;h2 id=&quot;loop-over-the-hosts&quot;&gt;Loop Over The Hosts&lt;/h2&gt;

&lt;p&gt;The INI gem will return an enumerable collection so this is just a .each call.  Piece of cake.  .each is my single favorite thing in all of Ruby.&lt;/p&gt;

&lt;h2 id=&quot;establish-an-ssh-connection&quot;&gt;Establish an SSH connection&lt;/h2&gt;

&lt;p&gt;There has to be a gem for this.  &lt;strong&gt;Google Furiously&lt;/strong&gt;  Yep.  Even better Jamis Buck wrote it.  Fantastic.  That means I can trust it.&lt;/p&gt;

&lt;h2 id=&quot;items-6-thru-9&quot;&gt;Items 6 thru 9&lt;/h2&gt;

&lt;p&gt;This is the core of a monitoring tool and where crap gets tricky:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;You have to make sure you actually have outbound connectivity so you need something to test against that NEVER goes down.  Hm… 8.8.8.8 is perfect – it is Google’s DNS server and it can be ping’d so I don’t have to test via SSH.  There must be a ping gem.  &lt;strong&gt;More Furious Googling&lt;/strong&gt;.  Yep.&lt;/li&gt;
  &lt;li&gt;You have to alert.  Yep.  That means I’m going to use Twilio again.  Twilio is fantastic.&lt;/li&gt;
  &lt;li&gt;In the event of a failure you have to get my attention and no alert needs to be sent if I’m already at the computer.  I’ll yank out the old white wedding play routine I used for my second monitoring tool (which indirectly was this same damn code base) and I’ll just reuse it.&lt;/li&gt;
  &lt;li&gt;You need a machine which is 24x7 connected to the Internet and never goes away.  Well my Macbook Air travels everywhere I go these days but my Macbook Pro is constantly on.  So I’ll use that.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;the-code&quot;&gt;The Code&lt;/h1&gt;

&lt;p&gt;Listed below is a rake task which encapsulates the bulk of it.  This is actually only the &lt;strong&gt;first draft&lt;/strong&gt; of it.  The actual &lt;a href=&quot;https://github.com/fuzzygroup/aws_monitor&quot;&gt;github&lt;/a&gt; code is better but I’ve been up all night so I don’t think trying to write a good description of it is wise.  The detailed stuff is handled by aws_monitor.rb which is a short class of static methods just to simplify the rake task and make them testable.  The only bad thing I can ever say about Jim Weirich is that Rake tasks aren’t really testable.  Other than that I wish he was still with us.  Right now this code is a bit of a rough draft as the failure hasn’t happened again yet and things like error handling always need to get addressed but it looks something like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;namespace :monitor_aws do
  # bundle exec rake monitor_aws:ansible_hosts --trace
  task :ansible_hosts =&amp;gt; :environment do
    #
    # Things to change easily for adapting to different environments
    #

    # CHANGE THIS to your ansible inventory file
    ansible_hosts_file = File.join(Rails.root, 'script/ansible/inventories/production2')
    # CHANGE THIS to how frequently to monitor
    sleep_time = 60 * 5  # every five minutes we will execute
    # CHANGE THIS to your ssh login
    username = &quot;ubuntu&quot;
    # CHANGE THIS to the number of consecutive failures you want to alert on
    min_failures = 2     

    run_ctr = 0
    while(true) do
      run_ctr = run_ctr + 1
      puts &quot;Monitoring run: #{run_ctr}&quot;
      ansible_hosts = AwsMonitor.load_ansible_hosts(ansible_hosts_file)
      failure_ctr = 0
      ansible_hosts.entries.each do |entry|
        ansible_host = AwsMonitor.ini_entry_to_struct(entry)
        session = Net::SSH.start( ansible_host.host_name, username, :keys =&amp;gt; ansible_host.keyfile )
        if session.error.nil?
          puts &quot;Success!  The box #{ansible_host.human_name} is still alive!!!&quot;.green
        else
          puts &quot;#{session.error}&quot;
          AwsMonitor.play_white_wedding(ansible_host, '')
          debugger          
        end
        session.close
      end
      puts &quot;\n\n\n&quot;
      sleep(sleep_time)
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And that’s about all there is to it.  The complicated version, which is also written, but not yet published has some other tricks like using ping to make sure my local connectivity didn’t fail.  I don’t want to publish that yet since I don’t understand if my failure condition is going to be a  Net::SSH::AuthenticationFailed or a session.error message or what.&lt;/p&gt;

&lt;h2 id=&quot;postscript&quot;&gt;Postscript&lt;/h2&gt;

&lt;p&gt;This morning I added a running timer to track how long the boxes were up.  This is what it looks like now:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Monitoring run: 31
Success!  The box ficrawler3 is still alive and has been for: 9300 seconds!!!
Success!  The box ficrawler4 is still alive and has been for: 9300 seconds!!!
Success!  The box ficrawler5 is still alive and has been for: 9300 seconds!!!
Success!  The box ficrawler6 is still alive and has been for: 9300 seconds!!!
Success!  The box ficrawler7 is still alive and has been for: 9300 seconds!!!
Success!  The box ficrawler8 is still alive and has been for: 9300 seconds!!!
Success!  The box ficrawler9 is still alive and has been for: 9300 seconds!!!
Success!  The box ficrawler10 is still alive and has been for: 9300 seconds!!!
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;postscript-2&quot;&gt;Postscript 2&lt;/h2&gt;

&lt;p&gt;I had wanted to make this work with Twilio for alerting but I just ran out of time.  If anyone needs help with that reach out to me and I’ll get it in.  Its not hard and Twilio is an awesome, awesome company to work with.&lt;/p&gt;

&lt;h2 id=&quot;postscript-3&quot;&gt;Postscript 3&lt;/h2&gt;

&lt;p&gt;I just realized that I think the Twilio credentials are in the git repo.  Sigh.  I turned on 2 factor authentication so that should prevent them from getting used by someone other than me.&lt;/p&gt;

&lt;h2 id=&quot;license&quot;&gt;License&lt;/h2&gt;

&lt;p&gt;Do with it as you will.  Enjoy it; fork it, etc.  Sorry it took so long to get this post out.&lt;/p&gt;
</description>
        <pubDate>Thu, 13 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/aws/2016/10/13/aws-tutorial-16-ssh-failures-take-4-time-to-write-some-monitoring-code.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/aws/2016/10/13/aws-tutorial-16-ssh-failures-take-4-time-to-write-some-monitoring-code.html</guid>
        
        <category>aws</category>
        
        <category>ssh</category>
        
        <category>ruby</category>
        
        <category>monitoring</category>
        
        
        <category>aws</category>
        
      </item>
    
      <item>
        <title>Ansible Tutorial 02 - Configuring a Sidekiq Upstart Job on Ubuntu 14.04</title>
        <description>&lt;p&gt;As I’ve now noted a number of times, I’m in the process of a large scale AWS migration and we’ve had stability problems.  Unlike previous times in my life where I threw my hands up, got tired with devops and just hacked something together, I’m determined that, this time, things will be different.  At the heart of our issues has been ballooning memory use in Ruby.  Whether the issue is in our code, a gem, an interaction or something else entirely is, at present, unknown.&lt;/p&gt;

&lt;p&gt;The solution I’ve opted to go with for solving this is:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Remove our own threading code&lt;/li&gt;
  &lt;li&gt;Use &lt;a href=&quot;http://www.mikeperham.com&quot;&gt;Mike Perham&lt;/a&gt;’s astonishingly wonderful &lt;a href=&quot;http://sidekiq.org&quot;&gt;Sidekiq&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Sign up for paid support / &lt;a href=&quot;http://sidekiq.org/products/pro&quot;&gt;Sidekiq Pro&lt;/a&gt; so any assistance that we need is possible.&lt;/li&gt;
  &lt;li&gt;Move to an upstart job to run sidekiq&lt;/li&gt;
  &lt;li&gt;Use &lt;a href=&quot;https://mmonit.com/monit/&quot;&gt;Monit&lt;/a&gt; or &lt;a href=&quot;https://github.com/mperham/inspeqtor&quot;&gt;inspeqtor&lt;/a&gt; to Monitor Sidekiq&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In this blog post I’m going to focus on #4 – using an Upstart Job to Run Sidekiq and define that job with Ansible.  The very first thing to know is that my previous ansible task, &lt;a href=&quot;https://fuzzygroup.github.io/blog/ansible/2016/10/09/ansible-quickie-fixing-a-poorly-designed-galaxy-role.html&quot;&gt;here&lt;/a&gt;, is absolute crap as best I can tell.  Even with my fixes, like so many things on &lt;a href=&quot;https://galaxy.ansible.com&quot;&gt;Ansible Galaxy&lt;/a&gt;, it was just plain wrong.  Where Galaxy is good, its excellent, but that’s rare in my experience.&lt;/p&gt;

&lt;p&gt;Just a disclaimer - any errors here are mine, not Mike’s or Sidekiq’s.  I own the responsibility here.&lt;/p&gt;

&lt;h1 id=&quot;using-ansible-to-install-a-sidekiq-service&quot;&gt;Using Ansible to Install a Sidekiq Service&lt;/h1&gt;

&lt;p&gt;Here are our assumptions that we’re basing our ansible code on:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ubuntu 14.04&lt;/li&gt;
  &lt;li&gt;Upstart&lt;/li&gt;
  &lt;li&gt;Single, global ruby per server&lt;/li&gt;
  &lt;li&gt;RVM (even though it isn’t strictly necessary)&lt;/li&gt;
  &lt;li&gt;One ruby app per server&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let’s begin with the structure of our role:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd ~/whatever_your_ansible_root_is
mkdir -p roles/software_licenses/tasks
mkdir -p roles/services
mkdir roles/services/tasks
mkdir roles/servies/templates
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;optional---adding-your-sidekiq-pro-software-license&quot;&gt;Optional - Adding Your Sidekiq Pro Software License&lt;/h2&gt;

&lt;p&gt;Sidekiq Pro is commercial software, not open source, so if you’re using it instead of the open source version, you’ll need to authorize it.  Here’s how to do this.  Here’s what goes in your roles/software_licenses/tasks/main.yml:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gd&quot;&gt;--- 
- name: set the licensing for sidekiq pro
&lt;/span&gt;  become: no
  shell:  &quot;cd /var/www/apps/banks/current &amp;amp;&amp;amp; bundle config gems.contribsys.com YOUR_SECURITY_KEY&quot;    
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;defining-your-group-vars&quot;&gt;Defining Your Group Vars&lt;/h2&gt;

&lt;p&gt;Here’s what goes in your group_vars context.  I had these in all but you may choose a different approach:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;app_name: banks
app_base: /var/www/apps/banks/
app_path: /var/www/apps/banks/current/
user_name: ubuntu
db_root_password: FDFJKSDJFKLSFJSLKFJSKLFSJFKLSDJF
my_ip_address: 64.184.12.117
server_env: production
rvm_path: /usr/local/rvm/bin/rvm    
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;your-template-for-the-upstart-job&quot;&gt;Your Template for the Upstart Job&lt;/h2&gt;

&lt;p&gt;Here’s what goes in roles/services/templates/sidekiq_perham_init.j2:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# /etc/init/sidekiq.conf - Sidekiq config
# source: https://github.com/mperham/sidekiq/blob/master/examples/upstart/sidekiq.conf

# This example config should work with Ubuntu 12.04+.  It
# allows you to manage multiple Sidekiq instances with
# Upstart, Ubuntu's native service management tool.
#
# See workers.conf for how to manage all Sidekiq instances at once.
#
# Save this config as /etc/init/sidekiq.conf then manage sidekiq with:
#   sudo start sidekiq index=0
#   sudo stop sidekiq index=0
#   sudo status sidekiq index=0
#
# Hack Upstart's reload command to 'quiet' Sidekiq:
#
#   sudo reload sidekiq index=0
#
# or use the service command:
#   sudo service sidekiq {start,stop,restart,status}
#

description &quot;Sidekiq Background Worker&quot;

# This script is not meant to start on bootup, workers.conf
# will start all sidekiq instances explicitly when it starts.
#start on runlevel [2345]
#stop on runlevel [06]

# change to match your deployment user
setuid 
setgid 
env HOME=

respawn
respawn limit 3 30

# TERM is sent by sidekiqctl when stopping sidekiq. Without declaring these as
# normal exit codes, it just respawns.
normal exit 0 TERM

# Older versions of Upstart might not support the reload command and need
# this commented out.
reload signal USR1

# Upstart waits 5 seconds by default to kill the a process. Increase timeout to
# give sidekiq process enough time to exit.
kill timeout 15

#instance $index
instance 0

script
# this script runs in /bin/sh by default
# respawn as bash so we can source in rbenv
exec /bin/bash &amp;lt;&amp;lt;'EOT'
  # Pick your poison :) Or none if you're using a system wide installed Ruby.
  # rbenv
  # source /home/apps/.bash_profile
  # OR
  # source /home/apps/.profile
  # OR system:
  # source /etc/profile.d/rbenv.sh
  #
  # rvm
  # source /home/apps/.rvm/scripts/rvm
  source 

  # Logs out to /var/log/upstart/sidekiq.log by default

  cd 
  #exec bundle exec sidekiq -i ${index} -e production
  exec bundle exec sidekiq -i 0 -e production
EOT
end script
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Please note that the template above comes directly from Mike Perham’s Sidekiq Wiki, &lt;a href=&quot;https://github.com/mperham/sidekiq/blob/master/examples/upstart/sidekiq.conf&quot;&gt;here&lt;/a&gt;.  I modified it slightly to incorporate ansible variables and to remove the index parameter which didn’t function, at least for me, on Ubuntu 14.04.&lt;/p&gt;

&lt;h2 id=&quot;pulling-the-template-and-service-together&quot;&gt;Pulling the Template and Service Together&lt;/h2&gt;

&lt;p&gt;Here’s what goes in roles/services/tasks/main.yml:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- name: prevent sidekiq init from running if it has already been done
  stat: path=/etc/init/sidekiq.conf
  register: sidekiq_init_installed
  
- name: Copy sidekiq init template to init.d dir
  template: src=sidekiq_perham_init.j2 dest=/etc/init/sidekiq.conf owner=root group=root force=yes
  sudo: yes
  when: sidekiq_init_installed.stat.exists == False

- name: start_sidekiq
  service: name=sidekiq state=started
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The only real Ansible trick here is to figure out how to make this idempotent so it only installs the upstart job once.  To do that I use the stat module to check the location of the upstart sidekiq.conf file and register a variable.  Then I only install the template when that variable is false.&lt;/p&gt;

&lt;h2 id=&quot;calling-everything-from-the-playbook&quot;&gt;Calling Everything from the Playbook&lt;/h2&gt;

&lt;p&gt;The final step here is to pull the roles into the playbook so it can run.  Here’s how:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- { role: software_licenses, tags: software_licenses }
- { role: services, tags: services }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Because the service depends on the gem it is important that the software_licenses role run first so the gem is authorized.  Otherwise Sidekiq won’t start and the service will be borked.&lt;/p&gt;

&lt;h2 id=&quot;optional---your-ruby-apps-gemfile&quot;&gt;Optional - Your Ruby App’s Gemfile&lt;/h2&gt;

&lt;p&gt;If you’re using Sidekiq Pro, you’ll need to update your gem file with the stuff you got from Sidekiq support.&lt;/p&gt;

&lt;h2 id=&quot;running-the-playbook&quot;&gt;Running the Playbook&lt;/h2&gt;

&lt;p&gt;If you just want to run part the services and software_licenses role then you can use:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ansible-playbook -i inventories/ficrawler3 playbook_crawler.yml --tags=&quot;software_licenses, services&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here’s the output from running just the services role on a single one of my boxes:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ansible-playbook -i inventories/ficrawler3 playbook_crawler.yml --tags=&quot;services&quot;

[DEPRECATION WARNING]: Instead of sudo/sudo_user, use become/become_user and make sure become_method is 'sudo' (default).
This feature will be removed in a future release. Deprecation warnings can be
disabled by setting deprecation_warnings=False in ansible.cfg.

PLAY [crawler, ansibletest] ****************************************************

TASK [setup] *******************************************************************
ok: [ficrawler3]

TASK [services : stop_sendmail] ************************************************
ok: [ficrawler3]

TASK [services : stop_apache2] *************************************************
ok: [ficrawler3]

TASK [services : stop_memcached] ***********************************************
ok: [ficrawler3]

TASK [services : prevent sidekiq init from running if it has already been done]
ok: [ficrawler3]

TASK [services : Copy sidekiq init template to init.d dir] *********************
skipping: [ficrawler3]

TASK [services : start_sidekiq] ************************************************
changed: [ficrawler3]

PLAY RECAP *********************************************************************
ficrawler3                 : ok=6    changed=1    unreachable=0    failed=0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Your results may differ a bit but it should be similar to that.&lt;/p&gt;

&lt;h1 id=&quot;log-file&quot;&gt;Log File&lt;/h1&gt;

&lt;p&gt;It is always terribly important with long running processes to know where their log file goes.  In this case it is located at:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/var/log/upstart/sidekiq_0.log  
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;I’ll return to that in a later Ansible tutorial when I configure cross server log management with Graylog.  For my work, sidekiq logs are critical so I added a bash command to the shells on all my boxes so I can tail them easily.  All it takes is to drop alias tailsidekiq=’tail -f /var/log/upstart/sidekiq_0.log’ into the .bashrc on all your boxes.&lt;/p&gt;

&lt;p&gt;And, yes, I’m am showing off here.  This points out just how awesome automatically provisioning your boxes with ansible is.  When you can make changes across a farm of boxes with a single command, you can apply the same types of refactoring / continuous improvement that you do with code to devops.  In years past if I wanted this I’d have had to do it manually.  Now its a change to a template file and running an ansible playbook.  Tomorrow I’ll likely pipe all log files over the network to Graylog but until then I have my tailsidekiq command.&lt;/p&gt;

&lt;h1 id=&quot;sidebar-why-use-rvm-with-a-single-ruby&quot;&gt;Sidebar: Why Use RVM With a Single Ruby?&lt;/h1&gt;

&lt;p&gt;I know someone’s going to ask this so I may as well answer it.  RVM is the easiest way, that I’ve found, to get Ruby installed anywhere.  Even with a single Ruby, RVM makes getting it installed better.&lt;/p&gt;
</description>
        <pubDate>Thu, 13 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/ansible/2016/10/13/ansible-tutorial-02-configuring-a-sidekiq-upstart-job-on-ubuntu-14-04.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/ansible/2016/10/13/ansible-tutorial-02-configuring-a-sidekiq-upstart-job-on-ubuntu-14-04.html</guid>
        
        <category>ansible</category>
        
        <category>sidekiq</category>
        
        <category>ruby</category>
        
        <category>rvm</category>
        
        
        <category>ansible</category>
        
      </item>
    
  </channel>
</rss>
