<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>FuzzyBlog</title>
    <description>Scott Johnson writing about the usual array of nerd stuff: AWS / Ansible / Ruby / Rails / Elixir / Misc.
</description>
    <link>https://fuzzygroup.github.io/blog/</link>
    <atom:link href="https://fuzzygroup.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 06 Jan 2017 06:15:14 -0500</pubDate>
    <lastBuildDate>Fri, 06 Jan 2017 06:15:14 -0500</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>Hyde Feature Overview 01 - Check for Broken Links aka The Nick Feature</title>
        <description>&lt;p&gt;I’m currently programming what in my head will always be known as &lt;em&gt;The Nick Feature&lt;/em&gt;.  &lt;a href=&quot;http://nickjanetkis.com&quot;&gt;Nick&lt;/a&gt; is a buddy of mine and a regular pair programming partner. Together he and I have wrestled to the ground a number of Ansible powered dragons, dynamically build tens upon tens of AWS instances and other various and sundry nerd tasks.&lt;/p&gt;

&lt;p&gt;In the way that nerds often do, we chat about things as we go about the day and one day he asked me about programmatically checking his blog for broken links.  As questions like this always do, it made me think.  Several hours later I spun up a small test project and starting playing with that in the context of both his blog and mine.&lt;/p&gt;

&lt;p&gt;Broken links share a particular fascination for me because in my first hypertext authoring tool, Black Magic, we didn’t allow them.  Our underlying engine made it very, very hard for dangling links to exist.  You could do it but you did it by moving a file outside the environment.  It wasn’t until the world wide web came along that I ran into the problem of broken links in the wild.  And like everyone else in the web tools 1.0 world I solved this problem with perl scripts and other first generation automation tools.  But I haven’t ever forgotten the elegant architecture for broken links that my first partner, Brian Giedt, created.&lt;/p&gt;

&lt;p&gt;As I looked at Nick’s blog and then my own I realized that broken links actually are only really a problem in a certain context. Given that the Internet is constantly changing, broken links are just an inevitability – they will happen.  And, honestly, trying to fix them after a certain point in time is likely not possible.  Additionally things like server side mod_rewrite rules mean that links may break and proper 404s may never be returned to you. Finally just knowing the original destination of a link often is enough.  There is, after all, &lt;a href=&quot;http://www.archive.org&quot;&gt;archive.org&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So if there are contexts where you don’t worry about broken links, is there a context where you &lt;strong&gt;do&lt;/strong&gt; worry about them.  The answer is absolutely YES – you worry about broken links when the content item is newly created.  And that’s why one of the very first features I’ve written into Hyde is just that – it takes a newly created post and makes sure that all of the links in it actually exist.  It is executed every time a post changes.&lt;/p&gt;

&lt;p&gt;Thanks Nick!&lt;/p&gt;

&lt;h1 id=&quot;technical-notes&quot;&gt;Technical Notes&lt;/h1&gt;

&lt;p&gt;Given that Nick, a very experienced software engineer, was asking me how to tackle this I thought it might be worth discussing how to implement something like this.&lt;/p&gt;

&lt;p&gt;result = HTTPClient.head(“http://www.scripting.com/fooddfdfdfdfd”)
 =&amp;gt; #&amp;lt;HTTP::Message:0x007feaf8454558 @http_header=#&amp;lt;HTTP::Message::Headers:0x007feaf8454508 @http_version=”1.1”, @body_size=0, @chunked=false, @request_method=”HEAD”, @request_uri=#&amp;lt;Addressable::URI:0x3ff57c22aa90 URI:http://www.scripting.com/fooddfdfdfdfd&amp;gt;, @request_query=nil, @request_absolute_uri=nil, @status_code=301, @reason_phrase=”Moved Permanently”, @body_type=nil, @body_charset=nil, @body_date=nil, @body_encoding=nil, @is_request=false, @header_item=[[“x-amz-id-2”, “GzHUJzCkS3rqbqEBuWdGD2V9cApmMZX7SKUV8Xc9WT/ECKz9glwtBpK6x65rnDdsyjqrP1ITrv4=”], [“x-amz-request-id”, “00986197CE6075E4”], [“Date”, “Fri, 06 Jan 2017 09:08:05 GMT”], [“Location”, “http://scripting.com/fooddfdfdfdfd”], [“Content-Length”, “0”], [“Server”, “AmazonS3”]], @dumped=false&amp;gt;, @peer_cert=nil, @http_body=#&amp;lt;HTTP::Message::Body:0x007feaf8454490 @body=””, @size=0, @positions=nil, @chunk_size=nil&amp;gt;, @previous=nil&amp;gt;
2.3.1 :007 &amp;gt; result = HTTPClient.head(“http://www.google.com/fooddfdfdfdfd”)
 =&amp;gt; #&amp;lt;HTTP::Message:0x007feaf842e5b0 @http_header=#&amp;lt;HTTP::Message::Headers:0x007feaf842e560 @http_version=”1.1”, @body_size=0, @chunked=false, @request_method=”HEAD”, @request_uri=#&amp;lt;Addressable::URI:0x3ff57c217bd4 URI:http://www.google.com/fooddfdfdfdfd&amp;gt;, @request_query=nil, @request_absolute_uri=nil, @status_code=404, @reason_phrase=”Not Found”, @body_type=nil, @body_charset=nil, @body_date=nil, @body_encoding=#&lt;Encoding:UTF-8&gt;, @is_request=false, @header_item=[[&quot;Content-Type&quot;, &quot;text/html; charset=UTF-8&quot;], [&quot;Content-Length&quot;, &quot;1574&quot;], [&quot;Date&quot;, &quot;Fri, 06 Jan 2017 09:08:22 GMT&quot;]], @dumped=false&amp;gt;, @peer_cert=nil, @http_body=#&amp;lt;HTTP::Message::Body:0x007feaf842e420 @body=&quot;&quot;, @size=0, @positions=nil, @chunk_size=nil&amp;gt;, @previous=nil&amp;gt;&lt;/Encoding:UTF-8&gt;&lt;/p&gt;

</description>
        <pubDate>Fri, 06 Jan 2017 04:10:32 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/2017/01/06/hyde-feature-overview-01-check-for-broken-links-aka-the-nick-feature.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/2017/01/06/hyde-feature-overview-01-check-for-broken-links-aka-the-nick-feature.html</guid>
        
        
      </item>
    
      <item>
        <title>How Tech Companies Can Easily Create Jobs</title>
        <description>&lt;p&gt;A few days ago Ross Mayfield wrote an absolutely compelling piece about jobs, tech companies and the original &lt;a href=&quot;https://en.wikipedia.org/wiki/Luddite&quot;&gt;Luddite movement&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;50% of the jobs will be gone in ~20 years. Not from the great sucking sound of jobs to Mexico that can be stopped with a wall. Not from moving offshore to China. From automation that is moving quickly from blue collar manufacturing to white collar information work. Second only to climate change, this is the greatest disruption of our time, and I don’t mean that word in a good way. &lt;a href=&quot;https://shift.newco.co/the-coming-tech-backlash-82b22e0c1198&quot;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Years and years ago I actually knew Ross on a fairly good level and Ross is &lt;strong&gt;smart&lt;/strong&gt;.  He’s also not wrong about what tech companies are doing to the economy.  While I don’t think the trends are as dire as he says, there is a real wild card and that’s self driving technology that actually works.&lt;/p&gt;

&lt;p&gt;If self driving technology works then we can easily see things like:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Massive disruption of the trucking industry; &lt;a href=&quot;http://www.marketwatch.com/story/keep-on-truckin-in-a-majority-of-states-its-the-most-popular-job-2015-02-09&quot;&gt;America’s Number One Job&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;A move away from personal vehicle ownership towards transportation as a service and that in turn will nuke the car dealership and car repair industries, car detailing, etc.&lt;/li&gt;
  &lt;li&gt;This will absolutely devalue the car that you own today so it affects you in &lt;strong&gt;your&lt;/strong&gt; pocketbook.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But self driving technology is a wild card and I’m less certain about it getting to the fully automated level than a lot of analysts.  We’ve all heard the statement that the last 5% of an engineering project can be as hard as the rest and we’re not even at the 95% level yet.  So while self driving technology will get here, it is very unclear to me if it is 2020 or 2040.&lt;/p&gt;

&lt;p&gt;Now, that said, I don’t think that most people would dispute that we have a jobs issue at present.  There are definitely ways that tech companies can actually create jobs and do it fairly easily:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Actually hire support workers&lt;/li&gt;
  &lt;li&gt;Avoid big acquisitions&lt;/li&gt;
  &lt;li&gt;Reduce hours&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Each of these is covered below.  None of these will be popular with tech companies because they do affect the bottom line.  But if we don’t affect our own bottom line then the government or the people will do it for us – and that’s always worse.&lt;/p&gt;

&lt;h1 id=&quot;actually-hire-support-workers&quot;&gt;Actually Hire Support Workers&lt;/h1&gt;

&lt;p&gt;I do not think that I am the only person who has realized that it is utterly unacceptable that you can never reach technical support at most of the leading tech companies – Google, Facebook, PayPal, etc.  There is always some kind of problem that only a human can resolve.  The high tech industry used to understand this and understand it well.  I came of age in this field when &lt;a href=&quot;https://en.wikipedia.org/wiki/WordPerfect&quot;&gt;WordPerfect&lt;/a&gt; still ruled the desktop for word processing and WordPerfect had a near legendary approach to support that actually helped build its business.&lt;/p&gt;

&lt;p&gt;It certainly feels to me like the big tech companies could actually afford to hire support workers; none of these companies lack for profits.  And the world isn’t the 1980s anymore.  You don’t even have to staff a giant call center with full time workers – this could all be done with a distributed work force that works from home on a part time basis to avoid the health care costs.  And perhaps these aren’t great jobs but they are still jobs and that’s what we are currently lacking.&lt;/p&gt;

&lt;h1 id=&quot;avoid-big-acquisitions&quot;&gt;Avoid Big Acquisitions&lt;/h1&gt;

&lt;p&gt;Big acquisitions are often predicated on the concept that if you put two companies together you can increase profits by reducing common overhead.  For example you don’t actually need two accounting departments.  And while not everyone in one of the accounting departments is let go, a substantial portion of them generally are.  Multiply that across the span of acquisition activity that seems to happen across the high tech industry in general and you have a lot of lost jobs.&lt;/p&gt;

&lt;p&gt;Please note that I do actually recognize that this is a simplistic argument and there are lots and lots of reasons for acquisitions but large acquisitions generally seem to lead to net job losses.&lt;/p&gt;

&lt;h1 id=&quot;reduce-hours&quot;&gt;Reduce Hours&lt;/h1&gt;

&lt;p&gt;The concept of the 8 hour work day, 40 hour work week is fairly engrained in our culture but things weren’t always this way.  The 8 hour work day originated as a political movement globally against employer abuses of workers and then became, in the U.S., part of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Eight-hour_day#North_America&quot;&gt;Fair Labor Standards Act under Roosevelt’s New Deal&lt;/a&gt;. But is an 8 hour work day the only way that work can be done?  Could, for example, a company move to a 6 hour work day?  Or perhaps just move away from people working the 10 to 14 hour days that are oh so common to the high tech world?&lt;/p&gt;

&lt;p&gt;I’d be really, really curious to know if a company formally moving to a six hour day resulted in hiring more staff or people simply being more efficient so they could enjoy those two extra hours they get back to their own life.&lt;/p&gt;

&lt;p&gt;There’s substantial economic research that people lose effectiveness beyond the 8 hour day anyway.  Some of those studies can be found &lt;a href=&quot;https://hn.algolia.com/?query=8%20hour%20day&amp;amp;sort=byPopularity&amp;amp;prefix&amp;amp;page=0&amp;amp;dateRange=all&amp;amp;type=story&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Side Thought&lt;/strong&gt;: Given all the problems that we see in tech recruiting, I wonder what the impact would be on a company if they announced “We actually work a six hour day”.  Might that be a compelling pitch to job candidates?&lt;/p&gt;
</description>
        <pubDate>Fri, 06 Jan 2017 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/startup/2017/01/06/how-tech-companies-can-easily-create-jobs.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/startup/2017/01/06/how-tech-companies-can-easily-create-jobs.html</guid>
        
        <category>jobs</category>
        
        <category>economy</category>
        
        
        <category>startup</category>
        
      </item>
    
      <item>
        <title>When RSpec Just Won't Install</title>
        <description>&lt;p&gt;git commit -m “Myriad gyrations to do nothing more than get rspec installed; curse you bundler”&lt;/p&gt;

</description>
        <pubDate>Thu, 05 Jan 2017 10:13:51 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/2017/01/05/when-rspec-just-won-t-install.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/2017/01/05/when-rspec-just-won-t-install.html</guid>
        
        
      </item>
    
      <item>
        <title>Scott's Rule of API Development</title>
        <description>&lt;p&gt;So on Tuesday I wrote a new api that allows an &lt;a href=&quot;https://www.ansible.com/&quot;&gt;Ansible&lt;/a&gt; playbook to register an AWS instance with an internal service I’m writing.  This is for the purpose of monitoring large jobs (think tens if not hundreds of lightweight EC2 instances) so that they can be shut down programmatically when they are done.&lt;/p&gt;

&lt;p&gt;In some kind of alternate universe I’d just do all this with &lt;a href=&quot;https://aws.amazon.com/lambda/&quot;&gt;AWS Lambda&lt;/a&gt; but I’m working in a monolithic rails code base so I used my &lt;a href=&quot;https://fuzzygroup.github.io/blog/rails/2017/01/03/processing-large-datasets-on-aws-using-ruby-rails-and-sidekiq.html&quot;&gt;Large Datasets approach&lt;/a&gt; I documented earlier this week.&lt;/p&gt;

&lt;p&gt;My ansible playbook creates the EC2 instances, binds the whole process together and initiates everything – I can literally run one playbook and have 40 workers (or really N workers) created and an entire data set start processing along with getting an internal record of all the instances and the job so that I can do proper cost accounting, dynamic instance shut down and the whole nine yards.  This is a big step for me.  I am getting close to a technical goal that I’ve been working towards either for six months or about 7 years depending on how you measure it.&lt;/p&gt;

&lt;p&gt;So &lt;a href=&quot;http://nickjanetaks.com/&quot;&gt;Nick&lt;/a&gt; and I did all this fancy, fancy EC2 automation – AMI creation, instance creation, job launching – and the thing that &lt;strong&gt;&lt;em&gt;failed&lt;/em&gt;&lt;/strong&gt; was a simple &lt;em&gt;http post API&lt;/em&gt; call using the &lt;a href=&quot;http://docs.ansible.com/ansible/uri_module.html&quot;&gt;Ansible URI module&lt;/a&gt;.  Like everyone else in the industry I’ve written a post API, I don’t know – 50 times? 100 times? — and they always fail the first time.  And this brings me to what I’m going to immodestly call Scott’s Rule of API Development:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Scott’s Rule of API Development&lt;/strong&gt;.  Always, always, always test your APIs with &lt;a href=&quot;https://curl.haxx.se/&quot;&gt;curl&lt;/a&gt; from an external box before you actually try and use them.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Seriously – I hit this problem six months ago at &lt;a href=&quot;http://www.therachat.io&quot;&gt;TheraChat&lt;/a&gt; when I wrote their MVP.  I hit it yesterday.  I seemingly hit it every single damn time I make an API.  Hence Scott’s Rule of API Development.  Now, that said, what does using curl to test an api actually mean / how do you do it:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Create your API.&lt;/li&gt;
  &lt;li&gt;Write your curl statement. Here’s a sample which I used once upon a time for an authorization API (the -d tells curl to post it): &lt;em&gt;curl -i -d “api_key=forceawakens13928534aY&amp;amp;&amp;amp;mobile_number=317-531-4853&amp;amp;password=BLAH” “http://app.foo.com/api/authorize”&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Test it locally against your development system.  Fix any bugs.  Lather / Rinse / Repeat.&lt;/li&gt;
  &lt;li&gt;Deploy your code.&lt;/li&gt;
  &lt;li&gt;Run it on another box that isn’t your actual API to make sure that there are no security glitches / remote code issues / etc.&lt;/li&gt;
  &lt;li&gt;If this API is part of a full stack Rails app then don’t forget to disable forgery protection in Application Controller with &lt;em&gt;protect_from_forgery with: :null_session&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;For bonus points store the curl commands that exercise your API as part of your code base and always try them before a release.  APIs can be tricky little buggers and they are both difficult to get and seem to break easily.  Regularly testing with curl prevents that and makes users of your API much, much happier.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Yes test coverage should prevent what’s described in #7 but I’d strongly recommend belt and suspenders on this one.  When the people who rely on your API have issues you can always give them a curl statement and say “Well this works for me – what about you”.  You can’t do that we test coverage as APIs are often used from a variety of languages and environments but curl is absolutely &lt;strong&gt;universal&lt;/strong&gt;.&lt;/p&gt;
</description>
        <pubDate>Thu, 05 Jan 2017 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/software_engineering/2017/01/05/scott-s-rule-of-api-development.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/software_engineering/2017/01/05/scott-s-rule-of-api-development.html</guid>
        
        <category>software_engineering</category>
        
        <category>api</category>
        
        <category>curl</category>
        
        <category>ansible</category>
        
        <category>aws</category>
        
        <category>rails</category>
        
        
        <category>software_engineering</category>
        
      </item>
    
      <item>
        <title>Returning to RSS Programming After 14 Years</title>
        <description>&lt;p&gt;There is a very odd, very good feeling when you as a programmer return to some technical task that you used to do – and you find that you do it &lt;strong&gt;better&lt;/strong&gt;. For myself I am once again dabbling in RSS programming and it feels &lt;strong&gt;great&lt;/strong&gt;.  It was almost 14 years ago to the day that I started Feedster based on an idea that &lt;a href=&quot;http://scripting.com/2003/03/09.html&quot;&gt;Dave&lt;/a&gt; put out there by linking to an idea that Dave Aiello  had.&lt;/p&gt;

&lt;p&gt;That one tiny mention on &lt;a href=&quot;http://www.scripting.com/&quot;&gt;Scripting.com&lt;/a&gt; inspired me to hack together a truly awful RSS search engine that in turn survived a slashdotting and then picked up a co-founder, a CEO, angel investment, a move to San Francisco, real venture funding and actual staff.&lt;/p&gt;

&lt;p&gt;It was, I believe, March of 2003 on a snowy night and now in January 2017 on another snowy night I am again writing feed processing code.&lt;/p&gt;

&lt;p&gt;The technically interesting part here is that the operations I did poorly back in 2003 are now flowing and gracefully from my fingers as I work.  Specifically I used to monitor feeds by doing a full fetch and then hashing the body with MD5 and comparing it to a stored value from the last time.  This time I &lt;em&gt;knew&lt;/em&gt; “Ok.  Do an HTTP head and look at just the header values”.  Additionally I am using a far better toolset in 2017 (ruby / rails / elixir / phoenix) than I ever did back in 2003 (php).&lt;/p&gt;

&lt;p&gt;If as an engineer you’ve never returned to a problem space after a long interval, I’d recommend it.  Just seeing how you tackle the same problem after a long break certainly makes you think.&lt;/p&gt;
</description>
        <pubDate>Thu, 05 Jan 2017 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/startup/2017/01/05/returning-to-rss-programming-after-14-years.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/startup/2017/01/05/returning-to-rss-programming-after-14-years.html</guid>
        
        <category>hyde</category>
        
        <category>rss</category>
        
        <category>rails</category>
        
        <category>startup</category>
        
        <category>software_engineering</category>
        
        
        <category>startup</category>
        
      </item>
    
      <item>
        <title></title>
        <description>&lt;p&gt;The classical Rails architectural pattern is the &lt;em&gt;monolith&lt;/em&gt; – a giant application that encompasses all parts of your codebase. You know it, I know it, we all know it and all &lt;strong&gt;too well&lt;/strong&gt;.  Even though we all talk about micro services, Rails itself seems almost designed to prevent that architectural pattern.  You know what I’m talking about – you start by building a web app in Rails. Then you need an API so you quickly make an API controller within the same application.  Then you need an admin tool and sooner or later you end up with numbers like these:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;+----------------------+-------+-------+---------+---------+-----+-------+
| Name                 | Lines |   LOC | Classes | Methods | M/C | LOC/M |
+----------------------+-------+-------+---------+---------+-----+-------+
| Controllers          | 36621 | 24073 |     147 |    1297 |   8 |    16 |
| Helpers              |  6688 |  5212 |       1 |     393 | 393 |    11 |
| Models               | 153716 | 81985 |    1446 |    9737 |   6 |     6 |
| Mailers              |     0 |     0 |       0 |       0 |   0 |     0 |
| Javascripts          | 25828 | 16579 |       0 |    1993 |   0 |     6 |
| Libraries            | 60197 | 36648 |     189 |    1571 |   8 |    21 |
| Integration tests    |    75 |    59 |       1 |       1 |   1 |    57 |
| Controller specs     | 18848 | 11227 |       0 |       0 |   0 |     0 |
| Feature specs        |  4239 |   529 |       0 |       0 |   0 |     0 |
| Helper specs         |  2366 |  1388 |       0 |       0 |   0 |     0 |
| Lib specs            |  4162 |  2948 |       0 |       0 |   0 |     0 |
| Model specs          | 54256 | 37837 |       0 |       3 |   0 | 12610 |
| View specs           |   534 |   320 |       0 |       2 |   0 |   158 |
+----------------------+-------+-------+---------+---------+-----+-------+
| Total                | 367530 | 218805 |    1784 |   14997 |   8 |    12 |
+----------------------+-------+-------+---------+---------+-----+-------+
  Code LOC: 164497     Test LOC: 54308     Code to Test Ratio: 1:0.3
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;That’s from one of my production applications – it has &lt;strong&gt;everything&lt;/strong&gt; and it is an absolute nightmare to maintain.  Yes it is terribly convenient to have a monolith but the number of potential interactions between different parts of the system are monstrous and just the time to launch Rails console is now approaching a full minute.&lt;/p&gt;

&lt;p&gt;So if a monolith has all these issues, why do we do it?  Well the answer really comes down to code re-use and code management.  Let’s consider, for example, what happens when you want to add a user api onto an existing application.  To start you probably want to use the new Rails 5 API mode.&lt;/p&gt;

&lt;p&gt;Thank about the task of building an API for your Rails application.  While Rails 5 offers the &lt;strong&gt;wonderful&lt;/strong&gt; new API mode, it is a &lt;em&gt;mode&lt;/em&gt; and it cannot be used as part of a full stack Rails application.&lt;/p&gt;

&lt;p&gt;rake task for copying in validations&lt;/p&gt;

&lt;p&gt;http://stackoverflow.com/questions/11372484/rails-put-validation-in-a-module-mixin&lt;/p&gt;

&lt;p&gt;require ‘api_key_validations’
  include ApiKeyValidations&lt;/p&gt;

&lt;p&gt;module ApiKeyValidations
  extend ActiveSupport::Concern&lt;/p&gt;

&lt;p&gt;included do
    validates_presence_of :name
    validates_presence_of :user
    #validates :name, :length =&amp;gt; { :minimum =&amp;gt; 2 }, :presence =&amp;gt; true, :uniqueness =&amp;gt; true
    #validates :name_seo, :length =&amp;gt; { :minimum =&amp;gt; 2 }, :presence =&amp;gt; true, :uniqueness =&amp;gt; true
  end
end&lt;/p&gt;
</description>
        <pubDate>Wed, 04 Jan 2017 22:15:19 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/2017/01/04/breaking-the-rails-monolith-apart-01-validations.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/2017/01/04/breaking-the-rails-monolith-apart-01-validations.html</guid>
        
        
      </item>
    
      <item>
        <title>Getting Started with MongoDB and Rails</title>
        <description>&lt;p&gt;I am a well known MySQL fan if not fanatic.  I’ve used MySQL since 1999 and while I’ve had the occasional issue here and there, I’ve been immensely happy with it overall.  But times change and now I find myself using Mongo in the context of a Rails app and, well, I’m a bit lost.  This post writes down what I’ve learned – mostly about the operational side of Mongo and getting started.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Assumptions&lt;/strong&gt;: Rails 5 / Ruby 2.3 / Mongo 3.4 / OSX; currently building a rails application called &lt;strong&gt;api&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;the-error-message&quot;&gt;The Error Message&lt;/h1&gt;

&lt;p&gt;What drove me into writing all of this down was I kept hitting this error message:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Mongoid::Errors::NoClientConfig: message:   No configuration could be found for a client named 'default'.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;useful-reading&quot;&gt;Useful Reading:&lt;/h1&gt;

&lt;p&gt;I read a number of things including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://gorails.com/guides/setting-up-rails-4-with-mongodb-and-mongoid&quot;&gt;GoRails&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.tutorialspoint.com/mongodb/mongodb_create_database.htm&quot;&gt;TutorialsPoint&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/15354936/rails-engine-mongoid-no-configuration-could-be-found-for-a-session-named-def&quot;&gt;StackOverflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;installation&quot;&gt;Installation&lt;/h1&gt;

&lt;p&gt;I used HomeBrew to install Mongo:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;brew install mongodb
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;getting-into-the-shell&quot;&gt;Getting into the Shell&lt;/h1&gt;

&lt;p&gt;After Mongo is installed you can get into the Mongo shell with the command:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mongo
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;creating-your-first-database&quot;&gt;Creating Your First Database&lt;/h1&gt;

&lt;p&gt;Oddly the use command creates the database.  If the database doesn’t exist then it is automatically created:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;use api_development ENTER
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;making-mongo-work-under-rails&quot;&gt;Making Mongo Work Under Rails&lt;/h1&gt;

&lt;p&gt;Getting to this stage wasn’t all that hard.  The problem here is that I’ve never setup a new rails app from scratch with Mongo.  I’ve worked on Mongo stuff in the past but this was an entirely new thing. Here were the steps I followed.&lt;/p&gt;

&lt;h2 id=&quot;getting-rid-of-activerecord-in-your-application&quot;&gt;Getting Rid of ActiveRecord in Your Application&lt;/h2&gt;

&lt;p&gt;When you create your rails app, you need to add the –skip-active-record flag to turn off ActiveRecord entirely:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rails new api --skip-active-record --api
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Note: This is an api mode Rails application so I’m passing in –api.&lt;/p&gt;

&lt;h2 id=&quot;creating-the-mongoidyml-file&quot;&gt;Creating the mongoid.yml File&lt;/h2&gt;

&lt;p&gt;rails g mongoid:config&lt;/p&gt;

&lt;h2 id=&quot;getting-mongoidyml-loaded&quot;&gt;Getting mongoid.yml Loaded&lt;/h2&gt;

&lt;p&gt;touch config/initializers/mongo.yml&lt;/p&gt;
</description>
        <pubDate>Wed, 04 Jan 2017 06:44:54 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/rails/2017/01/04/getting-started-with-mongodb-and-rails.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/rails/2017/01/04/getting-started-with-mongodb-and-rails.html</guid>
        
        <category>rails</category>
        
        <category>mongo</category>
        
        
        <category>rails</category>
        
      </item>
    
      <item>
        <title>On the Changes at Medium</title>
        <description>&lt;p&gt;So Ev has just announced major layoffs at Medium:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I’ll start with the hard part: As of today, we are reducing our team by about one third — eliminating 50 jobs, mostly in sales, support, and other business functions. We are also changing our business model to more directly drive the mission we set out on originally. &lt;a href=&quot;https://blog.medium.com/renewing-mediums-focus-98f374a960be#.kh7coodv8&quot;&gt;Renewing Medium&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As someone who, on a vastly smaller scale, has been through this type of thing, I have nothing but sympathy for Ev.  Even when you are as monstrously successful as Ev (Blogger, Odeo, Twitter), layoffs always hurt.  You never hire people thinking that you are going to have to fire them.  You always hope that the people you hire will hire more people and so on.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://news.ycombinator.com/item?id=13321322&quot;&gt;Hacker News discussion&lt;/a&gt; on it has the normal nay sayers and people saying “But it is just a blogging platform”.  And, yes, Medium is a blogging platform but it is operating on a scale which is very, very hard to achieve.  The really interesting there is from the post by MG Siegler:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The numbers speak for themselves. 2 billion words written on Medium in the last year. 7.5 million posts during that time. 60 million monthly readers now.  &lt;a href=&quot;https://500ish.com/long-medium-b9ddfe2c3a0a#.wh8tzerfo&quot;&gt;Long Medium&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Wow.  I had no idea that Medium was on that type of growth curve.  That is flat out astonishing.  When you consider the scaling issues at that type of size with the rich user interface that Medium offers and the integrated analytics, aggregation and notification, yes, I can see why they raised the amount of funding that they have.&lt;/p&gt;

&lt;p&gt;Now, that said, it does seem that they overstaffed at the business level.  And it seems that those are the positions being scrapped.  Interestingly at least some of the staff seem to be dealing with this well:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Newly ex-Median here. This was not a huge surprise. On the surface, this is a change in product strategy. The underlying story is the company positioning itself so it can survive an adverse environment if it needs to. It’s hard to fault managers for dealing with that potential (and its hard to deny that the next 2-4 years could be really bad). Hopefully not, but it would be malpractice not to prepare. So better to focus resources now than be walking dead in a year or so, jettison unnecessary products/projects, and hope for the best. It’s a great product, and with time and luck, they’ll sort out a good business model, but like the rest of the publishing world, they’re still sorting things out. Despite being one of those made redundant, I enjoyed being there, and wish them the best. On that note, you should ask yourself if you are prepared for winter, because winter is coming. &lt;a href=&quot;https://news.ycombinator.com/item?id=13322380&quot;&gt;Permalink&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Wed, 04 Jan 2017 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/medium/2017/01/04/on-the-changes-at-medium.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/medium/2017/01/04/on-the-changes-at-medium.html</guid>
        
        <category>medium</category>
        
        <category>blogging</category>
        
        <category>startup</category>
        
        
        <category>medium</category>
        
      </item>
    
      <item>
        <title>Capistrano Failure - Asset Manifest Not Created</title>
        <description>&lt;p&gt;I setup a new Rails application using Capistrano earlier today and hit a fair number of odder than normal &lt;a href=&quot;http://capistranorb.com/&quot;&gt;Capistrano&lt;/a&gt; issues.  The biggest issue was around the asset pipeline and the asset manifest not being created.  The error message revolved around “cannot stat (pathname) manifest file”.&lt;/p&gt;

&lt;p&gt;Digging into the issue with Google revealed that it actually is a problem with Capistrano itself.  Here’s the &lt;a href=&quot;https://github.com/capistrano/rails/issues/111&quot;&gt;thread&lt;/a&gt;.  Upgrading to at least Capistrano 1.1.8 fixes this problem.&lt;/p&gt;
</description>
        <pubDate>Wed, 04 Jan 2017 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/rails/2017/01/04/capistrano-failure-asset-manifest-not-created.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/rails/2017/01/04/capistrano-failure-asset-manifest-not-created.html</guid>
        
        <category>rails</category>
        
        <category>capistrano</category>
        
        <category>asset_pipeline</category>
        
        
        <category>rails</category>
        
      </item>
    
      <item>
        <title>Ansible Unable to Find Boto Errors</title>
        <description>&lt;p&gt;Over the past several days I have been doing quite a bit of work with the ansible &lt;a href=&quot;http://docs.ansible.com/ansible/ec2_module.html&quot;&gt;EC2&lt;/a&gt; and &lt;a href=&quot;http://docs.ansible.com/ansible/ec2_ami_module.html&quot;&gt;AMI&lt;/a&gt; modules for dynamically creating instances and AMIs on AWS.  Ansible, however, doesn’t actually talk directly to AWS; it talks to AWS thru a python module named &lt;a href=&quot;https://github.com/boto/boto&quot;&gt;&lt;strong&gt;boto&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;There are a number of common problems that you might find when you the error “boto required for this module” or “unable to find boto”:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Make sure boto is installed: &lt;em&gt;sudo pip install boto&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Uninstall ansible entirely and then install it via Python: &lt;em&gt;sudo pip install ansible&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Run your playbook using sudo to ensure that the version of python is the one that comes from sudo&lt;/li&gt;
  &lt;li&gt;Eliminate &lt;em&gt;connection: local&lt;/em&gt; at the playbook level and move it to the task level&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you uninstall Ansible using HomeBrew or apt-get, you may find that your Galaxy roles have been uninstalled.  This can very badly impact your playbook execution so be careful.  If you want to avoid this then use the -p option when you install a role to specify that the role goes into a local directory of your choosing; &lt;a href=&quot;http://stackoverflow.com/questions/22201306/ansible-galaxy-roles-install-in-to-a-specific-directory&quot;&gt;Stack Overflow Explanation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The last one of these, eliminating connection: local, requires a bit of explaining.  Details can be found &lt;a href=&quot;https://github.com/ansible/ansible/issues/15019&quot;&gt;here&lt;/a&gt;.  When I first encountered this problem, my playbook looked like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- hosts: &quot;fi_app_metadata_monthly&quot;
  become: yes
  remote_user: ubuntu
  connection: local
  vars:
    - redis_ami_id: &quot;ami-XXXX&quot;
    - redis_security_group_id: &quot;sg-YYY&quot;
    - redis_instance_type: &quot;t2.micro&quot;
    - redis_tag_name: &quot;dynamic_redis_fi_app_metadata_update&quot;
    - redis_instance_count: 1
    - template_instance_id: &quot;i-UUUUUUUU&quot; # in future this comes in from command line
    - number_of_instances: 3                      
    - instance_type: &quot;m3.large&quot;                   
    - region: &quot;us-west-2&quot;
    - vpc_subnet_id: &quot;subnet-IIIIII&quot;
    - vpc_id: &quot;vpc-RRRR&quot;
    - group_id: &quot;sg-YYYY&quot;
    - aws_access_key: &quot;ERRERERE&quot;
    - key_name: &quot;appdata_aws&quot;
    - aws_secret_key: &quot;ERERERE&quot;
    - farm_job_name: &quot;monthly_fi_app_metadata_update_2017-01&quot;
    - farmer_address: &quot;ec2-9-9-9-9.us-west-2.compute.amazonaws.com&quot;
    - tag_name: &quot;fi_app_metadata&quot;
    - rake_task: &quot;bundle exec rake fi_farm_work:fi_app_metadata_update --trace&quot;
  roles:
    - { role: ec2_make_redis_instance_from_ami, tags: ec2_make_redis_instance_from_ami}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;When the above playbook was run, it resulted in boto not being found errors.  The solution was to remove the line &lt;em&gt;connection: local&lt;/em&gt; from the playbook and move it to the task level:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- name: make the redis instance from the ami
  # note - you used to be able to do this at the role level; now it has to be at the task level
  # note - think of this as you are setting the connection context for the task being executed
  connection: local
  ec2:
    aws_access_key: &quot;&quot;
    aws_secret_key: &quot;&quot;
    region: &quot;&quot;
    image: &quot;&quot;
    ...
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This is one of those code errors that, honestly, I just don’t understand.  From talking with another Ansible buddy, &lt;a href=&quot;https://nickjanetakis.com/&quot;&gt;Nick&lt;/a&gt;, he confirmed that it used to work at the playbook level.  Perhaps this is just one of those perplexing changes that results from other other architectural work going on at the project level.&lt;/p&gt;
</description>
        <pubDate>Wed, 04 Jan 2017 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/ansible/2017/01/04/ansible-unable-to-find-boto-errors.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/ansible/2017/01/04/ansible-unable-to-find-boto-errors.html</guid>
        
        <category>ansible</category>
        
        <category>boto</category>
        
        <category>aws</category>
        
        
        <category>ansible</category>
        
      </item>
    
  </channel>
</rss>
