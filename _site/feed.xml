<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>FuzzyBlog</title>
    <description>Scott Johnson writing about the usual array of nerd stuff: AWS / Ansible / Ruby / Rails / Elixir / Misc / Hyde.
</description>
    <link>http://fuzzyblog.io//blog/</link>
    <atom:link href="http://fuzzyblog.io//blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 27 Feb 2017 19:48:58 -0500</pubDate>
    <lastBuildDate>Mon, 27 Feb 2017 19:48:58 -0500</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>Working with the Gem Ecosystem Part 2 - Updating Gems and Writing Generators</title>
        <description>&lt;p&gt;In case you haven’t figured out yet that I write stuff here as much for myself as for anyone else, well, its true.  Almost every single day I find myself going back to my own blog as a reference tool.  Today I’m writing a part two to my &lt;a href=&quot;http://fuzzyblog.io/blog/ruby/2016/08/17/working-with-the-gem-ecosystem.html&quot;&gt;Working with the Gem Ecosystem&lt;/a&gt; post.&lt;/p&gt;

&lt;p&gt;My thanks are extended to &lt;a href=&quot;http://www.nickjanetakis.com/blog/&quot;&gt;Nick&lt;/a&gt; who helped clarify the Gem update process and pointed out the need to embed the branch name in the Gemfile.  He picked this up from his work on the &lt;a href=&quot;https://github.com/nickjj/orats&quot;&gt;Orats gem&lt;/a&gt; which is very useful if you’re into Rails and Docker.&lt;/p&gt;

&lt;h1 id=&quot;generators&quot;&gt;Generators&lt;/h1&gt;

&lt;p&gt;I’m a big believer in custom generators and I’ve always found the process of writing them to be convoluted at best.  I recently found &lt;a href=&quot;https://github.com/sungwoncho/pattern_generator&quot;&gt;pattern_generator&lt;/a&gt; which makes writing generators drop dead easy.  I’m writing a project now where a major part of the process is writing custom data parsers for all kinds of web sites – udemy, leanpub, pluralsight, instagram, etc.  These are all PORO (plain old ruby objects) i.e. no ActiveRecord backed and I wanted a custom generator which:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;created my class&lt;/li&gt;
  &lt;li&gt;created my template&lt;/li&gt;
  &lt;li&gt;filled out the boilerplate structure&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Happily pattern_generator is just plain perfect. Here’s all I did&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;fork the gem&lt;/li&gt;
  &lt;li&gt;clone it to my computer&lt;/li&gt;
  &lt;li&gt;open it in an editor&lt;/li&gt;
  &lt;li&gt;create a directory&lt;/li&gt;
  &lt;li&gt;add my template class&lt;/li&gt;
  &lt;li&gt;add my template spec&lt;/li&gt;
  &lt;li&gt;replace the class name with erb style output tags&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And while this worked great, I ran into issues when I started making changes …&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The issues I had here are mine and mine alone.  &lt;a href=&quot;https://github.com/sungwoncho&quot;&gt;Sung Won Cho&lt;/a&gt; did a great job on pattern_generator and I thank him for it.&lt;/p&gt;

&lt;h1 id=&quot;and-now-back-to-gems&quot;&gt;And Now Back to Gems&lt;/h1&gt;

&lt;p&gt;My problem came when I added my fork of pattern_generator to my project’s Gemfile and did a bundle install.  At first the gem came down perfectly but I noticed a few bugs.  I then updated my code and re-bundled and &lt;em&gt;nothing&lt;/em&gt;.  I didn’t get any of my changes.  Here’s how I had it in my Gemfile initially:&lt;/p&gt;

&lt;div class=&quot;language-ruby highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;gem&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'pattern_generator'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;:git&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'https://github.com/fuzzygroup/pattern_generator.git'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Naturally this was located in a development only section of the Gemfile since we don’t want the memory overhead of this in production.&lt;/p&gt;

&lt;p&gt;My first thought was that this was tied to a bundle update versus bundle instlal so I did:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;bundle update&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And, again, nothing.  Next I tried:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;bundle update –source=https://github.com/fuzzygroup/pattern_generator.git&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I would have expected a bundle update pattern_generator to work but I did not find that to be the case.  But even with specifying the source explicitly I still did not get the right version of my code.  Happily Nick and I were about to pair anyway so I asked him and he honed right in on the branch i.e. specify the branch in the Gemfile.  Here’s how that looks:&lt;/p&gt;

&lt;div class=&quot;language-ruby highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;gem&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'pattern_generator'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;:git&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'https://github.com/fuzzygroup/pattern_generator.git'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;:branch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;master&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And that worked perfectly.  I wrote several new parsers today and then used my &lt;a href=&quot;https://github.com/fuzzygroup/sync-dot-rake&quot;&gt;SyncDotRake&lt;/a&gt; toolkit to merge the parsing code into a new Service Oriented API.  Overall it was a damn good day.  Thanks Nick!&lt;/p&gt;
</description>
        <pubDate>Mon, 27 Feb 2017 00:00:00 -0500</pubDate>
        <link>http://fuzzyblog.io//blog/ruby/2017/02/27/working-with-the-gem-ecosystem-part-2.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/ruby/2017/02/27/working-with-the-gem-ecosystem-part-2.html</guid>
        
        <category>ruby</category>
        
        <category>rails</category>
        
        <category>generators</category>
        
        <category>pattern_generator</category>
        
        <category>hyde</category>
        
        
        <category>ruby</category>
        
      </item>
    
      <item>
        <title>Headphones for Programmers - Bose QC-35 Blue Tooth Over Ear Noise Cancelling Headphones</title>
        <description>&lt;p&gt;Anyone who has ever worked with me since 2007 or so knows that I’m an unabashed fan of pair programming.  While the quantity of pairing I do varies from project to project, I’ve had 12 hour pairing days from time to time and one job that was almost &lt;strong&gt;exclusively pairing&lt;/strong&gt; over a 2 year period.&lt;/p&gt;

&lt;p&gt;There are four types of gear that matter for pairing:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Screen Sharing Software w/ Voice Communications&lt;/li&gt;
  &lt;li&gt;Similar or Matched Screen Resolutions&lt;/li&gt;
  &lt;li&gt;Decent Connectivity&lt;/li&gt;
  &lt;li&gt;Headphones&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Today I’m going to talk about headphones and specifically about Bose Quiet Comfort Headphones.  My wife, after an awful week, surprised me with a pair of Bose QC-35s.  She knew I wanted them and it had been an absolute shite show of a week so this was a wonderful surprise.&lt;/p&gt;

&lt;p&gt;I’ve been wearing wired Bose Quiet Comfort headphones now for almost a decade and I &lt;strong&gt;adore&lt;/strong&gt; them.  I don’t use the word adore oftem with respect to hardware / software.  Yes I adore my wife and, generally, my kids – but headphones?  Well Bose headphones are just that good.  I can wear my wired Bose head phones for 12 hours at a stretch without pain and that’s astonishing.&lt;/p&gt;

&lt;p&gt;I’m not at all an audiophile&lt;/p&gt;

&lt;p&gt;Now while I have long resisted blue tooth for serious audio, I&lt;/p&gt;
</description>
        <pubDate>Sun, 26 Feb 2017 02:09:15 -0500</pubDate>
        <link>http://fuzzyblog.io//blog/gear/2017/02/26/headphones-for-programmers-bose-qc-35-blue-tooth-over-ear-noise-cancelling-headphones.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/gear/2017/02/26/headphones-for-programmers-bose-qc-35-blue-tooth-over-ear-noise-cancelling-headphones.html</guid>
        
        <category>gear</category>
        
        <category>headphones</category>
        
        <category>pair_programming</category>
        
        
        <category>gear</category>
        
      </item>
    
      <item>
        <title>Setting Up Rails with Rspec From the Start</title>
        <description>&lt;p&gt;So this morning I was working on my side project and I realized that one aspect of it alone is now 26 plus PORO (plain old ruby objects) models and growing rapidly.  Given that I’m building this along the lines of a service oriented architeture where I want to be able to replace components prototyped in Ruby down the road with Elixir this would make sense so it was time to isolate it into a standalone http service as a separate Rails API stack.&lt;/p&gt;

&lt;p&gt;And this brings up the need to generate a stack with RSpec from the start.  Here’s how to do this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;rails new hyde_page_parser -T –skip-active-record –skip-action-cable –skip-spring –api&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I want this to &lt;strong&gt;NOT&lt;/strong&gt; include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;test_unit so -T gets rid of that&lt;/li&gt;
  &lt;li&gt;ActiveRecord so –skip-active-refactor&lt;/li&gt;
  &lt;li&gt;ActionCable so –skip-action-cable&lt;/li&gt;
  &lt;li&gt;Spring so –skip-spring&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That gets me a baseline project to which I can add RSpec.  Using &lt;a href=&quot;http://nrakochy.github.io/rspec/rails/2015/05/27/How-To-Setup-Rspec-Instead-Of-Test-Unit-Rails/&quot;&gt;Nrakochy’s&lt;/a&gt; instructions, all you need to do is:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Add gem ‘rspec-rails’ to a development, test group in Gemfile&lt;/li&gt;
  &lt;li&gt;Run bundle install&lt;/li&gt;
  &lt;li&gt;Run bundle exec rails g rspec:install&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Sun, 26 Feb 2017 00:00:00 -0500</pubDate>
        <link>http://fuzzyblog.io//blog/rails/2017/02/26/setting-up-rails-with-rspec-from-the-start.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/rails/2017/02/26/setting-up-rails-with-rspec-from-the-start.html</guid>
        
        <category>rails</category>
        
        <category>rspec</category>
        
        <category>hyde</category>
        
        
        <category>rails</category>
        
      </item>
    
      <item>
        <title>Multi Line Comments in Ruby - Finally</title>
        <description>&lt;p&gt;I’ve wanted multi line comments in Ruby forever and I just, thanks to &lt;a href=&quot;http://stackoverflow.com/questions/2989762/multi-line-comments-in-ruby&quot;&gt;this Stack Overflow post&lt;/a&gt;, found out that they exist thanks to =begin and =end:&lt;/p&gt;

&lt;div class=&quot;language-ruby highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;=begin

A long comment
that spans two
lines

=end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here’s a practical example where I’m keeping an example of how to run an instance method on a class in an easy to use copy and paste fashion (copy it and just drop it in Rails console).&lt;/p&gt;

&lt;div class=&quot;language-ruby highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;=begin

url = &quot;https://www.etsy.com/listing/253953555/tacos-tshirt-perfect-for-tacos-lover?ref=finds_l&quot;
parser = Page.new(url)
parser.parse

=end&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;I’m a fan of keeping code snippets around for easy copy and paste so you can get back to stuff quickly and multi-line comments make that so, so much easier.  Sure, I’d prefer /* and */, but, honestly, this will make me happy.  Matz made a choice to not have multi-line comments and while I don’t personally agree, long ago, I tied my&lt;/p&gt;
</description>
        <pubDate>Sun, 26 Feb 2017 00:00:00 -0500</pubDate>
        <link>http://fuzzyblog.io//blog/ruby/2017/02/26/multi-line-comments-in-ruby-finally.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/ruby/2017/02/26/multi-line-comments-in-ruby-finally.html</guid>
        
        <category>ruby</category>
        
        <category>rails</category>
        
        
        <category>ruby</category>
        
      </item>
    
      <item>
        <title>Understanding Low Level Index Issues in MySQL and Rails</title>
        <description>&lt;h1 id=&quot;the-problem&quot;&gt;The Problem&lt;/h1&gt;

&lt;p&gt;I had a weird thing recently – a table with 313 million rows had 30+ second queries on a unique index – that’s way, way too long.  Here’s how I went about troubleshooting this.&lt;/p&gt;

&lt;p&gt;A shout out of thanks to &lt;a href=&quot;https://github.com/itsgg&quot;&gt;Ganesh&lt;/a&gt; and to &lt;a href=&quot;https://github.com/wakproductions&quot;&gt;Winston&lt;/a&gt; who both helped out.  Notable mention to Ganesh who actually figured out the core issue; I’m really just the scribe here.&lt;/p&gt;

&lt;h1 id=&quot;viewing-mysql-indexes&quot;&gt;Viewing MySQL Indexes&lt;/h1&gt;

&lt;p&gt;Any performance problem always starts with an explain on the query:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-BASH&quot;&gt;explain select * from line_items where company_id=37 and document_identifier = 'RCON2170' and period = '2008-12-31'\G
*************************** 1. row ***************************
           id: 1
  select_type: SIMPLE
        table: line_items
         type: ALL
possible_keys: NULL
          key: NULL
      key_len: NULL
          ref: NULL
         rows: 314459869
        Extra: Using where
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Given that I &lt;strong&gt;know&lt;/strong&gt; that there’s an index I found this &lt;em&gt;puzzling&lt;/em&gt;.  The next step was to use a FORCE INDEX syntax on the query to ensure that this isn’t an optimizer issue:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;select * from line_items FORCE INDEX (index_line_items_fin_document_identifier_period) where company_id=37 and document_identifier = ‘RCON2170’ and period = ‘2008-12-31’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And that gave the same disappointing performance.  Pity. Using FORCE INDEX would have sucked but it would have been an easy fix at least.  Onward!&lt;/p&gt;

&lt;p&gt;This is where Ganesh rose to the challenge and recommended using SHOW INDEXES FROM table_name.  I haven’t used that in years and that’s likely a bad, bad, bad thing on my part (sorry).  Here’s what that gave us:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;SHOW INDEX FROM line_items\G&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&quot;language-BASH&quot;&gt;
MariaDB [data_production]&amp;gt; SHOW INDEX FROM line_items\G
*************************** 1. row ***************************
        Table: line_items
   Non_unique: 0
     Key_name: PRIMARY
 Seq_in_index: 1
  Column_name: id
    Collation: A
  Cardinality: 313591995
     Sub_part: NULL
       Packed: NULL
         Null:
   Index_type: BTREE
      Comment:
Index_comment:

*************************** 2. row ***************************
        Table: line_items
   Non_unique: 0
     Key_name: index_line_items_fin_document_identifier_period
 Seq_in_index: 1
  Column_name: company_id
    Collation: A
  Cardinality: 200
     Sub_part: NULL
       Packed: NULL
         Null: YES
   Index_type: BTREE
      Comment:
Index_comment:

*************************** 3. row ***************************
        Table: line_items
   Non_unique: 0
     Key_name: index_line_items_fin_document_identifier_period
 Seq_in_index: 2
  Column_name: document_identifier
    Collation: A
  Cardinality: 200
     Sub_part: NULL
       Packed: NULL
         Null: YES
   Index_type: BTREE
      Comment:
Index_comment:

*************************** 4. row ***************************
        Table: line_items
   Non_unique: 0
     Key_name: index_line_items_fin_document_identifier_period
 Seq_in_index: 3
  Column_name: period
    Collation: A
  Cardinality: 200
     Sub_part: NULL
       Packed: NULL
         Null: YES
   Index_type: BTREE
      Comment:
Index_comment:
4 rows in set (0.01 sec)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The very, very curious thing is that we see &lt;strong&gt;3 copies&lt;/strong&gt; of the index!  And you may notice that the cardinality of the index is incredibly low – 200 versus the 313591995 cardinality of the primary key index.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ibm.com/developerworks/data/library/techarticle/dm-1309cardinal/&quot;&gt;Cardinality&lt;/a&gt; is one of those key database concepts that most of us never have to worry about – essentially it is a measure of uniqueness in the index.  Indices perform better when they are unique and this is way, way, way too low – particularly for a unique index which incorporates 3 columns.  The actual cardinality here should equal that of the primary key index since this is a unique index.&lt;/p&gt;

&lt;h1 id=&quot;understanding-how-indexes-get-corrupted&quot;&gt;Understanding How Indexes Get Corrupted&lt;/h1&gt;

&lt;p&gt;This is the kind of thing that should NEVER happen so what went wrong?  Here’s where you have to guess a bit since we lack enough history to recreate things exactly.  Here’s what I think happened:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;We had this running on a 100GB partition where the database was roughly 54 gb and, yes, most of that space was dedicated to this one table.&lt;/li&gt;
  &lt;li&gt;An ALTER TABLE (via a Rails migration) started the index creation and then it failed part way through due to a lack of disc space.&lt;/li&gt;
  &lt;li&gt;And since it likely took a long time to run the ALTER TABLE, the timestamp for the migration was NEVER inserted into the schema_migrations table (deploy timeout).&lt;/li&gt;
  &lt;li&gt;This meant the next time that a deploy happened, the ALTER TABLE was run again.  And again.  And again until the timestamp finally made it into the schema_migrations table (even though technically the index was never fully created).&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;fixing-all-this&quot;&gt;Fixing All This&lt;/h1&gt;

&lt;p&gt;The solution to fixing this was actually pretty simple and had four parts:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Run an alter table statement which &lt;strong&gt;deleted&lt;/strong&gt; the original bad migration: &lt;strong&gt;ALTER TABLE line_items DROP INDEX index_line_items_fin_document_identifier_period;&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Delete the time stamp for the migration from the table schema_versions: &lt;strong&gt;DELETE FROM schema_migrations WHERE version=20161115210810;&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;Do a full deploy which will cause the migration to run again.  Given that this is a multi hour migration, the chance of your SSH connectivity staying up long enough to complete is slim.  Just know that and accept that.&lt;/li&gt;
  &lt;li&gt;Manually insert the timestamp back into the schema_migrations table: &lt;strong&gt;INSERT INTO schema_migrations (version) VALUES (20161115210810);&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Note 1:&lt;/strong&gt; A better way to do this, that I just thought of, is to &lt;strong&gt;NOT&lt;/strong&gt; do this as a deploy but instead manually scp the migration to the server (in fact it should be in db/migrate it should be there), delete the timestamp from schema_migrations and then run db:migrate directly on the server.  This would avoid step 4 entirely.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note 2:&lt;/strong&gt; Very &lt;strong&gt;long running&lt;/strong&gt; migrations are generally best run directly on the server without a deploy (in my not so humble opinion).  I used to do this all the time in my AppData hey day but I haven’t had to in ages so it took a while to remember it.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note 3:&lt;/strong&gt; If you don’t like doing an scp of a migration file then deploy to one node in your cluster of servers that is NOT a db role.  That prevents the migration from running automatically and then you can log in via ssh and start the migration manually.  Migrations &lt;strong&gt;only&lt;/strong&gt; run automatically when you have at least one machine identified as a db role being deployed to.&lt;/p&gt;

</description>
        <pubDate>Fri, 24 Feb 2017 00:00:00 -0500</pubDate>
        <link>http://fuzzyblog.io//blog/rails/2017/02/24/understanding-low-level-index-issues-in-mysql.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/rails/2017/02/24/understanding-low-level-index-issues-in-mysql.html</guid>
        
        <category>mysql</category>
        
        <category>index</category>
        
        <category>performance</category>
        
        <category>rails</category>
        
        
        <category>rails</category>
        
      </item>
    
      <item>
        <title>Leveling Up as a Developer</title>
        <description>&lt;p&gt;I have spent the past week handing off about 450,00 lines of ruby / ansible code (as measured by rake stats) that are an interface to about 6 terabytes of MySQL data handled by n AWS instances where n varies between 15 and several hundred to a &lt;strong&gt;single&lt;/strong&gt; developer – who happened to be more junior I was.  He’s not a bad guy by any means but, at times, it felt like I had hit him with an intellectual anvil.  We had only one week for the transition.&lt;/p&gt;

&lt;p&gt;Given how hard transitions and taking on a whole new code base can be, I thought I’d write out some recommendations for &lt;em&gt;Leveling Up as a Developer&lt;/em&gt;.&lt;/p&gt;

&lt;h1 id=&quot;its-all-about-immersion&quot;&gt;Its All About Immersion&lt;/h1&gt;

&lt;p&gt;About 9 months ago, I realized that the future of computing lay, imho, in AWS.  After having resisted cloud hosting for years, I finally buckled down and immersed myself in it. During the first six months of that 9 month period, well, I pretty much read constantly about little else but AWS.  There aren’t lots of great AWS books from what I can tell so I read blog post after blog post after blog post.  And then when I learned something I’d try it and then &lt;a href=&quot;http://fuzzyblog.io/blog/category.html#aws&quot;&gt;write it down&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;you-need-to-write-it-down&quot;&gt;You Need to Write It Down&lt;/h1&gt;

&lt;p&gt;The way I got good at learning things came back in 2002 when I learned to blog.  By writing things down in such a way that I could understand them, I taught them to myself.  Personally my writing preference has always been blogging since it gives something back to the public commons and, if I do write it well, I always, always, always learn something new from the writing process itself.  See Notes 1, 2 and 3 at the bottom of &lt;a href=&quot;http://fuzzyblog.io/blog/rails/2017/02/24/understanding-low-level-index-issues-in-mysql.html&quot;&gt;this post&lt;/a&gt; as an example.  Writing it down helped me come up with those three important points.&lt;/p&gt;

&lt;h1 id=&quot;you-need-a-side-project&quot;&gt;You Need a Side Project&lt;/h1&gt;

&lt;p&gt;I think every single developer out there needs a side project.  It doesn’t have to be grandiose in nature or even make money but your day job doesn’t always allow you to learn the things that you need.  A side project is &lt;strong&gt;yours&lt;/strong&gt;.  Want to play with backbone?  Then write a backbone front end to it.  Need to experiment with Elixir after you spent your own cash on the conference and the training and your boss denied it as too risky?  Just use it on your side project.&lt;/p&gt;

&lt;h1 id=&quot;you-need-to-write-code-every-single-day&quot;&gt;You Need to Write Code Every Single Day&lt;/h1&gt;

&lt;p&gt;I’m a big believer in incrementalism and the fact that you get better bit by bit.  On my current side project I have a commitment to myself that I put in at least one hard core hour per day every single day and I’ve been sustaining that since December 27th when I got serious about it.  If you want to level up then coding isn’t just a 9 to 5 thing; its an every day thing.&lt;/p&gt;

&lt;h1 id=&quot;read-read-read&quot;&gt;Read, Read, Read&lt;/h1&gt;

&lt;p&gt;You need to read until you’re sick of it and then you need to read some more.  This tends to go beyond immersion.  Immersion is when you’re picking up something entirely new.  Reading is part of taking software development seriously as your craft.&lt;/p&gt;

&lt;h1 id=&quot;realize-this-basic-fact&quot;&gt;Realize This Basic Fact&lt;/h1&gt;

&lt;p&gt;I’ve now been working in software development since ‘87 and it took me years and years to learn this basic fact:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Any software engineer increases their skills in direct proportion to the &lt;strong&gt;number&lt;/strong&gt; of &lt;strong&gt;different&lt;/strong&gt; codebases that they work on.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The problem here is that when you’re an employee the number of different codebases you’re generally exposed to is, well, &lt;strong&gt;one&lt;/strong&gt;.  The single best thing I ever did for my engineering skills was to move to being a freelancer.  I can cite which experience, since 2010, the start of my focus on freelancing, taught me what:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;AppData - Large scale data &lt;em&gt;everything&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;HowAboutWe - ActiveRecord optimization&lt;/li&gt;
  &lt;li&gt;StreamSend - Alternative ActiveRecord sharding architecures for decreasing hosting costs&lt;/li&gt;
  &lt;li&gt;LiveText - How to take a code base without any tests and grandfather them in without breaking things&lt;/li&gt;
  &lt;li&gt;FI Navigator - Devops&lt;/li&gt;
  &lt;li&gt;Interana - SAML&lt;/li&gt;
  &lt;li&gt;SigStr - MongoDB i.e. the world is not entirely MySQL&lt;/li&gt;
  &lt;li&gt;AddApp - Primary market research and ideation&lt;/li&gt;
  &lt;li&gt;Inside Network - How to write a billing system end to end that scales to millions of dollars and operates with zero downtime over a multiyear period&lt;/li&gt;
  &lt;li&gt;MDDX - Complex mathemetical workflows in Ruby&lt;/li&gt;
  &lt;li&gt;LinkedIn - Low level optimizations for an intensive Ruby workload&lt;/li&gt;
  &lt;li&gt;Trazzler - Geopositioning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Had I been stuck in 1 or even maybe 3 different jobs since 2010, I’m absolutely certain that I would never have picked up all these things.&lt;/p&gt;

&lt;h1 id=&quot;learning-is-multi-medium-these-days&quot;&gt;Learning is Multi-Medium These Days&lt;/h1&gt;

&lt;p&gt;I’m an admitted book nerd:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/book_nerd.jpg&quot; alt=&quot;book_nerd&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You should know that these book shelves &lt;em&gt;now&lt;/em&gt; go floor to ceiling and this is mostly computer science / high tech industry case studies with a bunch of cook books.  But even I have to admit that there are now very high bandwidth learning tools including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;YouTube.  Ignore the cat videos and search for conference proceedings.&lt;/li&gt;
  &lt;li&gt;Podcasts.  I highly, highly recommend &lt;a href=&quot;https://softwareengineeringdaily.com/&quot;&gt;Software Engineering Daily&lt;/a&gt;.  It is a fantastic learning tool for staying up to date on things.&lt;/li&gt;
  &lt;li&gt;Udemy Courses.  I’ve learned a ton from Udemy but I got the best computer science basics from &lt;a href=&quot;https://www.udemy.com/break-away-coding-interviews-1/learn/v4/t/lecture/3948990?start=0&quot;&gt;this course on Interviewing&lt;/a&gt;.  Also see my buddy Nick’s stuff on &lt;a href=&quot;https://www.udemy.com/the-docker-for-devops-course-from-development-to-production/&quot;&gt;Docker&lt;/a&gt;.  Outstanding.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;apply-it-for-yourself&quot;&gt;Apply It For Yourself&lt;/h1&gt;

&lt;p&gt;Seemingly any technology you want to get good at these days there’s a way to apply it for your personal use. Let’s say for example that you want to learn Ansible.  Here are two personal applications that would teach you quite a bit:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I now configure my MacBook using &lt;a href=&quot;https://github.com/fuzzygroup/ansible-macbook-pro&quot;&gt;Ansible&lt;/a&gt; - the link is to my repo for this.&lt;/li&gt;
  &lt;li&gt;I know other people who configure their &lt;a href=&quot;https://github.com/Phunky/ansible-plexmediaserver&quot;&gt;Plex servers using Ansible&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 24 Feb 2017 00:00:00 -0500</pubDate>
        <link>http://fuzzyblog.io//blog/software_engineering/2017/02/24/leveling-up-as-a-developer.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/software_engineering/2017/02/24/leveling-up-as-a-developer.html</guid>
        
        <category>software_engineering</category>
        
        
        <category>software_engineering</category>
        
      </item>
    
      <item>
        <title>Advice on Complex Caching Schemes</title>
        <description>&lt;p&gt;It is reputed to have been said:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;There are only two hard things in Computer Science: cache invalidation and naming things. &lt;a href=&quot;https://martinfowler.com/bliki/TwoHardThings.html&quot;&gt;Link&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Personally I’d generalize this to:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;There are only two hard things in Computer Science: caching things and naming things. (Me/Today)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Or the JWZ variant:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;table&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;I had a performance problem so I implemented a cache.  Now I had two problems.  (Me/Today&lt;/td&gt;
        &lt;td&gt;&lt;a href=&quot;http://regex.info/blog/2006-09-15/247&quot;&gt;JWZ Variant&lt;/a&gt;)&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
&lt;/blockquote&gt;

&lt;p&gt;I recently spoke with a client that wanted to implement a fairly complex scheme for caching the results of API operations.  They had a memcached implementation using &lt;a href=&quot;https://aws.amazon.com/elasticache/&quot;&gt;AWS ElastiCache&lt;/a&gt; and wanted to extend this to CloudFront.  My advice was simple:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Hell No!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Any kind of cache is always &lt;strong&gt;finicky&lt;/strong&gt; and &lt;strong&gt;hard to debug&lt;/strong&gt;.  The more complexity in your caching architecture, the absolutely harder it is to debug and the less likely it is to work reliably.  I’ve implemented a lot of caches over the years and I’ve tried to be trickier and tricker and, generally, when I bothered to track cache hits, the trickier ones never seemed to work quite right.  Part of it may have been logic errors and part of it may been misunderstanding how caches get called in this new crazy multi core world but I think my point stands – &lt;em&gt;complex caching schemes are hard to get right&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Here was my advice to the client:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Use &lt;a href=&quot;https://memcached.org/&quot;&gt;memcached&lt;/a&gt; solely (as part of ElastiCache); don’t bring in cloudfront.  Memcached has that brilliantly simple, automagical cache invalidation where you a) set when the object is available until allowing it to just disappear &lt;em&gt;automatically&lt;/em&gt; and b) if enough other objects crowd it out, it is expired using a FIFO architecture.  Those two properties make the cache invalidation issues pretty much disappear.&lt;/li&gt;
  &lt;li&gt;Take the incoming API call params and a) put them in a hash, b) call hash.to_json to get a stringified version, c) call a SHA1 routine on that stringified version.  That gives you a dirt simple cache key that you can store into memcached.&lt;/li&gt;
  &lt;li&gt;If their implementation of ElastiCache allows having multiple caches then set up a new cache for this new data and separate it logically from the current cache as this is high volume but low value.&lt;/li&gt;
  &lt;li&gt;If their implementation of ElastiCache doesn’t allow multiple caches then simply increase the size of the current cache.  Your goal here is to ensure that this new cache (which is on low value data) doesn’t crowd out the current cache citizens (which are higher value data).&lt;/li&gt;
  &lt;li&gt;Look into their current implementation of ElastiCache and see if they have any metrics on cache hit ratio and the like.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;That’s 458 words on caching and I could honestly write a book on it but I think I’ll stop here.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sidebar 1&lt;/strong&gt;: (Not part of the 458 words).  If you never watched Brad Danga’s video on Live Journal architecture then I absolutely recommend it unfortunately it seems to have expired from YouTube and the best I can do are the &lt;a href=&quot;http://danga.com/words/2005_oscon/oscon-2005.pdf&quot;&gt;slides&lt;/a&gt; (my favorite version) / &lt;a href=&quot;http://danga.com/words/&quot;&gt;More Slides&lt;/a&gt;.  Brad is my favorite Internet Architect and if he had a baseball card, well, I’d treasure it.  Recommended.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sidebar 2&lt;/strong&gt;: (Not part of the 458 words).  If you haven’t used ElastiCache then I highly recommend it.  It is truly the simplest way you’ll ever setup caching infrastructure.  AWS really knocked it out of the park on this one.&lt;/p&gt;
</description>
        <pubDate>Fri, 24 Feb 2017 00:00:00 -0500</pubDate>
        <link>http://fuzzyblog.io//blog/software_engineering/2017/02/24/advice-on-complex-caching-schemes.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/software_engineering/2017/02/24/advice-on-complex-caching-schemes.html</guid>
        
        <category>software_engineering</category>
        
        <category>caching</category>
        
        <category>aws</category>
        
        
        <category>software_engineering</category>
        
      </item>
    
      <item>
        <title>Diagnosing Slow Selects in MySQL</title>
        <description>&lt;p&gt;show indexes and look at cardinality&lt;/p&gt;
</description>
        <pubDate>Thu, 23 Feb 2017 09:02:29 -0500</pubDate>
        <link>http://fuzzyblog.io//blog/2017/02/23/diagnosing-slow-selects-in-mysql.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/2017/02/23/diagnosing-slow-selects-in-mysql.html</guid>
        
        
      </item>
    
      <item>
        <title>Rails Tutorial - Setting Up Sphinx Search with Rails and Thinking Sphinx</title>
        <description>&lt;p&gt;Sphinx Search is an open source search product that powers CraigsList as well as lots of other things on the Internet.  Unfortunatey Sphinx Search has more than a bit of a reputation of being finicky to configure and get working.  Given that it is both Linux and Open Source, this likely isn’t suprising.  The rest of this short tutorial covers how to get Sphinx Search working with Ruby on Rails using the Thinking Sphinx gem in a relatively standard configuration such as this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;database server&lt;/li&gt;
  &lt;li&gt;indexing / search server&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The first problem you’re going to hit with Sphinx Search is absolutely atrocious documentation.  This is true both of Sphinx Search itself and the Thinking Sphinx ruby gem (both of these criticisms, as with all such things are IMHO).&lt;/p&gt;

&lt;p&gt;Elastic File System&lt;/p&gt;
</description>
        <pubDate>Wed, 22 Feb 2017 16:03:39 -0500</pubDate>
        <link>http://fuzzyblog.io//blog/rails/2017/02/22/rails-tutorial-setting-up-sphinx-search-with-rails-and-thinking-sphinx.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/rails/2017/02/22/rails-tutorial-setting-up-sphinx-search-with-rails-and-thinking-sphinx.html</guid>
        
        <category>rails</category>
        
        <category>sphinx</category>
        
        <category>sphinx_search</category>
        
        <category>thinking_sphinx</category>
        
        
        <category>rails</category>
        
      </item>
    
      <item>
        <title>Understanding The Culture of Software Developers and How It Affects Management</title>
        <description>&lt;p&gt;russian - good at math but dour
british good at fundamentals 
indian - follow the rules&lt;/p&gt;
</description>
        <pubDate>Wed, 22 Feb 2017 08:38:32 -0500</pubDate>
        <link>http://fuzzyblog.io//blog/2017/02/22/understanding-the-culture-of-software-developers-and-how-it-affects-management.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/2017/02/22/understanding-the-culture-of-software-developers-and-how-it-affects-management.html</guid>
        
        
      </item>
    
  </channel>
</rss>
