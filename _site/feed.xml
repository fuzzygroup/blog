<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>FuzzyBlog</title>
    <description>Scott Johnson writing about the usual array of nerd stuff: AWS / Ansible / Ruby / Rails / Elixir / Misc.
</description>
    <link>https://fuzzygroup.github.io/blog/</link>
    <atom:link href="https://fuzzygroup.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 26 Nov 2016 12:16:40 -0500</pubDate>
    <lastBuildDate>Sat, 26 Nov 2016 12:16:40 -0500</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>Understanding Twitter - Why Is This Person Following Me?</title>
        <description>&lt;p&gt;I am what is generally referred to as an old school blogger.  My first blog post was back in 2002 and the first time I used hypertext links to keep daily notes was probably back in 1988.  Needless to say I’ve been using this as a medium for a very, very long time.  And I’m a wordy bastard at times so &lt;a href=&quot;http://twitter.com/fuzzygroup&quot;&gt;Twitter, for me&lt;/a&gt;, is a particular challenge:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I know there’s something very, very real there&lt;/li&gt;
  &lt;li&gt;People I &lt;a href=&quot;https://twitter.com/niall?lang=en&quot;&gt;really, really respect&lt;/a&gt; work there including the &lt;a href=&quot;https://twitter.com/wolframarnold&quot;&gt;guy who taught me Rails&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;It is a hell of an ecosystem&lt;/li&gt;
  &lt;li&gt;It is closer to the open world of blogging than the closed garden of Facebook&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When I came back to blogging in 2016 after a hiatius, I had an intuitive feeling that Twitter was now part of it and I’ve been trying to make sense of it ever since.  What I’ve personally found is that Twitter is a way to distribute your content.  It provides much the same function that RSS used to once upon a time.&lt;/p&gt;

&lt;h1 id=&quot;the-question-of-who-to-follow&quot;&gt;The Question of Who to Follow&lt;/h1&gt;

&lt;p&gt;The thing that I’ve had real issues with is figuring out who to follow and whether or not reciprocal follow as a strategy actually makes sense.  When I first started really using Twitter I used what is called a reciprocal follow strategy – if someone followed me then I followed them.  And I did it fairly blindly where I didn’t first look at the “person” blindly.  This resulted in my following people like these:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://twitter.com/NadiaShapiro&quot;&gt;https://twitter.com/NadiaShapiro&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://twitter.com/SimoRanieriCHEF&quot;&gt;https://twitter.com/SimoRanieriCHEF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://twitter.com/FossaTeam&quot;&gt;https://twitter.com/FossaTeam&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://twitter.com/LaSavonnerie&quot;&gt;https://twitter.com/LaSavonnerie&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each of these people directly corresponds to specific tweet I made roughly at the time they followed me - with one exception.  Why in the world would LaSavonnerie ever follow me?  I have nothing to do with french milled soap.  That one was bizarre.  In the case of FossaTeam, for example, I posted something about email and then someone in the email space close to immediately followed me.&lt;/p&gt;

&lt;p&gt;The twitterverse is filled with APIs and is highly automated.  The implications of this became fully evident when this person followed me the other day:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/untangling_twitter_why_would_this_person_ever_follow_me.png&quot; alt=&quot;untangling_twitter_why_would_this_person_ever_follow_me.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On first glance this is really, really cool – the &lt;strong&gt;voice of Siri&lt;/strong&gt; follows me!  And then you look at the numbers - &lt;strong&gt;1.4 million&lt;/strong&gt; &lt;em&gt;followers&lt;/em&gt;.  That kind of makes sense, right?  I mean Siri is a big deal so this is kind of like the number of followers that a celebrity might have.  The next number, however, gives me great pause: &lt;strong&gt;1.1 million&lt;/strong&gt; &lt;em&gt;following&lt;/em&gt;.  Let’s just assume that you can find a Twitter user, evaluate their content quickly and make the decision to follow someone in say just 10 seconds.  That means that this person has spent &lt;strong&gt;12.7 years&lt;/strong&gt; doing nothing more than clicking follow.  Mission Control – we have a problem here …&lt;/p&gt;

&lt;p&gt;What seems to be going on here is that this person has a bot that is automatically finding “interesting” people to follow.  Perhaps via content matching similar to their goals or perhaps just via existence by monitoring new tweets.  The bot, acting as this person, then follows those people in the interest of building an audience.  This audience can likely then be monitized either thru advertising, promoting a product or service, delivering other people’s tweets to it or by driving people somewhere else on the web.&lt;/p&gt;

&lt;h1 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h1&gt;

&lt;p&gt;None of this is illegal, immoral or fattening but it absolutely feels &lt;strong&gt;spammy&lt;/strong&gt;.  It feels spammy enough that I spent my free time this past September when my family and I were at DisneyWorld working on using Twitter’s APIs to analyze my following list to see if I should continue to follow them.  I actually came up with a fairly decent algorithm but Twitter’s rate limits on API calls makes it hard to use reliably.  However I’m still trying to figure out a work around.&lt;/p&gt;

&lt;p&gt;Here are the rules around who to follow that I came up with:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Never blindly reciprocally follow anyone.  It pollutes your twitter feed dramatically.  I’m still getting rid of followers.&lt;/li&gt;
  &lt;li&gt;Follow people NOT products, not companies, not entities.&lt;/li&gt;
  &lt;li&gt;Don’t follow celebrities - who cares.&lt;/li&gt;
  &lt;li&gt;Follow people who have interest similar to yours.  Yes that ends up with a bit of an echo chamber effect but it gives you a feed of information that is consonant with your information needs.&lt;/li&gt;
  &lt;li&gt;Don’t follow general purpose media organizations.  Just goto Google News and let information surface that way.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;IMPORTANT&lt;/strong&gt;: The bottom line is that if you carefully curate the people you follow on Twitter it can be a tremendous source of constantly flowing information.  When you incorporate follow people blindly the signal to noise ratio drops dramatically and Twitter becomes much less useful.  Wolfram, see below, explained this well to me and that really made Twitter much more useful for me.&lt;/p&gt;

&lt;h1 id=&quot;thank-you&quot;&gt;Thank You&lt;/h1&gt;

&lt;p&gt;Thank you to &lt;a href=&quot;https://twitter.com/niall&quot;&gt;Niall Kennedy&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/wolframarnold&quot;&gt;Wolfram Arnold&lt;/a&gt; for advice on Twitter.  Both of these people are Twitter engineers that I knew in a previous life and both gave me great advice.  Appreciated.&lt;/p&gt;
</description>
        <pubDate>Sat, 26 Nov 2016 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/twitter/2016/11/26/understanding-twitter-why-is-this-person-following-me.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/twitter/2016/11/26/understanding-twitter-why-is-this-person-following-me.html</guid>
        
        <category>twitter</category>
        
        <category>blogging</category>
        
        <category>siri</category>
        
        
        <category>twitter</category>
        
      </item>
    
      <item>
        <title>Postmac - Glad I Got the Older MacBook Pro</title>
        <description>&lt;p&gt;Having just bought the last generation MacBook Pro as opposed to the new one, I was very glad to read this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Bugs. On day one, the wifi disconnected five times in four hours. Thankfully, since then, Wifi has been rock solid while traveling, despite that concerning first day. Bluetooth failed to pair many devices at first. After pairing, Bluetooth continues to drop devices occasionally. Touch ID often isn’t provided as an option when I open the lid. When I am prompted, it occasionally doesn’t respond at all. When connected to an external monitor, I am typically forced to open the lid and login via touch ID — the password field literally isn’t provided as an option. Edit: Turns out the password field isn’t displayed, but if I start typing it shows up. Touch ID is an inconsistent mess. Spotlight has frozen more than once, requiring a reboot. Activity monitor regularly crashes and restarts. And the aforementioned palm rejection issues mean the cursor occasionally jumps to another part of the screen.
Needless to say, for a nearly $3,000 machine, this list is hard to accept. So much so that I’m seriously considering returning the machine. The bright side is everything above can potentially be resolved by future software updates.
&lt;a href=&quot;https://medium.com/@housecor/a-week-with-the-new-macbook-pro-with-touch-pad-126eebb89ac#.h6qw1ha55&quot;&gt;Medium&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Overall I think I’m very, very happy having gotten the older MacBook Pro.  Yes in time this might get resolved but it also might not.&lt;/p&gt;

&lt;p&gt;Note: There were a bunch of good things he mentioned but for $3,000 you shouldn’t have to suffer through any of that.  I’m no longer as devoted to the Apple Kool-aid as I once was.&lt;/p&gt;

&lt;p&gt;And here’s the &lt;a href=&quot;https://news.ycombinator.com/item?id=13043422&quot;&gt;Hacker News Commentary&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Sat, 26 Nov 2016 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/postmac/2016/11/26/postmac-glad-i-got-the-older-macbook-pro.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/postmac/2016/11/26/postmac-glad-i-got-the-older-macbook-pro.html</guid>
        
        <category>postmac</category>
        
        <category>osx</category>
        
        <category>mac</category>
        
        
        <category>postmac</category>
        
      </item>
    
      <item>
        <title>Fear and Loathing in AWS or Adventures in Partition Resizing</title>
        <description>&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; - This is very, very long.  It is isn’t done yet and it is 3,589 words when I thought to add this note.  At my normal metric of 250 words per page, that I learned in college, that’s &lt;strong&gt;14.5&lt;/strong&gt; printed pages.  The reason for not splitting it up is that if you ever have these issues then you want all of this in here in one place.&lt;/p&gt;

&lt;p&gt;A few days ago I made a mistake – a significant one.  I had a large data load running into a MySQL database and I wasn’t really thinking about the storage implications of it.  To make matters worse this was the only box in the cluster that wasn’t running the monitoring software I like – &lt;a href=&quot;https://github.com/mperham/inspeqtor&quot;&gt;Inspeqtor&lt;/a&gt;.  The db server had been the first box I had configured when I brought up all of our boxes and I never went back and installed Inspeqtor.  I know, I know – an amateur’s mistake at best.  But, and it is no excuse, we’ve been running hard and fast for a while and, ultimately, this always catches up to you.&lt;/p&gt;

&lt;p&gt;So you know where this is going – &lt;strong&gt;we ran out of space&lt;/strong&gt;.  And out of space on a db server is generally a bad thing.  Sometimes it falls into the category of “ok bad” and other times it falls into the category of “oh shite bad”.  This was “oh shite bad”.  I spent about 12 hours wondering &lt;strong&gt;if&lt;/strong&gt; I’d get back my data, not &lt;em&gt;when&lt;/em&gt;.  Happily, my luck held, and it was &lt;strong&gt;when&lt;/strong&gt; and that &lt;strong&gt;when&lt;/strong&gt; is likely about 24 more hours from the time of this writing.  A bunch of the data has already been recovered and, with that, it is time to write the retrospective mea culpa and maybe cast some light on what is honestly a fairly crappy aspect of AWS.&lt;/p&gt;

&lt;p&gt;Now, unlike most of my AWS writings which I structure as tutorials, this is not a tutorial.  It is more of an essay or perhaps advice.  I couldn’t fully document the meandering path that I took as it was done under pressure and with a fair to moderate level of cursing.&lt;/p&gt;

&lt;p&gt;Note: When I went through all this I was fairly dissatisfied with AWS in this regard and there are some real quirks to storage and minor issues but when I think about what this would have taken with a classical data center, I applaud Amazon.  My guess is that if I had to get professional operations people involved to have helped with this, I would quickly be out a few thousand dollars in high priced on call labor.&lt;/p&gt;

&lt;h1 id=&quot;understand-this-well-very-well-here-there-be-dragons&quot;&gt;Understand This Well, Very Well, Here There Be Dragons&lt;/h1&gt;

&lt;p&gt;The first thing to understand is that the steps I took and the tools I used are &lt;strong&gt;dangerous&lt;/strong&gt;.  Had I taken a slightly wrong path I would likely have lost everything.  If you are going to walk this type of road then I strongly recommend:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Do it with a second set of eyes.  I am an unabashed fan of pair programming and whenever things are bad I prefer to have a pairing buddy.  My normal pairing partner, &lt;a href=&quot;http://www.dasari.me&quot;&gt;Dv&lt;/a&gt;, wasn’t available when all this was going on so I brought on &lt;a href=&quot;https://nickjanetakis.com/&quot;&gt;Nick&lt;/a&gt; as a consultant for this ordeal and he was fantastic.  At two critical junctures he kept me from going astray.  Highly recommended.&lt;/li&gt;
  &lt;li&gt;Take your time.  When data recovery is an issue you need to take your time and actually &lt;strong&gt;think&lt;/strong&gt;.  If people are yelling at you to get it done and hurry up then, well, don’t listen to them.  If I hadn’t brought this back up it would have likely cost us between 1 and 3 months of lost effort.  With those kind of stakes I’m going to take my damn time and so should you.&lt;/li&gt;
  &lt;li&gt;When in doubt – &lt;strong&gt;stop&lt;/strong&gt;.  It is always tempting to plunge forward since you are &lt;em&gt;almost&lt;/em&gt; there.  Nope.  When in doubt my advice is rest, coffee or even sleep.  Some things just can’t be rushed and understanding that is key.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;initial-mistakes-made&quot;&gt;Initial Mistakes Made&lt;/h1&gt;

&lt;p&gt;As I look back at this I can see that I made one real mistake early in setting up this, our first AWS box was that I didn’t really analyze our data volumes and growth rate and do some projections.  I’ve done that now, at least a bit, and I wish I had done that at the start.  For this project we’re growing at about 250 + gigs per month.  When I setup our database server I went for a very simple configuration – a 2 terabyte volume configured as the boot volume.  Apparently, even today, there are still hard and fast limits &lt;a href=&quot;http://unix.stackexchange.com/questions/33555/what-is-the-max-partition-supported-in-linux&quot;&gt;such as you can’t have a boot volume greater than two terabytes&lt;/a&gt;.  Sigh.  What I should have done is have a small boot volume and then a data volume that was 2 terabytes.  I can’t prove it but I think that if I had done this my woes in partition resizing would not have happened.&lt;/p&gt;

&lt;p&gt;Take away advice:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;For a db server always have a small boot volume&lt;/li&gt;
  &lt;li&gt;Make your database store its data on a non boot volume; yes that’s obvious based on #1 but I’m being explicit.&lt;/li&gt;
  &lt;li&gt;I suspect that if I had used LVM things might have been better but I’ve never understood LVM very well.&lt;/li&gt;
  &lt;li&gt;Whatever you do make &lt;em&gt;absolutely certain&lt;/em&gt; that if you are using MySQL then at the version you are using either has &lt;a href=&quot;http://dev.mysql.com/doc/refman/5.7/en/innodb-multiple-tablespaces.html&quot;&gt;innodb_per_file&lt;/a&gt; either turned on or as the default.  At my last data center I had this manually turned on in my.cnf.  And it became the default in MySQL 5.6.  I never dreamed when I set up my boxes at AWS this past fall that I didn’t get 5.6 as part of a normal &lt;em&gt;apt-get install mariadb&lt;/em&gt; operation.  This option defines whether you have a single gigantic blob of disc space that stores all your files or a blob of disc space &lt;strong&gt;per table&lt;/strong&gt;.  When you use innodb_per_file, despite some issues, it means that you can address storage needs far more granularly by applying symlinks to different file systems.  This is an incredible advantage for handling large amounts of data.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Note: If you understand the issues of innodb_per_file then you can likely ignore #4.  And, honestly, if you understand it then perhaps you should drop me a resume; I’m always looking for talent.&lt;/p&gt;

&lt;h1 id=&quot;but-why-didnt-you-use-rds&quot;&gt;But Why Didn’t You Use RDS?&lt;/h1&gt;

&lt;p&gt;I’m sure someone out there is shouting at their phone or tablet saying &lt;em&gt;Why, oh dear lord, why didn’t you use RDS&lt;/em&gt;.  Well I actually tried to use RDS, specifically Aurora, but found, for our data, &lt;a href=&quot;https://fuzzygroup.github.io/blog/aws/2016/08/28/aws-tutorial-4-rds-data-loading-into-aurora-run-in-circles-scream-and-shout-the-oh-shite-moment.html&quot;&gt;RDS led to silent data loss on data load&lt;/a&gt;.  I don’t know why but I verified it myself and I was in a hurry so I just setup my own DB server.  Yes RDS would have been easier but not if it loses data.&lt;/p&gt;

&lt;p&gt;Take away advice:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;RDS is still a new technology; be wary&lt;/li&gt;
  &lt;li&gt;Make sure that if you have large or complex data loads that it does load everything you give it.  Verify your row counts between old and new servers.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;step-1---reboot-the-server&quot;&gt;Step 1 - Reboot the Server&lt;/h1&gt;

&lt;p&gt;When a database server runs out of space, the database software itself generally goes down and that’s actually good.  The first step is always, always, always to reboot the server.  A reboot generally clears up at least some disc space, often enough to get things operational again.  I wouldn’t recommend actually adding more info to the database until you solve the storage issues but you can at least get access to the system.&lt;/p&gt;

&lt;p&gt;Take away advice:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reboot your database server after problems to clear up some space.&lt;/li&gt;
  &lt;li&gt;If your database software isn’t quickly accessible it is likely recovering from the crash.  Check the logs and be patient.  MySQL, my database of choice, is excellent at recovery.  I can’t speak to other databases but MySQL has always been great at this in my experience.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;step-2---get-a-second-set-of-eyes&quot;&gt;Step 2 - Get a Second Set of Eyes&lt;/h1&gt;

&lt;p&gt;As described above I strongly recommend getting a second set of eyes early in the process.  You really should do this.  It made all the difference in keeping things on track.&lt;/p&gt;

&lt;h1 id=&quot;step-3---understanding-storage-in-the-aws-world&quot;&gt;Step 3 - Understanding Storage in the AWS World&lt;/h1&gt;

&lt;p&gt;Most of us are familiar with storage in terms of our personal systems but AWS is a bit of different thing.  Here is what I learned through trial and error:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Any EC2 server can have multiple chunks of storage attached to it.&lt;/li&gt;
  &lt;li&gt;These chunks of storage are called volumes.&lt;/li&gt;
  &lt;li&gt;When you need more storage you can just create a volume.&lt;/li&gt;
  &lt;li&gt;Newly created volumes are entirely blank and do NOT have a file system on them.  For people from a Windows background in particular this can be odd.&lt;/li&gt;
  &lt;li&gt;Before you can use a volume you need to either attach or detach it.&lt;/li&gt;
  &lt;li&gt;Volumes need to be mounted with either a mount command or fstab.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;When you need to transfer a LOT of data from EC2 server 1 to EC2 server 2 then:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;You can create a volume&lt;/li&gt;
      &lt;li&gt;You can attach it to the source of the data (say a machine you are using for running mysqldump)&lt;/li&gt;
      &lt;li&gt;You can make a filesystem on it&lt;/li&gt;
      &lt;li&gt;You can mount it&lt;/li&gt;
      &lt;li&gt;You can dump your data to the new volume&lt;/li&gt;
      &lt;li&gt;You can detach the volume&lt;/li&gt;
      &lt;li&gt;You can attach it to the destination of the data&lt;/li&gt;
      &lt;li&gt;You can mount it&lt;/li&gt;
      &lt;li&gt;You can load the data&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;If you need to bring parallelism to things there is nothing stopping you from creating multiple volumes, putting data in one, moving it to the destination and then using another volume to continue the process.&lt;/li&gt;
  &lt;li&gt;All of your old school Unix commands come in handy.&lt;/li&gt;
  &lt;li&gt;Snapshots are quickly created backups that you can use to initialize a volume with data.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you need a way to visualize AWS storage then think of it this way:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Volumes are external hard drives that you can create freely and attach to servers.&lt;/li&gt;
  &lt;li&gt;You can have as many as you want within reason; you aren’t constrained by the number of ports you have in your machine.&lt;/li&gt;
  &lt;li&gt;Attaching and then mounting is equivalent to plugging the volume in&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;step-4---experiment-before-you-do-anything-with-your-data&quot;&gt;Step 4 - Experiment Before You Do Anything With Your Data&lt;/h1&gt;

&lt;p&gt;One of the brilliant aspects of AWS is that you can experiment with abandon.  Need to see how to mess about with a 4 terabyte 
partition?  You can just create one and then try things.  I’d strongly recommend experimenting with the process in full before you risk your data.&lt;/p&gt;

&lt;h1 id=&quot;step-5---the-low-level-unix-commands-in-question&quot;&gt;Step 5 - The Low Level Unix Commands in Question&lt;/h1&gt;

&lt;p&gt;There are several underlying low level Unix commands that I had to use during the course of this.&lt;/p&gt;

&lt;h2 id=&quot;the-fstab-file&quot;&gt;The fstab File&lt;/h2&gt;

&lt;p&gt;Fstab isn’t a command, it is a user defined ASCII data file in /etc i.e. /etc/fstab that defines how logical volumes are attached to the computer you’re working on and where they are &lt;em&gt;mounted&lt;/em&gt;.  What you have to is create a master directory such as /mnt and then subdirectories where you want discs to be attached such as /mnt/old.  The instructions in fstab would then connect a low level volume such as /dev/xvdf to that directory allowing you to ls, cd and so on.&lt;/p&gt;

&lt;p&gt;Here’s an example from one of my boxes:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cat /etc/fstab
LABEL=cloudimg-rootfs	/	 ext4	defaults,discard	0 0
/dev/xvdf  /mnt/old. ext4  defaults,discard 0 0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This shows two logical drives, one from the AWS default setup and one volume I created.  Both are ext4 filesystems and they are mounted at / and /mnt/old respectively.&lt;/p&gt;

&lt;p&gt;Since we’re into /etc/fstab, I would be remiss if I didn’t point out the noatime issue which I didn’t realize was still a thing in 2016 but apparently it still is.  Here are some urls to read:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.brendangregg.com/blog/2015-03-03/performance-tuning-linux-instances-on-ec2.html&quot;&gt;Absolutely Worth It&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://dev.mysql.com/doc/refman/5.7/en/disk-issues.html&quot;&gt;MySQL / Innodb on noatime&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://askubuntu.com/questions/674320/what-ssd-optimization-are-needed-on-latest-ubuntu-version&quot;&gt;Ask Ubuntu 1&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://serverfault.com/questions/47466/drawbacks-of-mounting-a-filesystem-with-noatime&quot;&gt;ServerFault&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://askubuntu.com/questions/2099/is-it-worth-to-tune-ext4-with-noatime&quot;&gt;Ask Ubuntu 2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://lonesysadmin.net/2013/12/08/gain-30-linux-disk-performance-noatime-nodiratime-relatime/&quot;&gt;30% Disk Performance Gains with Noatime&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note: I’m going to add noatime and nodiratime into my mount statements shortly.  This is what I’m going to add to my fstab:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rw,noatime,nodiratime,nobarrier,data=ordered 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;which I sourced from &lt;a href=&quot;http://www.zhongweicheng.com/?p=2494&quot;&gt;here&lt;/a&gt;.  Once that’s set in /etc/fstab then I’m going to:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo service mysql stop (making certain that nothing is using the db first)
mount -o remount
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;You can also do it &lt;a href=&quot;http://serverfault.com/questions/346360/how-can-i-add-the-noatime-flag-to-my-filesystem-without-a-reboot&quot;&gt;this way&lt;/a&gt; without modifying fstab but then you lose the options on reboot so that’s kind of suckass.&lt;/p&gt;

&lt;h2 id=&quot;mounting-a-drive---mount&quot;&gt;Mounting a Drive - mount&lt;/h2&gt;

&lt;p&gt;The mount command mounts the volumes identified in /etc/fstab.  You need to use this after you have attached a drive using the AWS console in order to make it available to the system.  If it helps you to understand this then think of the AWS Console’s attach command as equivalent to plugging in a hardware cable to a drive whereas mount is the software side.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo mount -a 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;You can also mount without an fstab file like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo mount /dev/sdg /vol -t ext4
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;unmounting-a-drive---umount&quot;&gt;Unmounting a Drive - umount&lt;/h2&gt;

&lt;p&gt;When you need to detach a volume with the AWS console you first need to unmount it with umount.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo umount /dev/xvdf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;When you can’t unmount a volume with the AWS console, what do you do – you do this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo umount /devxda1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And when you get&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;umount: /: device is busy.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;then you need to figure out what process still has this open.  Two tools for this are lsof and fuser (I was much more successful with fuser).&lt;/p&gt;

&lt;h2 id=&quot;list-block-devices---lsblk&quot;&gt;List Block Devices - lsblk&lt;/h2&gt;

&lt;p&gt;The lsblk command shows you the logical block devices on your system.  A block device essentially means a disk but it could be something else.  This one was new to me or at least something I don’t think I’ve used since I ran Fedora on my ThinkPad back in 2000.  Here’s an example:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lsblk
NAME                                MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
xvda                                202:0    0     8G  0 disk
└─xvda1                             202:1    0     8G  0 part /
xvdb                                202:16   0   3.9T  0 disk /mnt/new
xvdf                                202:80   0     2T  0 disk
loop0                                 7:0    0   100G  0 loop
└─docker-202:1-276736-pool (dm-0)   252:0    0   100G  0 dm
  └─docker-202:1-276736-base (dm-1) 252:1    0    10G  0 dm
loop1                                 7:1    0     2G  0 loop
└─docker-202:1-276736-pool (dm-0)   252:0    0   100G  0 dm
  └─docker-202:1-276736-base (dm-1) 252:1    0    10G  0 dm
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This is showing all the block devices.  If you notice xvda this is showing a physical volume and then a logical volume within it.  It is also interesting to note that docker is actually a block device.  It makes sense that Docker went this route but until I saw it myself I don’t think I really appreciated that; &lt;strong&gt;very, very cool&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;file-system-file-system-what-do-we-have---file&quot;&gt;File System, File System, What do We Have - file&lt;/h2&gt;

&lt;p&gt;The file command tells you what file system your disk volume supports.  When I first moved to Linux professionally from Windows, as opposed to just mucking about with Linux, I remember being a bit baffled about the wealth of file system options – ext2, ext3, reiser / murderfs, etc.  You really didn’t see this much if at all in Windows at the time so it was disconcerting.  The basic idea being having multiple filesytems is that different filesytems are good at different things.  If, for example, the year is 2005 and you want to put 100,000 files in a single directory then your only real option is ReiserFS.  Reiser was fantastic at this.  Similarly if you need a maximum file size of 16 exabytes in size then you need Btrfs and that’s likely the only filesystem on the planet other than ZFS which can do this.&lt;/p&gt;

&lt;p&gt;Given that all data on a computer is ultimately written to a file at some point, if you can get better performance from a different filesystem, then changing filesystems is a really easy way to get better performance that affects everything.  When you improve your code you affect only your application but move to a filesystem with say 10% better write speed then &lt;strong&gt;everything&lt;/strong&gt; you do on that machine improves.  That’s the power of changing your filesystem.  Now, that said, this is something where you absolutely need to understand every single issue.  For example Btrfs looks great but only use it on OpenSuse or Oracle Linux.  On other platforms it is still under active development.&lt;/p&gt;

&lt;p&gt;Here’s an example of using file on a newly created volume:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo file -s /dev/xvdf
/dev/xvdf: data
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;If you notice all it says is &lt;strong&gt;data&lt;/strong&gt;.  This means that the volume is newly created and has no filesystem yet so you’ll need to use mkfs covered below.&lt;/p&gt;

&lt;p&gt;Here’s file when a filesystem exists:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo file -s /dev/xvdf
/dev/xvdf: Linux rev 1.0 ext4 filesystem data, UUID=2a3476d6-cb01-44e6-a4c6-3c6d3c1cb675 (extents) (large files) (huge files)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Interesting URLS:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://mariadb.com/resources/blog/what-best-linux-filesystem-mariadb&quot;&gt;Best Filesystem for MariaDB&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://serverfault.com/questions/29193/what-is-the-best-linux-filesystem-for-mysql-innodb&quot;&gt;Best Filesystem for MariaDB Stack Overflow; quite old but illustrates the tradeoffs well&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.percona.com/blog/2014/05/23/improve-innodb-performance-write-bound-loads/&quot;&gt;Read This But Don’t Do It&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jeremytinley.wordpress.com/2014/10/08/more-ext4-vs-xfs-io-testing/&quot;&gt;Benchmark Results&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;making-a-file-system---mkfs&quot;&gt;Making a File System - mkfs&lt;/h2&gt;

&lt;p&gt;The mkfs command actually creates a filesystem.  Years ago this was actually slow but in 2016 even with an enormous 4TB volume it was rippingly fast:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo mkfs -t ext4 /dev/xvdf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;step-6---and-now-we-come-to-partition-resizing&quot;&gt;Step 6 - And Now We Come to Partition Resizing&lt;/h1&gt;

&lt;p&gt;It may be hard to believe that it has taken this many words to get ourselves ready for partition resizing. Damn but I can be a &lt;em&gt;wordy son of a bitch&lt;/em&gt; at times – apologies.  Anyway I’m going to give the punch line first:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I was never, ever able to resize a 2 TB AWS boot volume to a bigger size.  According to the &lt;a href=&quot;http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-expand-volume.html&quot;&gt;AWS docs&lt;/a&gt; this should be possible but they are actually fairly crappy with respect to volume issues.  No matter what I did I kept getting superblock / magic number errors that I could not get past.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The basic process should have been something like this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Create a snapshot of the current volume&lt;/li&gt;
  &lt;li&gt;Create a new volume of the desired size&lt;/li&gt;
  &lt;li&gt;Import the snapshot into the new volume&lt;/li&gt;
  &lt;li&gt;Use parted / gpt to adjust the core partition to the new size&lt;/li&gt;
  &lt;li&gt;Use resizefs to finish the process&lt;/li&gt;
  &lt;li&gt;Profit!!!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Honestly I was really, really surprised that in 2016 trying to resize a Linux partition was such an absolute shite show.  Perhaps it was me but the other person pairing on this had no better luck than I.  It should not have been this hard.&lt;/p&gt;

&lt;p&gt;So, &lt;em&gt;somewhat&lt;/em&gt; unfortunately, I ended up having to do a full dump / restore of my database to get around this.  And while that sucked monkey chunks it did end up wiht some positive things as covered in the next section.&lt;/p&gt;

&lt;h2 id=&quot;aws-gotchas&quot;&gt;AWS Gotchas&lt;/h2&gt;

&lt;p&gt;While at this step we hit a number of gotchas that were really confusing at first.  The first of these was the fact that logical device names change depending on AWS versus which kernel you have.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/beware_names_are_inconsistent_01.png&quot; alt=&quot;beware_names_are_inconsistent_01.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(Here it is /dev/sdf)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/beware_names_are_inconsistent_02.png&quot; alt=&quot;beware_names_are_inconsistent_02.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(Here it is /dev/xvdf)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/beware_names_are_inconsistent_03.png&quot; alt=&quot;beware_names_are_inconsistent_03.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(Here is the warning)&lt;/p&gt;

&lt;p&gt;I find it absolutely inconceivable that Amazon can’t do better than this.  Given the possibility for destructive errors by getting things wrong this should be much, much better.  Given that this is a controlled cloud computing environment, doesn’t Amazon know the kernel?&lt;/p&gt;

&lt;p&gt;Note: I’m a self admitted amazon fan boy for AWS so for me to say this means I think its really really serious.&lt;/p&gt;

&lt;p&gt;When you create a disc volume there is no option for naming / tagging it at creation time:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/create_volume.png&quot; alt=&quot;create_volume.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;That is equally sucky.  Do this a lot and you end with a bunch of things name vol-64bb3234d and vol-534343bc and you’re scratching your head going “hm…”.  Yes you can name them after but that increases the chance that they never get named.&lt;/p&gt;

&lt;h2 id=&quot;my-path-if-its-useful-to-you&quot;&gt;My Path If Its Useful To You&lt;/h2&gt;

&lt;p&gt;Here is my rough, meandering path thru resize2fs, parted and gpt in case anyone out there wants to tell me where I went wrong.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;__AWS_PRODUCTION__ ubuntu@ip-172-31-45-225:~$ resize2fs /dev/xvda1
resize2fs 1.42.9 (4-Feb-2014)
open: Permission denied while opening /dev/xvda1
__AWS_PRODUCTION__ ubuntu@ip-172-31-45-225:~$ sudo resize2fs /dev/xvda1
resize2fs 1.42.9 (4-Feb-2014)
The filesystem is already 536868903 blocks long.  Nothing to do!


sudo parted /dev/xvdg1
GNU Parted 2.3
Using /dev/xvdg1
Welcome to GNU Parted! Type 'help' to view a list of commands.
(parted) unit s
(parted) print
Model: Unknown (unknown)
Disk /dev/xvdg1: 4294951231s
Sector size (logical/physical): 512B/512B
Partition Table: loop

Number  Start  End          Size         File system  Flags
 1      0s     4294951230s  4294951231s  ext4

(parted) rm 1
Error: Partition(s) 1 on /dev/xvdg1 have been written, but we have been unable to inform the kernel of the change, probably because it/they are in use.  As a result, the old
partition(s) will remain in use.  You should reboot now before making further changes.
Ignore/Cancel? c
(parted) quit
Information: You may need to update /etc/fstab.

lsblk
NAME    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
xvda    202:0    0    8G  0 disk
└─xvda1 202:1    0    8G  0 part /
xvdn    202:208  0  3.9T  0 disk
└─xvdn1 202:209  0    2T  0 part
[ec2-user@ip-172-31-45-119 ~]$ sudo parted /dev/xvdn
GNU Parted 2.1
Using /dev/xvdn
Welcome to GNU Parted! Type 'help' to view a list of commands.
(parted) help
  align-check TYPE N                        check partition N for TYPE(min|opt) alignment
  check NUMBER                             do a simple check on the file system
  cp [FROM-DEVICE] FROM-NUMBER TO-NUMBER   copy file system to another partition
  help [COMMAND]                           print general help, or help on COMMAND
  mklabel,mktable LABEL-TYPE               create a new disklabel (partition table)
  mkfs NUMBER FS-TYPE                      make a FS-TYPE file system on partition NUMBER
  mkpart PART-TYPE [FS-TYPE] START END     make a partition
  mkpartfs PART-TYPE FS-TYPE START END     make a partition with a file system
  move NUMBER START END                    move partition NUMBER
  name NUMBER NAME                         name partition NUMBER as NAME
  print [devices|free|list,all|NUMBER]     display the partition table, available devices, free space, all found partitions, or a particular partition
  quit                                     exit program
  rescue START END                         rescue a lost partition near START and END
  resize NUMBER START END                  resize partition NUMBER and its file system
  rm NUMBER                                delete partition NUMBER
  select DEVICE                            choose the device to edit
  set NUMBER FLAG STATE                    change the FLAG on partition NUMBER
  toggle [NUMBER [FLAG]]                   toggle the state of FLAG on partition NUMBER
  unit UNIT                                set the default unit to UNIT
  version                                  display the version number and copyright information of GNU Parted
(parted) unit s
(parted) print
Model: Xen Virtual Block Device (xvd)
Disk /dev/xvdn: 8388608000s
Sector size (logical/physical): 512B/512B
Partition Table: msdos

Number  Start   End          Size         Type     File system  Flags
 1      16065s  4294967295s  4294951231s  primary  ext4         boot

(parted) rm 1
(parted) mkpart primary 16065s 100%
Error: partition length of 8388591935 sectors exceeds the msdos-partition-table-imposed maximum of 4294967295
(parted) print
Model: Xen Virtual Block Device (xvd)
Disk /dev/xvdn: 8388608000s
Sector size (logical/physical): 512B/512B
Partition Table: msdos

Number  Start  End  Size  Type  File system  Flags

(parted) rm 1^C
(parted) ^C
(parted) ^C
(parted) ^C
(parted) quit
Information: You may need to update /etc/fstab.

[ec2-user@ip-172-31-45-119 ~]$ sudo parted /dev/xvdn
GNU Parted 2.1
Using /dev/xvdn
Welcome to GNU Parted! Type 'help' to view a list of commands.
(parted) print
Model: Xen Virtual Block Device (xvd)
Disk /dev/xvdn: 4295GB
Sector size (logical/physical): 512B/512B
Partition Table: msdos

Number  Start  End  Size  Type  File system  Flags

(parted) mklabel gpt
Warning: The existing disk label on /dev/xvdn will be destroyed and all data on this disk will be lost. Do you want to continue?
Yes/No? no
(parted) ^C
(parted) quit
[ec2-user@ip-172-31-45-119 ~]$ gdisk
GPT fdisk (gdisk) version 0.8.10

Type device filename, or press &amp;lt;Enter&amp;gt; to exit: /dev/xvdn
Problem opening /dev/xvdn for reading! Error is 13.
You must run this program as root or use sudo!
[ec2-user@ip-172-31-45-119 ~]$ sudo gdisk
GPT fdisk (gdisk) version 0.8.10

Type device filename, or press &amp;lt;Enter&amp;gt; to exit: /dev/xvdn
Partition table scan:
  MBR: MBR only
  BSD: not present
  APM: not present
  GPT: not present


***************************************************************
Found invalid GPT and valid MBR; converting MBR to GPT format
in memory. THIS OPERATION IS POTENTIALLY DESTRUCTIVE! Exit by
typing 'q' if you don't want to convert your MBR partitions
to GPT format!
***************************************************************


Command (? for help): p
Disk /dev/xvdn: 8388608000 sectors, 3.9 TiB
Logical sector size: 512 bytes
Disk identifier (GUID): 93F6FAE1-8253-4399-B31B-0B49896792B0
Partition table holds up to 128 entries
First usable sector is 34, last usable sector is 8388607966
Partitions will be aligned on 2048-sector boundaries
Total free space is 8388607933 sectors (3.9 TiB)

Number  Start (sector)    End (sector)  Size       Code  Name

Command (? for help): o
This option deletes all partitions and creates a new protective MBR.
Proceed? (Y/N): ^C[ec2-user@ip-172-31-45-119 ~]$ ^C
[ec2-user@ip-172-31-45-119 ~]$ exit
logout
Connection to ec2-35-163-65-227.us-west-2.compute.amazonaws.com closed.
FuzzygroupMacbookPro2016:~ sjohnson$ ssh -i &quot;~/.ssh/fi_nav_sitecrawl.pem&quot; ec2-user@ec2-35-163-65-227.us-west-2.compute.amazonaws.com
Last login: Tue Nov 22 19:40:18 2016 from 64-184-12-117.dial.hrtc.net

       __|  __|_  )
       _|  (     /   Amazon Linux AMI
      ___|\___|___|

https://aws.amazon.com/amazon-linux-ami/2016.09-release-notes/
6 package(s) needed for security, out of 11 available
Run &quot;sudo yum update&quot; to apply all updates.
[ec2-user@ip-172-31-45-119 ~]$ df -h
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        488M   64K  488M   1% /dev
tmpfs           498M     0  498M   0% /dev/shm
/dev/xvda1      7.8G  975M  6.7G  13% /
[ec2-user@ip-172-31-45-119 ~]$ sudo e2fsck -f /dev/sdbm
e2fsck 1.42.12 (29-Aug-2014)
e2fsck: No such file or directory while trying to open /dev/sdbm
Possibly non-existent device?
[ec2-user@ip-172-31-45-119 ~]$ sudo e2fsck -f /dev/sdm
e2fsck 1.42.12 (29-Aug-2014)
ext2fs_open2: Bad magic number in super-block
e2fsck: Superblock invalid, trying backup blocks...
e2fsck: Bad magic number in super-block while trying to open /dev/sdm

The superblock could not be read or does not describe a valid ext2/ext3/ext4
filesystem.  If the device is valid and it really contains an ext2/ext3/ext4
filesystem (and not swap or ufs or something else), then the superblock
is corrupt, and you might try running e2fsck with an alternate superblock:
    e2fsck -b 8193 &amp;lt;device&amp;gt;
 or
    e2fsck -b 32768 &amp;lt;device&amp;gt;

[ec2-user@ip-172-31-45-119 ~]$ sudo e2fsck -f /dev/sdm^C
[ec2-user@ip-172-31-45-119 ~]$ lsblk
NAME    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
xvda    202:0    0    8G  0 disk
└─xvda1 202:1    0    8G  0 part /
xvdm    202:192  0  3.9T  0 disk
└─xvdm1 202:193  0    2T  0 part
[ec2-user@ip-172-31-45-119 ~]$ sudo e2fsck -f /dev/xvdm
e2fsck 1.42.12 (29-Aug-2014)
ext2fs_open2: Bad magic number in super-block
e2fsck: Superblock invalid, trying backup blocks...
e2fsck: Bad magic number in super-block while trying to open /dev/xvdm

The superblock could not be read or does not describe a valid ext2/ext3/ext4
filesystem.  If the device is valid and it really contains an ext2/ext3/ext4
filesystem (and not swap or ufs or something else), then the superblock
is corrupt, and you might try running e2fsck with an alternate superblock:
    e2fsck -b 8193 &amp;lt;device&amp;gt;
 or
    e2fsck -b 32768 &amp;lt;device&amp;gt;

[ec2-user@ip-172-31-45-119 ~]$ sudo parted /dev/xvdm
GNU Parted 2.1
Using /dev/xvdm
Welcome to GNU Parted! Type 'help' to view a list of commands.
(parted) print
Model: Xen Virtual Block Device (xvd)
Disk /dev/xvdm: 4295GB
Sector size (logical/physical): 512B/512B
Partition Table: msdos

Number  Start   End     Size    Type     File system  Flags
 1      8225kB  2147GB  2147GB  primary  ext4         boot

(parted) quit
[ec2-user@ip-172-31-45-119 ~]$ df -h^C
[ec2-user@ip-172-31-45-119 ~]$ sudo gdisk /dev/xvdm
GPT fdisk (gdisk) version 0.8.10

Partition table scan:
  MBR: MBR only
  BSD: not present
  APM: not present
  GPT: not present


***************************************************************
Found invalid GPT and valid MBR; converting MBR to GPT format
in memory. THIS OPERATION IS POTENTIALLY DESTRUCTIVE! Exit by
typing 'q' if you don't want to convert your MBR partitions
to GPT format!
***************************************************************


Command (? for help): ?
b	back up GPT data to a file
c	change a partition's name
d	delete a partition
i	show detailed information on a partition
l	list known partition types
n	add a new partition
o	create a new empty GUID partition table (GPT)
p	print the partition table
q	quit without saving changes
r	recovery and transformation options (experts only)
s	sort partitions
t	change a partition's type code
v	verify disk
w	write table to disk and exit
x	extra functionality (experts only)
?	print this menu

Command (? for help): p
Disk /dev/xvdm: 8388608000 sectors, 3.9 TiB
Logical sector size: 512 bytes
Disk identifier (GUID): 024ED60B-7DA6-4AB2-A8DC-9B0963E3B56C
Partition table holds up to 128 entries
First usable sector is 34, last usable sector is 8388607966
Partitions will be aligned on 8-sector boundaries
Total free space is 4194325603 sectors (2.0 TiB)

Number  Start (sector)    End (sector)  Size       Code  Name
   1           16065      4194298394   2.0 TiB     8300  Linux filesystem

Command (? for help): o
This option deletes all partitions and creates a new protective MBR.
Proceed? (Y/N): Y

Command (? for help): n
Partition number (1-128, default 1): 1
First sector (34-8388607966, default = 2048) or {+-}size{KMGTP}: 16065
Information: Moved requested sector from 16065 to 14336 in
order to align on 2048-sector boundaries.
Use 'l' on the experts' menu to adjust alignment
Last sector (14336-8388607966, default = 8388607966) or {+-}size{KMGTP}: 8388607966
Current type is 'Linux filesystem'
Hex code or GUID (L to show codes, Enter = 8300): 8300
Changed type of partition to 'Linux filesystem'

Command (? for help): ?
b	back up GPT data to a file
c	change a partition's name
d	delete a partition
i	show detailed information on a partition
l	list known partition types
n	add a new partition
o	create a new empty GUID partition table (GPT)
p	print the partition table
q	quit without saving changes
r	recovery and transformation options (experts only)
s	sort partitions
t	change a partition's type code
v	verify disk
w	write table to disk and exit
x	extra functionality (experts only)
?	print this menu

Command (? for help): p
Disk /dev/xvdm: 8388608000 sectors, 3.9 TiB
Logical sector size: 512 bytes
Disk identifier (GUID): 422B4B11-7A84-40DC-8DE2-CE219D94FDEC
Partition table holds up to 128 entries
First usable sector is 34, last usable sector is 8388607966
Partitions will be aligned on 2048-sector boundaries
Total free space is 14302 sectors (7.0 MiB)

Number  Start (sector)    End (sector)  Size       Code  Name
   1           14336      8388607966   3.9 TiB     8300  Linux filesystem

Command (? for help): g
b	back up GPT data to a file
c	change a partition's name
d	delete a partition
i	show detailed information on a partition
l	list known partition types
n	add a new partition
o	create a new empty GUID partition table (GPT)
p	print the partition table
q	quit without saving changes
r	recovery and transformation options (experts only)
s	sort partitions
t	change a partition's type code
v	verify disk
w	write table to disk and exit
x	extra functionality (experts only)
?	print this menu

Command (? for help): x

Expert command (? for help): g
Enter the disk's unique GUID ('R' to randomize): 024ED60B-7DA6-4AB2-A8DC-9B0963E3B56C
The new disk GUID is 024ED60B-7DA6-4AB2-A8DC-9B0963E3B56C

Expert command (? for help): w

Final checks complete. About to write GPT data. THIS WILL OVERWRITE EXISTING
PARTITIONS!!

Do you want to proceed? (Y/N): Y
OK; writing new GUID partition table (GPT) to /dev/xvdm.
The operation has completed successfully.
[ec2-user@ip-172-31-45-119 ~]$ sudo file -sL /dev/xvdm
/dev/xvdm: GPT partition table, version 1.0, GUID: 024ed60b-7da6-4ab2-a8dc-9b0963e3b56c, disk size: 8388608000 sectors of 512 bytes
[ec2-user@ip-172-31-45-119 ~]$ sudo e2fsck -f /dev/xvdm
e2fsck 1.42.12 (29-Aug-2014)
ext2fs_open2: Bad magic number in super-block
e2fsck: Superblock invalid, trying backup blocks...
e2fsck: Bad magic number in super-block while trying to open /dev/xvdm

The superblock could not be read or does not describe a valid ext2/ext3/ext4
filesystem.  If the device is valid and it really contains an ext2/ext3/ext4
filesystem (and not swap or ufs or something else), then the superblock
is corrupt, and you might try running e2fsck with an alternate superblock:
    e2fsck -b 8193 &amp;lt;device&amp;gt;
 or
    e2fsck -b 32768 &amp;lt;device&amp;gt;

[ec2-user@ip-172-31-45-119 ~]$ sudo e2fsck -b 8193 -f /dev/xvdm
e2fsck 1.42.12 (29-Aug-2014)
e2fsck: Bad magic number in super-block while trying to open /dev/xvdm

The superblock could not be read or does not describe a valid ext2/ext3/ext4
filesystem.  If the device is valid and it really contains an ext2/ext3/ext4
filesystem (and not swap or ufs or something else), then the superblock
is corrupt, and you might try running e2fsck with an alternate superblock:
    e2fsck -b 8193 &amp;lt;device&amp;gt;
 or
    e2fsck -b 32768 &amp;lt;device&amp;gt;

[ec2-user@ip-172-31-45-119 ~]$ sudo e2fsck -b 32768  -f /dev/xvdm
e2fsck 1.42.12 (29-Aug-2014)
e2fsck: Bad magic number in super-block while trying to open /dev/xvdm

The superblock could not be read or does not describe a valid ext2/ext3/ext4
filesystem.  If the device is valid and it really contains an ext2/ext3/ext4
filesystem (and not swap or ufs or something else), then the superblock
is corrupt, and you might try running e2fsck with an alternate superblock:
    e2fsck -b 8193 &amp;lt;device&amp;gt;
 or
    e2fsck -b 32768 &amp;lt;device&amp;gt;

[ec2-user@ip-172-31-45-119 ~]$ ls^C
[ec2-user@ip-172-31-45-119 ~]$ lsblk
NAME    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
xvda    202:0    0    8G  0 disk
└─xvda1 202:1    0    8G  0 part /
xvdm    202:192  0  3.9T  0 disk
└─xvdm1 202:193  0  3.9T  0 part
[ec2-user@ip-172-31-45-119 ~]$ sudo resize2fs -M -p /dev/xvdm
resize2fs 1.42.12 (29-Aug-2014)
resize2fs: Bad magic number in super-block while trying to open /dev/xvdm
Couldn't find valid filesystem superblock.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;step-7---why-having-partition-resizing-fail-was-ok&quot;&gt;Step 7 - Why Having Partition Resizing Fail was Ok&lt;/h1&gt;

&lt;p&gt;The reason that I never lost my mind was that in the process of troubleshooting all this I realized that I had failed to set the innodb_per_file option when my db server was initially setup.  The innodb_per_file option can only be set when a database is created / loaded so if I wanted it, I didn’t have a lot of options.  And, since it was a holiday and downtime was sort of naturally going on, it was actually about the best possible time to do all this.  Keep in mind that while it isn’t pleasant to go from &lt;em&gt;mince onions for stuffing&lt;/em&gt; to &lt;em&gt;check database dump&lt;/em&gt; and then to &lt;em&gt;make cranberry orange relish&lt;/em&gt;, you can actually do this without losing your mind.  By the end of it I was timing database dump routines along side recipes with ease i.e. “Ok I can make a caramel apple cobbler in the same time it takes to dump the table page2016_q2s”.  Certainly 2016, also known in my head as dbpocalyse, is a holiday I won’t soon forget.&lt;/p&gt;

&lt;h1 id=&quot;step-8---generating-your-mysql-dump-files&quot;&gt;Step 8 - Generating Your MySQL Dump Files&lt;/h1&gt;

&lt;p&gt;Due to the size generated and the need for load concurrency I generated my mysqldump files with a rake task.  All this has todo is:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;all_tables = ActiveRecord::Base.connection.select_values(&quot;SHOW TABLES&quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And then a simple all_tables.each loop like this will do most of the work:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;all_tables.each_with_index do |table, ctr|
  dump_statement = &quot;#{mysqldump_executable} -u#{username} -p#{password} -h#{host} #{db} #{table} &amp;gt; /mnt/transfer/#{table}.sql&quot;
  puts &quot;#{ctr} :: #{table} :: #{ctr.to_f/total*100}%&quot;
  puts &quot;  #{dump_statement}&quot;
  `#{dump_statement}` if execute_dump        
end
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The advantage to this approach is rather than a single massive database dump you end up with a file for each table which lets you reload multiple tables in parallel.&lt;/p&gt;

&lt;h1 id=&quot;step-9---verify-your-dump-files-with-tail&quot;&gt;Step 9 - Verify Your Dump Files with Tail&lt;/h1&gt;

&lt;p&gt;Here’s a general bit of advice when you are dealing with multi-hour long / multi-day long mysqldump processes – make sure that they actually complete.  After all when you’re looking at a directory listing and all you see is this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;215121716510 page2016_q2s.sql
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;How you to know that a file you basically identify as byte size / filename actually finished successfully?  An easy to check this is to just tail the file like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tail long_urls.sql

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2016-11-23  7:50:34
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;That’s what the tail of a successful MySQL dump should look like.  The key thing is &lt;strong&gt;– Dump completed on 2016-11-23  7:50:34&lt;/strong&gt;.&lt;/p&gt;

&lt;h1 id=&quot;step-10---why-didnt-i-try-maatkit-or-something-else&quot;&gt;Step 10 - Why Didn’t I Try maatkit or something else?&lt;/h1&gt;

&lt;p&gt;You’ll notice that I used straight up mysqldump as my backup tool.  Why would I do that when there are higher performance alternatives like maatkit, mydumper or mysqlhotbackup?  Well it all comes down to &lt;strong&gt;trust&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;mysqldump for all the issues is &lt;strong&gt;solid&lt;/strong&gt;.  I’ve used it for more than a decade and it has never given me issues – when I used it correctly.  Any issues I’ve had have been user error and that hasn’t happened for at least a decade.&lt;/li&gt;
  &lt;li&gt;mysqldump is regularly maintained.  &lt;a href=&quot;https://sourceforge.net/projects/maatkit/&quot;&gt;maatkit&lt;/a&gt; seems to have last been maintained in 2013 while &lt;a href=&quot;https://www.percona.com/blog/2015/11/12/logical-mysql-backup-tool-mydumper-0-9-1-now-available/&quot;&gt;mydumper&lt;/a&gt; is about a year since last maintenance.  While I’m not one to take the position that old software is dead software, for something as critical as a backup tool it does make me a little bit squeamish.&lt;/li&gt;
  &lt;li&gt;All of this happened over the U.S. Thanksgiving holiday and while I had time it was in dribs and drabs – often while I was in the middle of cooking – the last thing I had time for was sitting down and poring thru tech notes to figure out why the command line options for mydumper were different from mysqldump.  Honestly – why would you change these?  I could simply set mysqldump going on a half dozen different terminals front ended by tmux to keep them alive.  That gave me concurrency if not performance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sidebar-for-open-source-authors---currency-matters&quot;&gt;Sidebar for Open Source Authors - Currency Matters&lt;/h2&gt;

&lt;p&gt;There are tons and tons of different open source projects that are actually fantastic but haven’t really been updated recently.  That doesn’t mean that you shouldn’t use them by any means.  But, if you are an open source author, you should really be aware that the potential users of your software often look at your project in terms of its git repository.  And one of the first things you notice is the datestamp which github gives you as “2 years ago”, “a month ago” and so on.  I’m going to illustrate this with an example from a project I really, really like: &lt;a href=&quot;https://github.com/mperham/inspeqtor&quot;&gt;Inspeqtor&lt;/a&gt;.  Inspeqtor is an open source monitoring tool &lt;a href=&quot;https://fuzzygroup.github.io/blog/aws/2016/10/20/aws-tutorial-20-adding-machine-and-process-monitoring-to-your-aws-instance-with-inspeqtor.html&quot;&gt;I’ve written about before&lt;/a&gt;.  Honestly it is &lt;a href=&quot;https://mmonit.com/monit/&quot;&gt;monit&lt;/a&gt; with an easier configuration approach.  And it is from one of my open source heroes, &lt;a href=&quot;http://www.mikeperham.com/&quot;&gt;Mike Perham&lt;/a&gt;, so of course I like it. But, the first time I considered it, it hadn’t been updated in about a year and I have to say that did give me pause.  If I hadn’t known exactly who Mike Perham was then I likely would have raced over to Monit and used it instead.&lt;/p&gt;

&lt;p&gt;Now the secret trick for an open source is really simple – &lt;strong&gt;you don’t have to touch the code&lt;/strong&gt; – for github to update the last modified time stamp.  All you have to do is update the readme or some other documentation file.  A lot of the time when you are an open source user is that you don’t want &lt;strong&gt;abandonware&lt;/strong&gt;.  When you choose an open source tool you’re making an investment.  It may be an investment of time rather than money but it damn well is an investment.  And when things are abandonware the nature of that investment changes.  Even if I am 90% likely to never reach out to a project in the form of an issue or support, knowing that the project is still alive means that I can.  And about the only positive signal that a project is alive comes from damn timestamp that github reports so gleefully.&lt;/p&gt;

&lt;h1 id=&quot;step-11---why-didnt-i-get-a-real-professional&quot;&gt;Step 11 - Why Didn’t I Get a Real Professional?&lt;/h1&gt;

&lt;p&gt;I have to admit that it is &lt;strong&gt;pretty damn inconceiveable&lt;/strong&gt; to me that in &lt;strong&gt;2016&lt;/strong&gt; you can’t resize an AWS volume dynamically particularly if you can so easily unmount it and operate it on it.  And it is important to know that I am &lt;em&gt;not an expert&lt;/em&gt; in this area.  I’m not a full time ops guy nor am I a true sysadmin – I just play one on the internet from time to time.  So the logical thing to do would have been to reach out to a real professional or even AWS support so why didn’t I?  Well it comes down to this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Timing&lt;/strong&gt;.  This happened just prior to a holiday so people’s availability is severely constrained.  I didn’t want any resource involved that couldn’t see it thru end to end.  I know that I am fully available and I am confident enough that no matter what happened I would get thru it.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;No Backups&lt;/strong&gt;.  There were no database backups available (see next section) which means that any solution had to be 100% safe.  And I could only guarantee that if I did things myself.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Pricing&lt;/strong&gt;.  The older I get the more sensitive I get to being, what I feel, unfairly screwed.  The last time I got significant talent on the spot market – i.e. when you need it immediately – &lt;a href=&quot;https://www.linkedin.com/in/peter-hegedus-04ba331?authType=NAME_SEARCH&amp;amp;authToken=pg9J&amp;amp;locale=en_US&amp;amp;trk=tyah&amp;amp;trkInfo=clickedVertical%3Amynetwork%2CclickedEntityId%3A5541755%2CauthType%3ANAME_SEARCH%2Cidx%3A1-1-1%2CtarId%3A1480149749298%2Ctas%3Apeter%20hegedus&quot;&gt;that person&lt;/a&gt; charged me either $300 or $400 per hour for about two hours of what amounted to configuration support.  And that’s fine, it was his right to do that.  But that degree of what I felt was dramatic unfairness meant that I will never, ever contact him again before the &lt;strong&gt;heat death of the universe&lt;/strong&gt;.  And the pity is that this person could easily have taken less per hour and rolled it into an ongoing relationship where I’d still be relying on him today.  I mean I am still running, daily, the code he wrote.  Sigh.  I saw no reason to raise my blood pressure by being potentially screwed once again.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;step-12---flying-without-a-net-or-life-without-database-backups&quot;&gt;Step 12 - Flying without a Net or Life Without Database Backups&lt;/h1&gt;

&lt;p&gt;It may surprise some people that I did not have a decent backup system in place and there’s a story here.  This is a project that is an outgrowth of a very poorly funded project that I’ve been continuously working on since 2010.  The aggregate code base size is north of 400K lines of Ruby and all the code growth has been organic not planned.  Although other people have touched the code base at times I’ve been the sole author of probably 95% of it.  As an incredibly poorly funded project there was never much of an ops budget and since this was a 24x7x365 system there wasn’t a lot of opportunity for offline time for backup.  There was about a 2 year period when we changed to one data center where I was told backups were being done.  Unfortunately there were enough times were I was told that “we have a backup issue and we need to reboot all of your servers to address it” that I never once trusted it.&lt;/p&gt;

&lt;p&gt;During the past 7 years there was only one time when an important table was accidentally dropped.  That was the one case when we might have called for data recovery and we had a local copy of the same data that was only a few hours out of sync so we didn’t bother.  So, at least from a track record basis, I have a pretty good record for not screwing things up.  One of the secrets to my success tho is I applied a very strict trust metric to database access – if I woudn’t trust &lt;a href=&quot;http://dasari.me&quot;&gt;you&lt;/a&gt; to watch my kids then I wouldn’t give you access to the actual database.  And, surprisingly, that actually has worked out pretty well.&lt;/p&gt;

&lt;p&gt;Now, does any of that excuse there not being backups?  Absolutely not.  This is now both better funded and far more mission critical so I’ll get this figured out in short order.  If I end up rolling my own backup solution then I’ll do it on my own time and open source it.  While there are different backup solutions out there, our data sets have some unique characteristics and rolling some code to automate this might be an interesting challenge.  I suspect using &lt;a href=&quot;https://aws.amazon.com/dynamodb/&quot;&gt;dynamodb&lt;/a&gt; for tracking the backup catalog might be interesting.&lt;/p&gt;

&lt;h1 id=&quot;step-13---engineer-color-code-thyself&quot;&gt;Step 13 - Engineer Color Code Thyself&lt;/h1&gt;

&lt;p&gt;The biggest mistake in something like this, beyond the fact that it happened at all, is likely to come from yourself.  People, particularly tired, frustrated people (and you will be both tired and frustrated from this), make mistakes.  A lot of this work happens inside terminal tabs that look exactly alike.  It is incrediby easy to check on this and mistake source for destination and then – WHAM – you have a real problem.  And I know you are thinking that this cannot happen or “how stupid is this guy; &lt;strong&gt;I&lt;/strong&gt; am smarter than that.”  Well you might be, I certainly am, but it still happens.  And, honestly, if something like that has even a chance of happen you are better off setting things up so that it &lt;strong&gt;won’t&lt;/strong&gt; happen.&lt;/p&gt;

&lt;p&gt;Just as an example, even though I’d like to think I’m smarter than that, all of this started just prior to Thanksgiving 2016 so Turkey Day 2016 was spent running back and forth between Thanksgiving cooking and seeing if certain long running exports had finished yet.  Just as a 22 pound turkey seems to take forever to cook so, too, does a table dump that has this many bytes: 215121716510.  Since I was in and out of things so many times, statistically, the chance that I’d make a mistake I think was actually fairly high.&lt;/p&gt;

&lt;p&gt;When you are dealing with old and new systems that would normally look identical the best trick I’ve ever found is really, really simple – &lt;strong&gt;color code&lt;/strong&gt; things.  If you look at &lt;a href=&quot;https://www.quora.com/How-much-of-the-brain-is-involved-with-vision&quot;&gt;how much of the brain is related to vision&lt;/a&gt; then this actually makes sense.  Making dangerous things highly visual means that they really stand out.   All I did was set the background color differently for each terminal.  I made all terminals related to source be solarized and all terminals related to destination be normal (black).  Here is what that looks like:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/color_code_your_terminals_destination.png&quot; alt=&quot;solarized&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/color_code_your_terminals_source.png&quot; alt=&quot;black&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Given that I might have 3 or 4 terminals open on source and the same number on destination this makes everything so much easier.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sidebar:&lt;/strong&gt; I’ve been looking, for years, for a way to define my background terminal color on login to a different system automatically specifically to prevent this. This should happen automatically at login based on an environment variable.  If anyone out there knows a unix shell scripting trick for this I’d bloody well love to hear it.  Thanks!&lt;/p&gt;

&lt;h1 id=&quot;useful-urls&quot;&gt;Useful Urls&lt;/h1&gt;

&lt;p&gt;Here are some of the useful urls I came across in the process of dealing with the raft of shite associated with this minor debacle.&lt;/p&gt;

&lt;h2 id=&quot;aws-and-disk-resizing-stuff&quot;&gt;AWS and Disk Resizing Stuff&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;(MS-DOS partition table and partition resizing)[http://askubuntu.com/questions/84538/trouble-creating-3tb-ext4-partition-due-to-msdos-partition-table-imposed-error]&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/storage_expand_partition.html#expanding-partition-gdisk&quot;&gt;Expanding a Linux Partition&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/28792272/attaching-and-mounting-existing-ebs-volume-to-ec2-instance-filesystem-issue&quot;&gt;AWS Mount Issues&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ubuntuforums.org/showthread.php?t=1668813&quot;&gt;Misc Ubuntu Tech Notes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/storage_expand_partition.html&quot;&gt;Expanding Storage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://unix.stackexchange.com/questions/28436/how-to-mount-this-disk&quot;&gt;Mounting Disks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-using-volumes.html&quot;&gt;Using AWS Volumes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://chrisschuld.com/2007/08/reload-fstab-etcfstab/&quot;&gt;Reloading fstab&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://askubuntu.com/questions/84501/how-can-i-change-convert-a-ubuntu-mbr-drive-to-a-gpt-and-make-ubuntu-boot-from&quot;&gt;Converting MBR drives to gpt&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://cloud.tekgoblin.com/2013/04/29/aws-guides-how-to-increase-your-ec2-linux-root-volume-size/&quot;&gt;Increasing Your Root Volume Size&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://matt.berther.io/2015/02/03/how-to-resize-aws-ec2-ebs-volumes/&quot;&gt;Resizing AWS Volumes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://cloudacademy.com/blog/amazon-ebs-shink-volume/&quot;&gt;Shrinking Volumes; hey its the inverse of what I wanted but isn’t that the same thing?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-expand-volume.html&quot;&gt;EBS Expanding Volumes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.textit.in/why-buying-provisioned-iops-on-rds-may-be-a-mistake&quot;&gt;Provisioned IOPs - interesting&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://forums.aws.amazon.com/message.jspa?messageID=526918&quot;&gt;Tech Support&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://bbs.archlinux.org/viewtopic.php?id=62984&quot;&gt;Misc Tech Notes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mysql-and-innodb-stuff&quot;&gt;MySQL and Innodb Stuff&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.percona.com/blog/2015/11/12/logical-mysql-backup-tool-mydumper-0-9-1-now-available/&quot;&gt;MyDumper Press Release&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/luobailiang/mydumper&quot;&gt;MyDumper Github&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.percona.com/blog/2014/05/23/improve-innodb-performance-write-bound-loads/&quot;&gt;Innodb Performance Tuning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://dev.mysql.com/doc/refman/5.7/en/innodb-performance-multiple_io_threads.html&quot;&gt;Innodb Multiple IO Threads&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://dba.stackexchange.com/questions/86636/when-is-it-safe-to-disable-innodb-doublewrite-buffering&quot;&gt;Innodb Double Write Buffering&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://dev.mysql.com/doc/refman/5.7/en/mysqlimport.html&quot;&gt;MySQL Import; Don’t Bother with It&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://dba.stackexchange.com/questions/54639/is-there-a-successor-or-an-alternative-to-mk-parallel-dump&quot;&gt;Stack Overflow on mk parallel dump&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://learn.percona.com/hubfs/Manuals/Percona_Toolkit/Percona-Toolkit-2.2.19.pdf?t=1479504188846&quot;&gt;Percona Toolkit&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://dba.stackexchange.com/questions/20/how-can-i-optimize-a-mysqldump-of-a-large-database&quot;&gt;Optimizing MySQL Dump&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://dba.stackexchange.com/questions/20409/should-we-need-to-use-barriers-on-a-production-database-mysql-innodb&quot;&gt;MySQL and nobarrier&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.zhongweicheng.com/?p=2494&quot;&gt;Interesting / Recommended&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 26 Nov 2016 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/aws/2016/11/26/fear-and-loathing-in-awsville-or-adventures-in-partition-resizing.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/aws/2016/11/26/fear-and-loathing-in-awsville-or-adventures-in-partition-resizing.html</guid>
        
        <category>aws</category>
        
        <category>ebs</category>
        
        <category>volume</category>
        
        <category>linux</category>
        
        <category>partition</category>
        
        <category>mysql</category>
        
        <category>innodb</category>
        
        <category>tuning</category>
        
        
        <category>aws</category>
        
      </item>
    
      <item>
        <title>AWS Tech Note - Problems with Ubuntu 16.04 and Ansible</title>
        <description>&lt;p&gt;AWS Tech Note No python as default install on ubuntu 16.04 LTS&lt;/p&gt;

&lt;p&gt;ansible-playbook -i inventories/proxy playbook_appdata_proxy.yml&lt;/p&gt;

&lt;p&gt;PLAY [all] &lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;***&lt;/p&gt;

&lt;p&gt;TASK [setup] &lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;*
fatal: [adproxy2]: FAILED! =&amp;gt; {“changed”: false, “failed”: true, “module_stderr”: “”, “module_stdout”: “/bin/sh: 1: /usr/bin/python: not found\r\n”, “msg”: “MODULE FAILURE”, “parsed”: false}
fatal: [adproxy1]: FAILED! =&amp;gt; {“changed”: false, “failed”: true, “module_stderr”: “”, “module_stdout”: “/bin/sh: 1: /usr/bin/python: not found\r\n”, “msg”: “MODULE FAILURE”, “parsed”: false}&lt;/p&gt;

&lt;p&gt;NO MORE HOSTS LEFT &lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;*
 [WARNING]: Could not create retry file ‘playbook_appdata_proxy.retry’.         [Errno 2] No such file or directory: ‘’&lt;/p&gt;

&lt;p&gt;PLAY RECAP &lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;***
adproxy1                   : ok=0    changed=0    unreachable=0    failed=1
adproxy2                   : ok=0    changed=0    unreachable=0    failed=1&lt;/p&gt;
</description>
        <pubDate>Wed, 23 Nov 2016 12:08:35 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/2016/11/23/aws-tech-note-problems-with-ubuntu-16-04-and-ansible.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/2016/11/23/aws-tech-note-problems-with-ubuntu-16-04-and-ansible.html</guid>
        
        
      </item>
    
      <item>
        <title>Crazy Ansible UTF-8 Error</title>
        <description>&lt;p&gt;issue is that instance_id was set ot a string ar not a hash_&lt;/p&gt;

&lt;p&gt;from_email -@&lt;/p&gt;
</description>
        <pubDate>Wed, 23 Nov 2016 11:52:16 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/2016/11/23/crazy-ansible-utf-8-error.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/2016/11/23/crazy-ansible-utf-8-error.html</guid>
        
        
      </item>
    
      <item>
        <title>pkill Rocks</title>
        <description>&lt;p&gt;One of the singularly best things about Unix / Linux is that even after using it for literally years, there is always a new thing to learn.  The best way to learn something is to just get frustrated and then &lt;strong&gt;google&lt;/strong&gt;.  There is always a different way to do it – sometimes it is simple i.e. better and sometimes it might be really hard but there is always a different way.&lt;/p&gt;

&lt;p&gt;The problem I had the other day was I kept hitting open file handle limits.  I’m not sure why but when this happens it is generally reboot time and I hate reboot time so anything I can do to keep my box alive long enough to get the job done makes me just a bit less cranky.  In this case I had a strikingly large number of terminal windows open and I needed to get them shut down.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Activity Monitor wasn’t helpful and the only thing that was responsive was a sole instance of the Node JS based HyperTerm.  And, oddly enough, that was the one bit of my system which was responsive.  I knew that I could do ps auwwx&lt;/td&gt;
      &lt;td&gt;grep iTerm but, well, that would just suck:&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/pkill_rocks_01.png&quot; alt=&quot;pkill_rocks&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A quick google for &lt;em&gt;kill process by name&lt;/em&gt; led me &lt;a href=&quot;http://stackoverflow.com/questions/160924/how-can-i-kill-a-process-by-name-instead-of-pid&quot;&gt;here&lt;/a&gt; and it was a great illustration of the swiss army knife nature of Unix.  Options ranged from &lt;em&gt;pkill&lt;/em&gt; to &lt;em&gt;killall&lt;/em&gt; to &lt;em&gt;shell one liners&lt;/em&gt;.  pkill, while risky, worked great:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/pkill_rocks_02.png&quot; alt=&quot;pkill_rocks&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;risky&quot;&gt;Risky&lt;/h1&gt;

&lt;p&gt;pkill is a pattern matching tool so if you’re not careful it will take out anything that matches.  Here’s a &lt;a href=&quot;https://linux.die.net/man/1/pkill&quot;&gt;pkill man page&lt;/a&gt; and use with care but I surely like it.&lt;/p&gt;
</description>
        <pubDate>Wed, 23 Nov 2016 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/unix/2016/11/23/pkill-rocks.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/unix/2016/11/23/pkill-rocks.html</guid>
        
        <category>linux</category>
        
        <category>unix</category>
        
        <category>command_line</category>
        
        <category>osx</category>
        
        
        <category>unix</category>
        
      </item>
    
      <item>
        <title>Painful Checks I have Written as an Entrepreneur</title>
        <description>
</description>
        <pubDate>Tue, 22 Nov 2016 09:36:58 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/2016/11/22/painful-checks-i-have-written-as-an-entrepreneur.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/2016/11/22/painful-checks-i-have-written-as-an-entrepreneur.html</guid>
        
        
      </item>
    
      <item>
        <title>visudo On OSX Sierra</title>
        <description>&lt;p&gt;Having just gotten OSX Sierra on my new Macbook Pro, I added myself to the sudoers file and key getting sudo issues.  I found the answer on &lt;a href=&quot;http://stackoverflow.com/questions/39474074&quot;&gt;Stack Overflow&lt;/a&gt;.  Essentially there is an undocumented change where you need to add:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Defaults !tty_tickets
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;to the sudoers file when you run:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo visudo
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Joy oh undocumented joy.&lt;/p&gt;
</description>
        <pubDate>Tue, 22 Nov 2016 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/osx/2016/11/22/visudo-on-osx-sierra.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/osx/2016/11/22/visudo-on-osx-sierra.html</guid>
        
        <category>osx</category>
        
        <category>visudo</category>
        
        <category>mac</category>
        
        
        <category>osx</category>
        
      </item>
    
      <item>
        <title>In Defense of Facebook's Fake News Policy</title>
        <description>&lt;p&gt;I see from Dave Winer / &lt;a href=&quot;http://scripting.com/2016/11/20/whyZuckMustBeCareful.html&quot;&gt;Scripting&lt;/a&gt; that my old colleague, Scott Rafer, has come out swinging and is claiming&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“I’ve been trying to rationalize Mark Zuckerberg’s &lt;a href=&quot;http://mediagazer.com/161119/p1#a161119p1&quot;&gt;behavior&lt;/a&gt;, and all I can come up with is that he is secretly pro Trump. He can’t admit or too much of his workforce would quit starting with &lt;a href=&quot;https://en.wikipedia.org/wiki/Sheryl_Sandberg&quot;&gt;Sheryl Sandberg&lt;/a&gt;. But the behavior around defending Peter Thiel and denying the influence of fake news and Facebook’s place in it only leads me one place.” Source [https://www.facebook.com/rafer/posts/10154464766356329?pnref=story]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now I don’t know Mark Zuckerberg but I do know Dave Winer and once upon a time I hired Scott Rafer and then I worked for him.  I have tremendous respect for Dave and for Scott but I think that there are two separate and distinct issues here:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Trump&lt;/li&gt;
  &lt;li&gt;Fake News&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;trump&quot;&gt;Trump&lt;/h1&gt;

&lt;p&gt;Generally I don’t comment on political matters; the last time I actually cared about a candidate was Perot.  We live in a democracy and everyone is allowed, nay, &lt;strong&gt;encouraged&lt;/strong&gt; to have their own opinion.  The election happened and Trump was elected – we all need to accept that and begin moving on.  Not one of us actually know what is going to happen and this is all now speculation.  Just a few general, global and national political observations:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The US’s two party system is broken and needs to change and it has been needed for years.  Trump and Bernie Sanders were both manifestations of this.&lt;/li&gt;
  &lt;li&gt;Italy survived &lt;a href=&quot;https://en.wikipedia.org/wiki/Silvio_Berlusconi&quot;&gt;Berlusconi&lt;/a&gt;; we will survive Trump.&lt;/li&gt;
  &lt;li&gt;Politics in the rest of the world is far, far more entertaining than in the U.S.  Personally I’m interested to just watch the upcoming show.&lt;/li&gt;
  &lt;li&gt;When did we forget the rules of polite civility?  Shouldn’t we be allowed to have our own opinions.&lt;/li&gt;
  &lt;li&gt;If Zuckerberg supports Trump then will Sheryl Sandberg really quit a job which has made her a &lt;a href=&quot;https://www.google.com/search?q=sheryl+sandberg+net+worth&amp;amp;oq=sheryl+sandberg+net&amp;amp;aqs=chrome.0.0j69i57j0l4.5155j0j7&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8&quot;&gt;billionaire&lt;/a&gt;?  I don’t think so; come on.  Self interest always trumps everything else (like what I dd there?)&lt;/li&gt;
  &lt;li&gt;Peter Thiel can support anyone he damn well pleases.  So can you or I.  Personally I think he’s morally courageous for taking the position he did – whether or not I agree with it.&lt;/li&gt;
  &lt;li&gt;The US has had bad presidents before and we survived it. And we will survive Trump.  We are a 250 year old country that has had ups and downs.  This is not the end of the republic or the world.&lt;/li&gt;
  &lt;li&gt;I don’t know whether or not the electoral college is good or bad.  Personally I think that the founding fathers were generally smart and Hamilton was among the smartest and the electoral college was Hamilton so I’d think long and hard before calling for its change.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;the-fake-news-issue&quot;&gt;The Fake News Issue&lt;/h1&gt;

&lt;p&gt;I know Scott Rafer and, honestly, I &lt;strong&gt;am a fan&lt;/strong&gt;.  But Scott does love a conspiracy theory and, in years past, he pushed me to personally blog things like this and I regretted it.  Personally I’d attribute the fake news stuff to either Hanlon’s Law or technical issues.  Let’s tackle this one by one:&lt;/p&gt;

&lt;h2 id=&quot;hanlons-law&quot;&gt;Hanlon’s Law&lt;/h2&gt;

&lt;p&gt;Hanlon’s law states:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Never attribute to malice that which is adequately explained by stupidity &lt;a href=&quot;https://en.wikipedia.org/wiki/Hanlon's_razor&quot;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Once upon a time I accused Google of malfeasance which turned out to be a mistake that I made.  I learned my lesson from that one. So one possibility is that Facebook is just stupid.  I don’t actually think that’s true but it is a possibility.&lt;/p&gt;

&lt;h2 id=&quot;fake-news-is-a-technical-problem-not-a-political-thing&quot;&gt;Fake News is a Technical Problem Not a Political Thing&lt;/h2&gt;

&lt;p&gt;I know a few readers here aren’t hugely technical so the Fake News thing needs to be explained.  Some people are alleging that the results of the recent election were twisted due to “fake news” that fed into people’s facebook news feed.  Honestly it is the Internet people – you can find websites that support just about anything – and we all used to like that.  Now, in the wake of the favored candidate losing, we all seem to want something different.&lt;/p&gt;

&lt;p&gt;Here’s &lt;a href=&quot;https://backchannel.com/according-to-snopes-fake-news-is-not-the-problem-4ca4852b1ff0#.ka1jm96x6&quot;&gt;commentary citing the well known Snopes&lt;/a&gt; on the issue.  Interestingly she puts the blame on the traditional media:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The problem, Binkowski believes, is that the public has lost faith in the media broadly — therefore no media outlet is considered credible any longer. The reasons are familiar: as the business of news has grown tougher, many outlets have been stripped of the resources they need for journalists to do their jobs correctly. “When you’re on your fifth story of the day and there’s no editor because the editor’s been fired and there’s no fact checker so you have to Google it yourself and you don’t have access to any academic journals or anything like that, you will screw stories up,” she says.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And don’t think that this is new – the &lt;a href=&quot;https://en.wikipedia.org/wiki/Dateline_NBC&quot;&gt;Dateline NBC truck issue&lt;/a&gt; happened in 1992 long before the Internet mattered.  The media has been losing our trust for years and years.&lt;/p&gt;

&lt;p&gt;I think that it is important to recognize that Fake News is a technical problem, specifically a spam detection problem – and since it impinges on free speech issues – it is a particularly thorny technical problem.  I feel technically qualified to talk about this because I have specific competencies in spam detection having done this now at least three times in my career:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;email spam in 2002 which culminated in a shipping product, Inbox Buddy&lt;/li&gt;
  &lt;li&gt;blog spam in 2004 / 2005 at Feedster&lt;/li&gt;
  &lt;li&gt;twitter spam Fall 2016, personal project, unreleased&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Fighting spam is a classic attackers / defenders problem and there are always more attackers than defenders.  If you build something of value online then people will find a way to twist it to their own means.  That’s just a fact.  And your Facebook news feed is valuable because that’s where the people are.&lt;/p&gt;

&lt;h2 id=&quot;the-princeton-students-fake-news-code&quot;&gt;The Princeton Student’s Fake News “Code”&lt;/h2&gt;

&lt;p&gt;A few students from Princeton have received acclaim recently for their &lt;a href=&quot;http://www.businessinsider.com/students-solve-facebooks-fake-news-problem-in-36-hours-2016-11&quot;&gt;Fake News Solution&lt;/a&gt; which was written in 36 hours and my comment is &lt;strong&gt;big deal&lt;/strong&gt;.  I could likely take a stab at it myself in 36 hours and “solve” it.  But that’s not the same thing as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;solving it in an ongoing fashion&lt;/li&gt;
  &lt;li&gt;solving it in a performant manner&lt;/li&gt;
  &lt;li&gt;solving it for every user not just yourself&lt;/li&gt;
  &lt;li&gt;integrating it with what is likely a very complex code base&lt;/li&gt;
  &lt;li&gt;dealing with the N level of edge cases&lt;/li&gt;
  &lt;li&gt;keeping it up to date&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I lost well over a year of my life to battling blog spam and the scale of the Fake News problem is far beyond what I dealt with.  So, yes, they wrote code in 36 hours – so could anyone else – and fixing the Facebook News Feed is far, far harder.&lt;/p&gt;

&lt;h2 id=&quot;does-facebook-profit-from-fake-news&quot;&gt;Does Facebook Profit from “Fake News”&lt;/h2&gt;

&lt;p&gt;Of course they do.  Facebook profits from traffic and if people’s news feed contains “fake news” they are likely to consume more of it.  But that isn’t a crime and I’m going to raise the issue of the National Inquirer which seems to publish whatever they want.  If tabloid journalists can do that then why can’t Facebook put into the news feed “fake news”?  Is this even wrong?  Facebook is &lt;strong&gt;not&lt;/strong&gt; the New York Times and it isn’t supposed to be.&lt;/p&gt;

&lt;h2 id=&quot;even-facebook-fixes-fake-news&quot;&gt;Even Facebook Fixes “Fake News”&lt;/h2&gt;

&lt;p&gt;One of the problems here is that spam detection is often like obscenity and I refer to the 1964 Supreme Court Justice Potter Stewart:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I shall not today attempt further to define the kinds of material I understand to be embraced within that shorthand description [“hard-core pornography”], and perhaps I could never succeed in intelligibly doing so. But I know it when I see it, and the motion picture involved in this case is not that.[4] &lt;a href=&quot;https://en.wikipedia.org/wiki/I_know_it_when_I_see_it&quot;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I think that it is important to recognize that even if Facebook “fixes” this, they, the Facebook Company, is in a no win situtation.  Just as we are still battling email spam in 2016, we will be facing Facebook Fake News 20 years from now.  There are also important issues of free speech here.  The blogging world has fought mightily to be taken seriously as a journalistic source.  Heck &lt;a href=&quot;http://www.scripting.com&quot;&gt;Dave Winer&lt;/a&gt; himself has championed this on how many different occasions – it was among the very reasons he went to &lt;a href=&quot;https://cyber.harvard.edu/&quot;&gt;Berkman&lt;/a&gt; in the first place.&lt;/p&gt;

&lt;p&gt;There is a very easy way for Facebook to solve Fake News – simply reduce the inputs in your news feed to only &lt;strong&gt;official&lt;/strong&gt; news organizations.  That would solve it for sure but:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Is that really what people want?&lt;/li&gt;
  &lt;li&gt;Don’t we trust people enough to let them see everything and make their own decisions?&lt;/li&gt;
  &lt;li&gt;Ultimately people have to be personally responsible for what they read and what they believe.&lt;/li&gt;
  &lt;li&gt;Just as people have read the National Enquirer for years and years and drawn their news from it, isn’t this the same damn thing?&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;The Fake News issue is, in my opinion, a technical issue.  I actually know one of the Data Scientists on the news feed team (he worked for me in a previous life) and I actually asked him about the whole “Facebook is suppressing right wing stuff” that came out a few months ago.  He assured me that when that happened Facebook treated it professionally – all hands on deck, code reviews and such – and I believe him.  I really, really, really don’t think that Facebook or Zuckerberg have any personal stake in this – it is just a technical issue.  And I know for a fact that any spam problem is damn hard to solve – if it can be solved at all.  Generally spam problems are a matter of an ongoing battle that you never actually win.  I regard my period fighting blog spam as a personal vietnam and I suspect that Facebook feels the same way.&lt;/p&gt;
</description>
        <pubDate>Tue, 22 Nov 2016 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/facebook/2016/11/22/in-defense-of-facebook-s-fake-news-policy.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/facebook/2016/11/22/in-defense-of-facebook-s-fake-news-policy.html</guid>
        
        <category>facebook</category>
        
        <category>trump</category>
        
        <category>zuckerberg</category>
        
        <category>spam</category>
        
        
        <category>facebook</category>
        
      </item>
    
      <item>
        <title>Buying a Mac as a Developer in Fall 2016</title>
        <description>&lt;p&gt;So my buddy Nick &lt;a href=&quot;https://nickjanetakis.com/blog/i-almost-rage-bought-a-macbook-pro&quot;&gt;almost rage purchased a Mac&lt;/a&gt; the other day and I thought that given that I sit at an 8 foot long custom built computing desk with six different MacBook computers on it, and a nerd closet of doom with 3 on the shelf and 2 more upstairs for the family’s use, perhaps I should write down for him the different issues with respect to buying a developer machine in Fall 2016.  As I write this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I am in my PostMac phase where I’m actively trying to use an Ubuntu-Mate install on an Intel NUC as a primary development tool&lt;/li&gt;
  &lt;li&gt;I just bought a brand new MacBook Pro (last generation)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So I’m clearly deeply divided but perhaps writing all this down will help either myself or at least someone else sort it out.&lt;/p&gt;

&lt;p&gt;As I write this Apple has the following offerings each of which is a possibility for a developer:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MacBook 2016&lt;/li&gt;
  &lt;li&gt;MacBook Air 2015&lt;/li&gt;
  &lt;li&gt;MacBook Pro w/o TouchBar&lt;/li&gt;
  &lt;li&gt;MacBook Pro w/ Touchbar&lt;/li&gt;
  &lt;li&gt;MacBook Pro 2015&lt;/li&gt;
  &lt;li&gt;iMac&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each of these is discussed below.  Just as an overview, my buddy Nick isn’t part of the “Apple Faithful” at present.  He doesn’t bleed six colors as we used to say (I date back to the Apple II days and my first Mac was a Plus) which means there are all aspects of the ecosystem which he doesn’t yet get.  Nick is a Windows user, a Docker Captain, a Udemy instructor and an all around good guy.  His almost rage buy was inspired by frustration with Microsoft and its not dissimilar to my rage moving to Ubuntu-Mate.&lt;/p&gt;

&lt;h1 id=&quot;developer-or-tourist&quot;&gt;Developer or Tourist?&lt;/h1&gt;

&lt;p&gt;The first thing to understand if you’re going to enter the Apple ecosystem is are you doing it as a developer or as a tourist.  If you just want a Mac for light consumption, for syncing an iPhone or for just answering the question - “is this for me” then you could easily buy either of these:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MacBook 2016&lt;/li&gt;
  &lt;li&gt;MacBook Air 2015&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The new MacBook 2016 is the one I just bought my wife as she decided to goto graduate school this past October for her master’s degree.  It is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;tiny&lt;/li&gt;
  &lt;li&gt;elegant&lt;/li&gt;
  &lt;li&gt;beautiful&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Personally I despite the new Apple low travel keyboard but in time I could likely move from despise to gentle loathing.  Given that I still use ThinkPad keyboards with trackpoints for my “desktop” Mac usage, that’s actually a fair compliment.  The new MacBook 2016 is limited to 8 gigs of RAM which I don’t feel is acceptable for a developer but if your needs aren’t serious then that is likely ok.&lt;/p&gt;

&lt;p&gt;I’m tying this out on a MacBook Air 13” Early 2014 model which has been an absolute workhorse beast of a computer for me.  Even though it only has 8 gigs of RAM, I’ve done more with this MacBook I think than any other and it has been a rock star for me.  If Apple had just offered an upgrade of this exact machine with 16 gigs of RAM, I’d have bought it in a heart beat – I love it just that much.  When my 15” MacBook Pro decided that it was useless, and only redeemable by &lt;a href=&quot;https://fuzzygroup.github.io/blog/postmac/2016/11/05/life-in-a-postmac-world.html&quot;&gt;installing Elementary OS&lt;/a&gt;, this was the box that saved my professional life.  It runs I can’t tell you how many different code bases and the only drawback is really the amount of RAM.  It also has the advantage of a fantastic keyboard and an ok battery.  The CPU kind of sucks and the fan makes a bunch of noise but I do love this damn little box.&lt;/p&gt;

&lt;h1 id=&quot;sidebar-understanding-what-mac-you-have--upgrade-tools&quot;&gt;Sidebar: Understanding What Mac You Have / Upgrade Tools&lt;/h1&gt;

&lt;p&gt;One of the first weird things about Apple hardware to understand is that Apple has relatively few model names and they just keep reusing them with internal, non visual suffixes like Mid 2013 / Early 2015, etc.  What you have to do is this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Apple Menu
About this Mac
Support
Specifications
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here’s the visual flow:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/which_mac_01_apple_menu.png&quot; alt=&quot;which_mac_01_apple_menu.png&quot; /&gt;
&lt;img src=&quot;/blog/assets/which_mac_02_about_this_mac.png&quot; alt=&quot;which_mac_02_about_this_mac.png&quot; /&gt;
&lt;img src=&quot;/blog/assets/which_mac_03_specifications.png&quot; alt=&quot;which_mac_03_specifications.png&quot; /&gt;
&lt;img src=&quot;/blog/assets/which_mac_04_specifications_browser.png&quot; alt=&quot;which_mac_04_specifications_browser.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This will take you to a &lt;a href=&quot;http://support-sp.apple.com/sp/index?page=cpuspec&amp;amp;cc=G5RP&amp;amp;lang=en_US&quot;&gt;web page like this&lt;/a&gt; which explains exactly what your Mac is.  The name at the top like &lt;em&gt;MacBook Air (13-inch, Early 2014)&lt;/em&gt; is what you can give to &lt;a href=&quot;http://www.crucial.com/&quot;&gt;Crucial&lt;/a&gt; if you’re looking to upgrade something.  Yes Crucial is still vital if you’re using a Mac.  Another great resource is &lt;a href=&quot;http://www.ifixit.com&quot;&gt;iFixit.com&lt;/a&gt; if you’re looking to understand exactly how to install the upgrade from Crucial you just bought.  And yes there are special tools involved – just do whatever iFixit tells you to do and its usuallk ok.&lt;/p&gt;

&lt;p&gt;NOTE: RAM on MacBooks is soldered in.  If you don’t get it at purchase time you aren’t upgrading.  Crucial’s upgrades on RAM or Macs are either for older models or for Desktop Macs (the iMac line).&lt;/p&gt;

&lt;h1 id=&quot;so-you-want-to-develop-on-a-mac&quot;&gt;So You Want to Develop on a Mac&lt;/h1&gt;

&lt;p&gt;If you’re serious about dipping into the Apple waters then here are your options in Fall 2016:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MacBook Pro w/o TouchBar&lt;/li&gt;
  &lt;li&gt;MacBook Pro w/ Touchbar&lt;/li&gt;
  &lt;li&gt;MacBook Pro 2015&lt;/li&gt;
  &lt;li&gt;iMac&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each of these has distinct pros and cons.  They all have pros but I think the cons are more illuminating so let’s elaborate on them:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;MacBook Pro w/o TouchBar&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Pros
        &lt;ul&gt;
          &lt;li&gt;available today&lt;/li&gt;
          &lt;li&gt;cheaper&lt;/li&gt;
          &lt;li&gt;Light&lt;/li&gt;
          &lt;li&gt;At the time of this writing no ability to run Linux; maybe it will get sorted out; maybe not&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Cons
        &lt;ul&gt;
          &lt;li&gt;Not really a Macbook Pro imho&lt;/li&gt;
          &lt;li&gt;Really a big Macbook Air&lt;/li&gt;
          &lt;li&gt;Only 2 USB c ports&lt;/li&gt;
          &lt;li&gt;Dongle, Dongle, Dongle&lt;/li&gt;
          &lt;li&gt;No HDMI port&lt;/li&gt;
          &lt;li&gt;Keyboard&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MacBook Pro w/ Touchbar&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Pros
        &lt;ul&gt;
          &lt;li&gt;4 USB C ports&lt;/li&gt;
          &lt;li&gt;The Touchbar&lt;/li&gt;
          &lt;li&gt;Light&lt;/li&gt;
          &lt;li&gt;At the time of this writing no ability to run Linux; maybe it will get sorted out; maybe not&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Cons
        &lt;ul&gt;
          &lt;li&gt;4 USB C ports - only 2 of which are the high speed thunderbolt flavor&lt;/li&gt;
          &lt;li&gt;Expensive&lt;/li&gt;
          &lt;li&gt;The Touchbar&lt;/li&gt;
          &lt;li&gt;No function keys&lt;/li&gt;
          &lt;li&gt;No esc key&lt;/li&gt;
          &lt;li&gt;Only 16 gigs of RAM; DAMN YOU APPLE!&lt;/li&gt;
          &lt;li&gt;Dongle, Dongle, Dongle&lt;/li&gt;
          &lt;li&gt;No HDMI port&lt;/li&gt;
          &lt;li&gt;Keyboard&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MacBook Pro 2015&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Pros
        &lt;ul&gt;
          &lt;li&gt;Great Keyboard&lt;/li&gt;
          &lt;li&gt;A full array of ports - USB, Thunderbolt, HDMI&lt;/li&gt;
          &lt;li&gt;16 gigs of RAM is supported&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Cons
        &lt;ul&gt;
          &lt;li&gt;Older Hardware&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;iMac&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Pros
        &lt;ul&gt;
          &lt;li&gt;More than 16 gigs of RAM&lt;/li&gt;
          &lt;li&gt;It really is pretty&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Cons
        &lt;ul&gt;
          &lt;li&gt;Its a desktop&lt;/li&gt;
          &lt;li&gt;Painful to upgrade; I’m looking into upgrading a Mid 2011 iMac my family uses and the process scares the hell out of me&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As I look at this list I have to wonder if my decision to try working on an Intel NUC using Ubuntu-Mate was entirely rational.  An iMac would have gotten me the more than 16 gigs of RAM which I personally felt was necessary and that would have addressed my &lt;strong&gt;immediate&lt;/strong&gt; needs.  Now, that said, I’m a professional developer and, recently, it feels that Apple’s path and mine are diverging, specifically:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the increasingly locked down nature of OSX is at direct odds with what a developer needs&lt;/li&gt;
  &lt;li&gt;I don’t feel that Apple is remotely “fair” with respect to storage capacities on boxes / iPhones given modern picture density; there’s a huge space / capacity mismatch between high megapixel phones and lots of videos with respect to selling computers with paltry SSD capacity&lt;/li&gt;
  &lt;li&gt;poor Unix support.  I can’t find the links right now but we’re seeing poor support / broken libraries for core Unix stuff that shouldn’t be broken.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://fuzzygroup.github.io/blog/osx/2016/11/22/visudo-on-osx-sierra.html&quot;&gt;visudo issues on Mac OS Sierra&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I’m not the only one who feels this way:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://fuzzygroup.github.io/blog/tag.html#postmac&quot;&gt;My Post Mac Writings&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=12825849&quot;&gt;End of the Line for Macbook Pro&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=12822913&quot;&gt;Ask HN: What Do I Do Know That Apple Macs Suck&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=12818724&quot;&gt;Thinking of Going Purely Open Source in 2017&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=12810732&quot;&gt;What Will You Use Next for Development&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now there’s some level of whining here – and I’m clearly among them – because I did just hand Apple almost $3,000 of my hard earned personal money for a new MacBook but there is one thing that I haven’t mentioned about Apple Hardware and it is one of the two close out topics.&lt;/p&gt;

&lt;h1 id=&quot;apple-hardware-is-fantastic&quot;&gt;Apple Hardware Is Fantastic&lt;/h1&gt;

&lt;p&gt;When you separate out RAM, price and performance, one thing stands out about Apple hardware – when it matches what you need – the pure hardware is fantastic.  Specifically:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Macs just plain feel good; they have a level of fit and finish that I don’t don’t think I’ve ever seen else where (Intel’s NUC is a happy exception)&lt;/li&gt;
  &lt;li&gt;Macs tend to last a long time.  Examples:
    &lt;ul&gt;
      &lt;li&gt;My family 2011 iMac which the kids use daily is still running strong&lt;/li&gt;
      &lt;li&gt;Every Macbook or Macbook pro I’ve bought back to Snow Leopard still works&lt;/li&gt;
      &lt;li&gt;Generally a Linux version installs well on older MacBooks which is a great way to revive an older machine&lt;/li&gt;
      &lt;li&gt;Screws don’t come out; the chassis’s don’t bend or flex; this sounds minor but in the 90s I lost 3 separate Toshiba / Dell laptops due to screws coming loose and rattling around until they caused a short&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Macs have a high resale value&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;so-should-nick-buy-a-mac&quot;&gt;So Should Nick Buy a Mac?&lt;/h1&gt;

&lt;p&gt;So I started this with the tale of my buddy Nick almost buying a MacBook Pro.  That wasn’t a metaphor for what should I do – Nick is a real person who is telling his own tale &lt;a href=&quot;https://nickjanetakis.com/blog/i-almost-rage-bought-a-macbook-pro&quot;&gt;here&lt;/a&gt;.  My recent choice was clear – &lt;strong&gt;buy the top end of the previous generation&lt;/strong&gt;.  This got me the RAM upgrade I wanted, the keyboard I adore and it freed me from Dongle, Dongle, Dongle Hell.  Apple’s choice of USB-C everywhere is bold but it isn’t for me.  I do too many public facing events to NOT have an HDMI port on my primary travel machine.  And the incremental hardware advance isn’t sufficient in my opinion to justify the cost in Fall 2016.  If Apple had been able to give me more than 16 gigs of RAM then I could have dealt with likely everything else but more than 16 gigs was my key issue.&lt;/p&gt;

&lt;p&gt;I don’t know if Nick should buy a Mac.  For a professional developer buying into a platform is a major decision.  The amount of learning that you have to do if you’re serious is immense and the cost of the machine, unfortunately, is a rounding error when compared to the value of your time.  I remember how hard it was to transition from Windows to OSX back in 2006 in my post Feedster days and it was expensive in terms of time.  Personally I find it hard to think of Apple as a professional developer ecosystem in Fall 2016.  It feels like Apple is trying to become a mobile computing company and developers are just a wart on that.  I remember discussing this with colleagues as early as 2012 / 2013 and it does seem to be coming to pass.  Honestly it feels to me that committing to a Linux platform makes more sense for Nick but that’s just me.  His opinion likely varies as it should.  Personally I’m pissed as hell that the platform I’ve given more than a decade too seems to be petering out and that makes me more than a bit irrational on the matter.&lt;/p&gt;
</description>
        <pubDate>Tue, 22 Nov 2016 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/mac/2016/11/22/buying-a-mac-as-a-developer-in-fall-2016.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/mac/2016/11/22/buying-a-mac-as-a-developer-in-fall-2016.html</guid>
        
        <category>mac</category>
        
        <category>osx</category>
        
        <category>rage</category>
        
        
        <category>mac</category>
        
      </item>
    
  </channel>
</rss>
