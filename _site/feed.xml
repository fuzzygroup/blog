<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>FuzzyBlog</title>
    <description>Scott Johnson writing about the usual array of nerd stuff: AWS / Ansible / Ruby / Rails / Elixir / Misc.
</description>
    <link>https://fuzzygroup.github.io/blog/</link>
    <atom:link href="https://fuzzygroup.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 04 Jan 2017 20:12:37 -0500</pubDate>
    <lastBuildDate>Wed, 04 Jan 2017 20:12:37 -0500</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title></title>
        <description>&lt;p&gt;rake task for copying in validations&lt;/p&gt;

&lt;p&gt;http://stackoverflow.com/questions/11372484/rails-put-validation-in-a-module-mixin&lt;/p&gt;

&lt;p&gt;require ‘api_key_validations’
  include ApiKeyValidations&lt;/p&gt;

&lt;p&gt;module ApiKeyValidations
  extend ActiveSupport::Concern&lt;/p&gt;

&lt;p&gt;included do
    validates_presence_of :name
    validates_presence_of :user
    #validates :name, :length =&amp;gt; { :minimum =&amp;gt; 2 }, :presence =&amp;gt; true, :uniqueness =&amp;gt; true
    #validates :name_seo, :length =&amp;gt; { :minimum =&amp;gt; 2 }, :presence =&amp;gt; true, :uniqueness =&amp;gt; true
  end
end&lt;/p&gt;
</description>
        <pubDate>Wed, 04 Jan 2017 08:43:11 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/2017/01/04/breaking-the-rails-monolith-apart-01-validations.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/2017/01/04/breaking-the-rails-monolith-apart-01-validations.html</guid>
        
        
      </item>
    
      <item>
        <title>Getting Started with MongoDB and Rails</title>
        <description>&lt;p&gt;I am a well known MySQL fan if not fanatic.  I’ve used MySQL since 1999 and while I’ve had the occasional issue here and there, I’ve been immensely happy with it overall.  But times change and now I find myself using Mongo in the context of a Rails app and, well, I’m a bit lost.  This post writes down what I’ve learned – mostly about the operational side of Mongo and getting started.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Assumptions&lt;/strong&gt;: Rails 5 / Ruby 2.3 / Mongo 3.4 / OSX; currently building a rails application called &lt;strong&gt;api&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;the-error-message&quot;&gt;The Error Message&lt;/h1&gt;

&lt;p&gt;What drove me into writing all of this down was I kept hitting this error message:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Mongoid::Errors::NoClientConfig: message:   No configuration could be found for a client named 'default'.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;useful-reading&quot;&gt;Useful Reading:&lt;/h1&gt;

&lt;p&gt;I read a number of things including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://gorails.com/guides/setting-up-rails-4-with-mongodb-and-mongoid&quot;&gt;GoRails&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.tutorialspoint.com/mongodb/mongodb_create_database.htm&quot;&gt;TutorialsPoint&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/15354936/rails-engine-mongoid-no-configuration-could-be-found-for-a-session-named-def&quot;&gt;StackOverflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;installation&quot;&gt;Installation&lt;/h1&gt;

&lt;p&gt;I used HomeBrew to install Mongo:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;brew install mongodb
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;getting-into-the-shell&quot;&gt;Getting into the Shell&lt;/h1&gt;

&lt;p&gt;After Mongo is installed you can get into the Mongo shell with the command:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mongo
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;creating-your-first-database&quot;&gt;Creating Your First Database&lt;/h1&gt;

&lt;p&gt;Oddly the use command creates the database.  If the database doesn’t exist then it is automatically created:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;use api_development ENTER
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;making-mongo-work-under-rails&quot;&gt;Making Mongo Work Under Rails&lt;/h1&gt;

&lt;p&gt;Getting to this stage wasn’t all that hard.  The problem here is that I’ve never setup a new rails app from scratch with Mongo.  I’ve worked on Mongo stuff in the past but this was an entirely new thing. Here were the steps I followed.&lt;/p&gt;

&lt;h2 id=&quot;getting-rid-of-activerecord-in-your-application&quot;&gt;Getting Rid of ActiveRecord in Your Application&lt;/h2&gt;

&lt;p&gt;When you create your rails app, you need to add the –skip-active-record flag to turn off ActiveRecord entirely:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rails new api --skip-active-record --api
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Note: This is an api mode Rails application so I’m passing in –api.&lt;/p&gt;

&lt;h2 id=&quot;creating-the-mongoidyml-file&quot;&gt;Creating the mongoid.yml File&lt;/h2&gt;

&lt;p&gt;rails g mongoid:config&lt;/p&gt;

&lt;h2 id=&quot;getting-mongoidyml-loaded&quot;&gt;Getting mongoid.yml Loaded&lt;/h2&gt;

&lt;p&gt;touch config/initializers/mongo.yml&lt;/p&gt;
</description>
        <pubDate>Wed, 04 Jan 2017 06:44:54 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/rails/2017/01/04/getting-started-with-mongodb-and-rails.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/rails/2017/01/04/getting-started-with-mongodb-and-rails.html</guid>
        
        <category>rails</category>
        
        <category>mongo</category>
        
        
        <category>rails</category>
        
      </item>
    
      <item>
        <title>Capistrano Failure - Asset Manifest Not Created</title>
        <description>&lt;p&gt;I setup a new Rails application using Capistrano earlier today and hit a fair number of odder than normal &lt;a href=&quot;http://capistranorb.com/&quot;&gt;Capistrano&lt;/a&gt; issues.  The biggest issue was around the asset pipeline and the asset manifest not being created.  The error message revolved around “cannot stat (pathname) manifest file”.&lt;/p&gt;

&lt;p&gt;Digging into the issue with Google revealed that it actually is a problem with Capistrano itself.  Here’s the &lt;a href=&quot;https://github.com/capistrano/rails/issues/111&quot;&gt;thread&lt;/a&gt;.  Upgrading to at least Capistrano 1.1.8 fixes this problem.&lt;/p&gt;
</description>
        <pubDate>Wed, 04 Jan 2017 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/rails/2017/01/04/capistrano-failure-asset-manifest-not-created.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/rails/2017/01/04/capistrano-failure-asset-manifest-not-created.html</guid>
        
        <category>rails</category>
        
        <category>capistrano</category>
        
        <category>asset_pipeline</category>
        
        
        <category>rails</category>
        
      </item>
    
      <item>
        <title>Ansible Unable to Find Boto Errors</title>
        <description>&lt;p&gt;Over the past several days I have been doing quite a bit of work with the ansible &lt;a href=&quot;http://docs.ansible.com/ansible/ec2_module.html&quot;&gt;EC2&lt;/a&gt; and &lt;a href=&quot;http://docs.ansible.com/ansible/ec2_ami_module.html&quot;&gt;AMI&lt;/a&gt; modules for dynamically creating instances and AMIs on AWS.  Ansible, however, doesn’t actually talk directly to AWS; it talks to AWS thru a python module named &lt;a href=&quot;https://github.com/boto/boto&quot;&gt;&lt;strong&gt;boto&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;There are a number of common problems that you might find when you the error “boto required for this module” or “unable to find boto”:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Make sure boto is installed: &lt;em&gt;sudo pip install boto&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Uninstall ansible entirely and then install it via Python: &lt;em&gt;sudo pip install ansible&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Run your playbook using sudo to ensure that the version of python is the one that comes from sudo&lt;/li&gt;
  &lt;li&gt;Eliminate &lt;em&gt;connection: local&lt;/em&gt; at the playbook level and move it to the task level&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The last one of these, eliminating connection: local, requires a bit of explaining.  Details can be found &lt;a href=&quot;https://github.com/ansible/ansible/issues/15019&quot;&gt;here&lt;/a&gt;.  When I first encountered this problem, my playbook looked like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- hosts: &quot;fi_app_metadata_monthly&quot;
  become: yes
  remote_user: ubuntu
  connection: local
  vars:
    - redis_ami_id: &quot;ami-XXXX&quot;
    - redis_security_group_id: &quot;sg-YYY&quot;
    - redis_instance_type: &quot;t2.micro&quot;
    - redis_tag_name: &quot;dynamic_redis_fi_app_metadata_update&quot;
    - redis_instance_count: 1
    - template_instance_id: &quot;i-UUUUUUUU&quot; # in future this comes in from command line
    - number_of_instances: 3                      
    - instance_type: &quot;m3.large&quot;                   
    - region: &quot;us-west-2&quot;
    - vpc_subnet_id: &quot;subnet-IIIIII&quot;
    - vpc_id: &quot;vpc-RRRR&quot;
    - group_id: &quot;sg-YYYY&quot;
    - aws_access_key: &quot;ERRERERE&quot;
    - key_name: &quot;appdata_aws&quot;
    - aws_secret_key: &quot;ERERERE&quot;
    - farm_job_name: &quot;monthly_fi_app_metadata_update_2017-01&quot;
    - farmer_address: &quot;ec2-9-9-9-9.us-west-2.compute.amazonaws.com&quot;
    - tag_name: &quot;fi_app_metadata&quot;
    - rake_task: &quot;bundle exec rake fi_farm_work:fi_app_metadata_update --trace&quot;
  roles:
    - { role: ec2_make_redis_instance_from_ami, tags: ec2_make_redis_instance_from_ami}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;When the above playbook was run, it resulted in boto not being found errors.  The solution was to remove the line &lt;em&gt;connection: local&lt;/em&gt; from the playbook and move it to the task level:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- name: make the redis instance from the ami
  # note - you used to be able to do this at the role level; now it has to be at the task level
  # note - think of this as you are setting the connection context for the task being executed
  connection: local
  ec2:
    aws_access_key: &quot;&quot;
    aws_secret_key: &quot;&quot;
    region: &quot;&quot;
    image: &quot;&quot;
    ...
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This is one of those code errors that, honestly, I just don’t understand.  From talking with another Ansible buddy, &lt;a href=&quot;https://nickjanetakis.com/&quot;&gt;Nick&lt;/a&gt;, he confirmed that it used to work at the playbook level.  Perhaps this is just one of those perplexing changes that results from other other architectural work going on at the project level.&lt;/p&gt;
</description>
        <pubDate>Wed, 04 Jan 2017 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/ansible/2017/01/04/ansible-unable-to-find-boto-errors.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/ansible/2017/01/04/ansible-unable-to-find-boto-errors.html</guid>
        
        <category>ansible</category>
        
        <category>boto</category>
        
        <category>aws</category>
        
        
        <category>ansible</category>
        
      </item>
    
      <item>
        <title>Tutorial How To Upgrade Your PS4 to 2 Terabytes of Storage</title>
        <description>&lt;p&gt;There are times when it seems like we live in a weird world of storage capacity imbalance.  We see this in two places:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;phones&lt;/li&gt;
  &lt;li&gt;gaming consoles&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For phones we see this when a 12 megapixel camera shoots 4K video but the manufacturer sells it with only 32 gigs of ram.  And for gaming consoles we see this when a manufacturer ships a device with only a 500 gb drive but every single game you play might be 10+ gigs or more in size – and every game requires a full install + a multiple gig update.&lt;/p&gt;

&lt;p&gt;My kids have a PS4 – ok its actually mine but I’ve barely played it – and having gotten them the new PSVR for Christmas, we are officially out of space.  I had to delete some installed games just to make enough space to get things installed.  Clearly this is madness.&lt;/p&gt;

&lt;p&gt;My oldest son is an Xbox One gamer mostly and he has an external drive where he can just install all his extra games and it it works &lt;em&gt;beautifully&lt;/em&gt;.  Unfortunately the PS4 &lt;strong&gt;cannot&lt;/strong&gt; play games from an external drive and while this sucks green monkey chunks, it isn’t as bad as you might think because Sony made upgrading the hard drive in a PS4 brilliantly simple.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;You need a new 9 millimeter hard drive of at least bigger than your current.  I went with 2 tb.  Here’s the &lt;a href=&quot;https://www.amazon.com/gp/product/B00FRHTSK4/ref=oh_aui_detailpage_o01_s00?ie=UTF8&amp;amp;psc=1&quot;&gt;amazon link&lt;/a&gt; for about $80.  This is in a case so you can reuse the old drive in case you want to.  You also need a backup drive so you don’t lose anything.&lt;/li&gt;
  &lt;li&gt;Here are two youtube videos to watch: &lt;a href=&quot;https://www.youtube.com/watch?v=fkIyCXbiGZs&quot;&gt;Better&lt;/a&gt; and &lt;a href=&quot;https://www.youtube.com/watch?v=YDQL0qvt3Qk&quot;&gt;ok&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Take a blank, USB FAT, FAT32 or EXFAT drive of at least the same size as the drive in your PS4 (this should be either 500 gigs or 1 tb).  Connect the drive to the PS4.&lt;/li&gt;
  &lt;li&gt;Go into the PS4 settings and turn off all power down options so the PS4 stays on no matter what.&lt;/li&gt;
  &lt;li&gt;Go into each PS4 account and sync all trophies with the PlayStation Network.&lt;/li&gt;
  &lt;li&gt;Go into the PS4 settings and do a full backup.  This will take hours and hours.  For me it was like 6 hours.&lt;/li&gt;
  &lt;li&gt;Open the case which is done by powering down the system and disconnecting all cables.  Slide the case open per the video above.  Unscrew the hard drive and add a new one.  Any 9 millimeter USB 3 hard drive should do.&lt;/li&gt;
  &lt;li&gt;After you try and power the device on you’ll get a message on screen about “ps4 update file for reinstallation” which basically means &lt;em&gt;you have no operating system so go download one&lt;/em&gt; from Sony.&lt;/li&gt;
  &lt;li&gt;Take a USB stick with at least 1.5 gigs of free space on it and create a directory PS4 and then a directory PS4/UPDATE and place the PS4UPDATE.PUP file on it which you get from this [Sony PS4 download page]https://www.playstation.com/en-us/support/system-updates/ps4/.  Insert this into the PS4 and then power it on per their instructions holding down the power button for 7 seconds and it will prompt you to re-install the OS.&lt;/li&gt;
  &lt;li&gt;Once the PS4 is actually running again then go back into settings and select backup / restore and now choose restore and the backup drive will be loaded back onto your PS4 and all games, achievements, trophies, etc will be available to you.&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Tue, 03 Jan 2017 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/gaming/2017/01/03/tutorial-how-to-upgrade-your-ps4-to-2-terabytes-of-storage.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/gaming/2017/01/03/tutorial-how-to-upgrade-your-ps4-to-2-terabytes-of-storage.html</guid>
        
        <category>tutorial</category>
        
        <category>ps4</category>
        
        
        <category>gaming</category>
        
      </item>
    
      <item>
        <title>Recent PostMac Round Up</title>
        <description>&lt;p&gt;Well a new year and people are still unhappy about the state of the Mac.  Here are some interesting links worth following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://chuqui.com/2017/01/apples-2016-in-review/&quot;&gt;Apple 2016 in Review&lt;/a&gt; &lt;a href=&quot;https://news.ycombinator.com/item?id=13307040&quot;&gt;HN Commentary&lt;/a&gt;  His point on Apple relying on data too much is likely correct.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=13307648&quot;&gt;Regular Restarts on OSX&lt;/a&gt;  Yep.  Right there with you.  Even my brand new box had to be restarted today after only 10 days of uptime.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/@searls/warm-takes-on-microsofts-surface-pro-4-580f77634d2c#.7ix3536dx&quot;&gt;Warm Takes on Microsoft’s Surface Pro 4&lt;/a&gt;  All I can say here is that I have an equivalent setup to my OSX box on Linux for my daily work and I’ve had a far easier time than he has.  Overall a fantastic read.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=13299585&quot;&gt;Using a ThinkPad for Development under Linux&lt;/a&gt; (good discussion of gear and options here and also on the &lt;a href=&quot;https://news.ycombinator.com/item?id=13286150&quot;&gt;X1 Carbon article&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Tue, 03 Jan 2017 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/postmac/2017/01/03/recent-postmac-round-up.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/postmac/2017/01/03/recent-postmac-round-up.html</guid>
        
        <category>apple</category>
        
        <category>osx</category>
        
        <category>postmac</category>
        
        <category>windows</category>
        
        
        <category>postmac</category>
        
      </item>
    
      <item>
        <title>Processing Large Datasets On AWS Using Ruby, Rails and SideKiq</title>
        <description>&lt;p&gt;Two days ago I did a data processing task which previously took me a week – overnight.  I did this using the following technology stack:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ruby&lt;/li&gt;
  &lt;li&gt;Rails&lt;/li&gt;
  &lt;li&gt;AWS&lt;/li&gt;
  &lt;li&gt;Sidekiq&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;My platform was a “cluster” of 40 m3.large AWS ec2 instances.  We all see a lot about cloud computing and using AWS / Azure / Google Cloud to do these types of large jobs but you rarely see what I think of as the hard details:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How do you get code deployed?&lt;/li&gt;
  &lt;li&gt;How do you fix bugs?&lt;/li&gt;
  &lt;li&gt;How do you deal with Capistrano failures when a box isn’t available and Capistrano doesn’t give you good feedback?&lt;/li&gt;
  &lt;li&gt;How do you get things coordinated?&lt;/li&gt;
  &lt;li&gt;How do you kick off the overall job?&lt;/li&gt;
  &lt;li&gt;How do you know when it is done?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this blog post I’m going to illustrate how I managed these things.  I’m not saying that what I did was the only way to do this.  I’m not even saying that what I did was the best way to do this.  What I am saying is that this is a practical approach to ad hoc large data processing jobs using a ruby / rails / sidekiq approach.  And I’m going to describe how I did this without using cloud formation or another large, complicated AWS or third party API.  The only external tool I used was Ansible and even that was optional.&lt;/p&gt;

&lt;p&gt;For obvious reasons of company confidentiality I can’t go into the details of what the job was.  Suffice it to say:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a “lot” of data had to be “processed”&lt;/li&gt;
  &lt;li&gt;the actions were time consuming including deliberate sleep calls to avoid being blocked on the remote end&lt;/li&gt;
  &lt;li&gt;about 35,000 discrete data items needed to be processed.  With sleep calls at a randomized 10 to 15 seconds between each call that’s 350,000 to 525,000 seconds in aggregate compute time (less if threaded but too many threads and we get blocked)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, with that said, here’s how I went about this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;build an ec2 instance as a template&lt;/li&gt;
  &lt;li&gt;deploy the current code onto it&lt;/li&gt;
  &lt;li&gt;test&lt;/li&gt;
  &lt;li&gt;make an image&lt;/li&gt;
  &lt;li&gt;launch the job on the template box&lt;/li&gt;
  &lt;li&gt;launch more copies of the image&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each of these is described below.&lt;/p&gt;

&lt;p&gt;My thanks go out to &lt;a href=&quot;http://www.nickjanetakis.com/&quot;&gt;Nick&lt;/a&gt; who was a consultant on this and paired on it throughout the process.  I also have to say thank you to &lt;a href=&quot;http://www.mikeperham.com&quot;&gt;Mike Perham&lt;/a&gt; who built &lt;a href=&quot;http://www.sidekiq.org&quot;&gt;Sidekiq&lt;/a&gt; which is at the heart of this.&lt;/p&gt;

&lt;h1 id=&quot;step-1---build-an-ec2-template-instance&quot;&gt;Step 1 - Build an EC2 “Template” Instance&lt;/h1&gt;

&lt;p&gt;The first step is that like with everything AWS you need an instance.  Picking the right instance type isn’t a topic that I’m going to cover here.  I did know that I needed a reduced thread count so I wasn’t terribly worried about memory.  We had already arranged with Amazon for up to 200 m3.large instances so that’s what I went with.  I didn’t worry terribly about whether not not I had the perfect instance type – I just used what was available.&lt;/p&gt;

&lt;p&gt;A m3.large is 7.5 gb of RAM and 8 gigs of storage so that’s perfectly fine for a Rails app of even large size.&lt;/p&gt;

&lt;p&gt;After I created the box I provisioned to run my Rails app as &lt;a href=&quot;https://fuzzygroup.github.io/blog/category.html#ansible&quot;&gt;per all the things I’ve written about using Ansible&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Once we get this machine built out we’re going to be using it as a template for making more machines later hence my referring to this as a “template” instance.&lt;/p&gt;

&lt;h1 id=&quot;step-2---deploy-the-current-code-base-with-capistrano&quot;&gt;Step 2 - Deploy the Current Code Base with Capistrano&lt;/h1&gt;

&lt;p&gt;The next step was to get my code base onto the box using Capistrano.  I just added this box to my ~/.ssh/config file and then dropped the hostname into my config/deploy/production.rb file and did a normal deploy.&lt;/p&gt;

&lt;h1 id=&quot;step-3---test-test-test&quot;&gt;Step 3 - Test, Test, Test&lt;/h1&gt;

&lt;p&gt;At this point we have a single instance running our rails application.  We need to make very, very sure that this is working correctly because our next step is to make an &lt;strong&gt;image&lt;/strong&gt; of this instance and then use AWS to launch N copies of the image.  Here’s what you want to test:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;connectivity to your database&lt;/li&gt;
  &lt;li&gt;connectivity to your redis&lt;/li&gt;
  &lt;li&gt;that the job process code works&lt;/li&gt;
  &lt;li&gt;that sidekiq works&lt;/li&gt;
  &lt;li&gt;that your thread count is tuned properly&lt;/li&gt;
  &lt;li&gt;that sidekiq starts on boot&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This last point, that sidekiq starts on boot, is the key thing that you need to ascertain.  Since sidekiq is what’s going to run our jobs and we don’t want to manually ssh into each machine, we need a way for the job to start.  If sidekiq starts on boot then job processing begins automatically when the machine starts up.&lt;/p&gt;

&lt;p&gt;The only real way to verify this is:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/sbin/reboot
log back into machine
ps auwwx | grep side
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;If you see sidekiq running then you have things configured correctly and sidekiq is starting on boot.&lt;/p&gt;

&lt;h1 id=&quot;step-4---make-an-image&quot;&gt;Step 4 - Make an Image&lt;/h1&gt;

&lt;p&gt;At this point you know that things work and you might be thinking - “Ok I now create a bunch more boxes; provision them and deploy with capistrano.”  That’s absolutely correct from a classical hosting perspective and absolutely wrong in a cloud environment.  The far easier, far faster approach is to make an &lt;em&gt;image&lt;/em&gt;. An image is simply a full disk copy of the instance that you can use to replicate the machine.  If you’re an old school PC guy then think of this as ghosting the machine.  Where installing things from scratch or even provisioning from ansible takes hours or minutes, cloning takes only a few minutes and then AWS can launch your instance in parallel so 40 machines might come up in just a minute or two.&lt;/p&gt;

&lt;p&gt;On your EC2 instance list select the instance and then on the Actions menu select Image, Create Image.  You’ll need to give it a name and the more descriptive, the better  It will take a minute or two but Amazon will make it just fine.&lt;/p&gt;

&lt;p&gt;Note: Making an instance shuts down the machine fully to make sure that any open files are backed up.  Keep this in mind since you’ll need to re-login to the machine for Step 5.&lt;/p&gt;

&lt;h1 id=&quot;step-5---launch-the-job-using-sidekiq-and-re-test-to-be-sure&quot;&gt;Step 5 - Launch the Job Using Sidekiq and Re-test to be Sure&lt;/h1&gt;

&lt;p&gt;At this point you’re ready to actually launch the job using sidekiq and start processing on one instance.  You can do this with the Rails console or a Rake task.  I prefer a rake task. Here’s what my rake task looked like:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;task :some_large_job =&amp;gt; :environment do
  search_urls = MiscClass.large_urls_collection
  search_urls.each do |search_url|
    MiscCkassWorker.perform_async(search_url)
  end
end
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;That built a redis queue and gave each method to sidekiq as an asynchronous call to be processed.  Check your sidekiq log file to make sure that things are going ok.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; If You find that there are changes you need to make then you’ll need to re-create the image as per Step 4.&lt;/p&gt;

&lt;p&gt;As long as things are looking fine then it is time for Step 6 – launching more copies of the image.&lt;/p&gt;

&lt;h1 id=&quot;step-6---launch-n-more-copies-of-the-image&quot;&gt;Step 6 - Launch N More Copies of the Image&lt;/h1&gt;

&lt;p&gt;The final step is to launch more copies of the image.  Because the job is already queued into redis and running, as soon as you launch any more instances the copy of sidekiq which runs on boot will start pulling jobs and processing them.&lt;/p&gt;

&lt;p&gt;Launch an instance the way you create any instance, only this time you’ll select that you want to make the instance from “My AMIs”] and then pick the image that you created in Step 4.  You can then tell AWS how many copies of the image you want made.  I specified 40 and then it is the normal AWS instance creation options like security groups and such.  Sadly all of these options aren’t defined solely in the instance itself.&lt;/p&gt;

&lt;p&gt;Note: The AWS command line tools or ansible code can be used to automate this further.&lt;/p&gt;

&lt;h1 id=&quot;step-7---make-your-wife-a-margarita&quot;&gt;Step 7 - Make Your Wife a Margarita&lt;/h1&gt;

&lt;p&gt;Well you can celebrate how you want but that’s what I did.  I checked the sidekiq queue the next morning and it was at 0.  I checked the database and we had generated 2,500 new records which was about what I expected.&lt;/p&gt;

&lt;h1 id=&quot;epiphany---realize-youre-making-an-appliance&quot;&gt;Epiphany - Realize You’re Making an Appliance!&lt;/h1&gt;

&lt;p&gt;I’m writing this blog post now having done this a dozen times or more. What finally made all this click in my head is the realization that what I’m doing here is making an &lt;em&gt;appliance&lt;/em&gt; or actually a &lt;em&gt;farm&lt;/em&gt; of appliances. An appliance is a tool which does one thing and does it well.  If you think about what we’ve done here is that we’ve made a ruby appliance in the form of an AWS image which eats data and (presumably) excretes some type of database record.&lt;/p&gt;

&lt;h1 id=&quot;circling-back-to-the-hard-questions-mentioned-earlier&quot;&gt;Circling Back to The Hard Questions Mentioned Earlier&lt;/h1&gt;

&lt;p&gt;At the start of this piece I mentioned a number of hard questions like deployment, bug fixing, etc.  Each of these is addressed below.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How do you get code deployed?  Capistrano is currently our tool for code deployment.  If we need to get a code fix onto the boxes we built off the template we add the ec2 host name into our SSH config and then just do a deploy.  We are currently writing a simple deployer in Ansible to make deploy easier and more integral with the entire process.  Hopefully I’ll be able to open source that at some point.  Yes we looked at &lt;a href=&quot;https://github.com/ansistrano/deploy&quot;&gt;Anistrano&lt;/a&gt; but Anistrano lacks critical rails features like bundle install which I find to be an absolute show stopper on using it.&lt;/li&gt;
  &lt;li&gt;How do you fix bugs?  We try very hard to test up front to avoid having to fix bugs on a long running job.  We streamlined our testing and focused hard on it before the jobs began deliberately to minimize bugs.&lt;/li&gt;
  &lt;li&gt;How do you deal with Capistrano failures when a box isn’t available and Capistrano doesn’t give you good feedback?  This remains an issue.  When Capistrano fails on a multiple box deploy it often isn’t clear why and Capistrano is specifically designed to stop when a single box in a deploy fails.  This contrasts nicely with Ansible which is specifically designed to continue despite failing.&lt;/li&gt;
  &lt;li&gt;How do you get things coordinated?  Coordination is always, always hard.  I have some interesting ideas on management tools for pulling this together but it isn’t time yet to implement them.&lt;/li&gt;
  &lt;li&gt;How do you kick off the overall job?  We use a Rake task which is my default for automation and is documented above.&lt;/li&gt;
  &lt;li&gt;How do you know when it is done? We don’t have a great answer yet on this.   Again I have some interesting ideas but we’re not yet at the implementation stage yet.&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Tue, 03 Jan 2017 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/rails/2017/01/03/processing-large-datasets-on-aws-using-ruby-rails-and-sidekiq.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/rails/2017/01/03/processing-large-datasets-on-aws-using-ruby-rails-and-sidekiq.html</guid>
        
        <category>ruby</category>
        
        <category>rails</category>
        
        <category>sidekiq</category>
        
        <category>aws</category>
        
        
        <category>rails</category>
        
      </item>
    
      <item>
        <title>Invalid route name, already in use 'page'</title>
        <description>&lt;p&gt;It seems that whenever you start a new Rails project you hit some kind of wackiness with respect to an error message that you’ve never seen before.  Yesterday I started a new project and I wanted to use Bootstrap for my layout.  Well I couldn’t make it work and then &lt;a href=&quot;http://dv.dasari.me&quot;&gt;Dv&lt;/a&gt; couldn’t make it work so I finally turned to the &lt;a href=&quot;https://github.com/RailsApps/&quot;&gt;RailsApps&lt;/a&gt; project and used their &lt;a href=&quot;https://github.com/RailsApps/rails-bootstrap/blob/master/config/routes.rb&quot;&gt;bootstrap template app&lt;/a&gt;.  And that worked so Huzzah! both for them and me.  Thanks Guys!&lt;/p&gt;

&lt;p&gt;Note: Dv and I have both used bootstrap on I can’t tell you how many different sites and its always a pain in the neck to initially get going.  We were using the bootstrap gem and we had the scss stuff configured correctly at least by comparing to a reference site.&lt;/p&gt;

&lt;p&gt;Today I integrated &lt;a href=&quot;https://github.com/binarylogic/authlogic&quot;&gt;authlogic&lt;/a&gt; for authentication based on a &lt;a href=&quot;https://www.sitepoint.com/rails-authentication-with-authlogic/&quot;&gt;SitePoint AuthLogic tutorial&lt;/a&gt;.  When I generated a Pages Controller and dropped a resources :pages into my routes file I got this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Invalid route name, already in use: 'page' 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;My routes file right now is like 5 lines so I was actually certain that I didn’t have pages in there already (embarrassingly though I did do a command+F anyway).  A bunch of googling turned up this &lt;a href=&quot;https://github.com/thoughtbot/high_voltage/issues/109&quot;&gt;answer&lt;/a&gt;.  Apparently the &lt;a href=&quot;https://github.com/thoughtbot/high_voltage&quot;&gt;High Voltage gem&lt;/a&gt; from &lt;a href=&quot;https://github.com/thoughtbot&quot;&gt;Thoughtbot&lt;/a&gt; automagically inserts its pages route into the routes file.  And I get the desire for simplicity but when it doesn’t even require a declaration in the Gemfile it makes tracking this kind of stuff down annoying.  Sigh.&lt;/p&gt;

&lt;p&gt;Once that was removed then I was able to get my static pages working again so that’s nice.  And I like what the High Voltage gem is actually doing.&lt;/p&gt;
</description>
        <pubDate>Thu, 29 Dec 2016 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/rails/2016/12/29/invalid-route-name-already-in-use-page.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/rails/2016/12/29/invalid-route-name-already-in-use-page.html</guid>
        
        <category>rails</category>
        
        <category>pages</category>
        
        <category>authlogic</category>
        
        <category>bootstrap</category>
        
        
        <category>rails</category>
        
      </item>
    
      <item>
        <title>Getting Past SSH Errors in OSX Sierra</title>
        <description>&lt;p&gt;If you are having problems with OSX Sierra and authenticating with github, the issue is that OSX Sierra doesn’t automatically add ssh keys by default.&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.reddit.com/r/osx/comments/52zn5r/difficulties_with_sshagent_in_macos_sierra/&quot;&gt;Reddit&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/jirsbek/SSH-keys-in-macOS-Sierra-keychain&quot;&gt;SSH Keys in MacOS Sierra&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://askubuntu.com/questions/363404/ssh-add-command-does-not-add-my-identity-to-ssh-agent&quot;&gt;Adding SSH Identities via Terminal&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://help.github.com/articles/error-permission-denied-publickey/&quot;&gt;Github SSH Add&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One solution is to add the below lines to your .ssh/config file:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Host *
  IdentityFile ~/.ssh/id_rsa
  AddKeysToAgent yes
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 29 Dec 2016 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/osx/2016/12/29/getting-past-ssh-errors-in-osx-sierra.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/osx/2016/12/29/getting-past-ssh-errors-in-osx-sierra.html</guid>
        
        <category>osx</category>
        
        <category>ssh</category>
        
        <category>sierra</category>
        
        <category>sshagent</category>
        
        
        <category>osx</category>
        
      </item>
    
      <item>
        <title>Fixing Sudo on OSX Sierra</title>
        <description>&lt;p&gt;OSX Sierra makes a number of low level changes in how things operate.  Earlier I wrote about OSX and SSH errors.  If you’re having issues with sudo then you may want to add this to the sudoers file:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo visudo (this command gets)

Defaults !tty_tickets
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;http://stackoverflow.com/questions/39474047/sudo-command-on-macos-sierra-does-not-respect-timestamp-timeout&quot;&gt;Stack Overflow Reference&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 29 Dec 2016 00:00:00 -0500</pubDate>
        <link>https://fuzzygroup.github.io/blog/osx/2016/12/29/fixing-sudo-on-osx-sierra.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/osx/2016/12/29/fixing-sudo-on-osx-sierra.html</guid>
        
        <category>osx</category>
        
        <category>sierra</category>
        
        <category>sudo</category>
        
        
        <category>osx</category>
        
      </item>
    
  </channel>
</rss>
