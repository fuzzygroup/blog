<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>FuzzyBlog</title>
    <description>Scott Johnson writing about the usual array of nerd stuff.  Ruby / Rails / Elixir.
</description>
    <link>https://fuzzygroup.github.io/blog/</link>
    <atom:link href="https://fuzzygroup.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 05 Oct 2016 20:09:36 -0400</pubDate>
    <lastBuildDate>Wed, 05 Oct 2016 20:09:36 -0400</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>Ansible Quickie - Turning Off Services On A Group of Machines</title>
        <description>&lt;p&gt;In my continuing investigation of &lt;a href=&quot;https://fuzzygroup.github.io/blog/aws/2016/10/01/aws-tutorial-10-diagnosing-ssh-failures-or-when-ping-works-but-ssh-fails.html&quot;&gt;SSH failures on my cluster of AWS boxes&lt;/a&gt;, I’ve noticed that sendmail is running on my boxes and NOT refusing connections.  I’m not an ops guy but I can’t think that this is good.  Here’s what I’m seeing:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;tail -f /var/log/syslog

Oct  5 08:10:01 ip-172-31-32-56 sm-mta[25939]: u958A1I6025939: from=&amp;lt;root@ip-172-31-32-56.us-west-2.compute.internal&amp;gt;, size=888, class=0, nrcpts=1, msgid=&amp;lt;201610050810.u958A1eD025938@ip-172-31-32-56.us-west-2.compute.internal&amp;gt;, proto=ESMTP, daemon=MTA-v4, relay=localhost [127.0.0.1]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;stopping-services-with-ansible&quot;&gt;Stopping Services with Ansible&lt;/h1&gt;

&lt;p&gt;I don’t have a port open for sendmail in my security group so this confuses me but it should be easy enough to add an ansible role to my playbook to address it.  Here are the steps:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd ~/wherever_your_ansible_root_is
mkdir -p roles/services/tasks
touch roles/services/tasks/main.yml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;In main.yml add:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- name: stop_sendmail
  service: name=sendmail state=stopped
  
- name: stop_apache2
  service: name=apache2 state=stopped
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;I added the routines to stop my apache2 instances because I’m not actually using them yet and any part of an attack surface that I can reduce might increase the chance of these boxes staying running longer.  Ideally they should be on a private internal network that isn’t exposed to the world at all.  And that’s coming but that’s a level of work I can’t do this very minute.&lt;/p&gt;

&lt;p&gt;In my main playbook simply call this role:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- { role: services, tags: services }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;You should note that I’m calling that role as the very last role since it does no good to stop a service before its created.  According to the &lt;a href=&quot;http://docs.ansible.com/ansible/service_module.html&quot;&gt;ansible service module docs&lt;/a&gt;, the options for state are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;running&lt;/li&gt;
  &lt;li&gt;started&lt;/li&gt;
  &lt;li&gt;stopped&lt;/li&gt;
  &lt;li&gt;restarted&lt;/li&gt;
  &lt;li&gt;reloaded&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;proof&quot;&gt;Proof&lt;/h1&gt;

&lt;p&gt;Here’s an example of a ps test on this before and after:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Before:&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ps auwwx | grep sendmail
root      1447  0.0  0.0 100704  2628 ?        Ss   08:26   0:00 sendmail: MTA: accepting connections
ubuntu    2958  0.0  0.0  10460   940 pts/0    S+   08:31   0:00 grep --color=auto sendmail
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;After:&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ps auwwx | grep sendmail
ubuntu    8485  0.0  0.0  10460   940 pts/0    S+   08:37   0:00 grep --color=auto sendmail
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 05 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/ansible/2016/10/05/ansible-quickie-turning-off-services-on-a-group-of-machines.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/ansible/2016/10/05/ansible-quickie-turning-off-services-on-a-group-of-machines.html</guid>
        
        <category>ansible</category>
        
        <category>devops</category>
        
        <category>services</category>
        
        
        <category>ansible</category>
        
      </item>
    
      <item>
        <title>Ansible Basics Presentation at Indy Elixir Meetup</title>
        <description>&lt;p&gt;Here are the slides from my Indy Elixir Meet up on &lt;a href=&quot;/blog/assets/ansible_basics.pdf&quot;&gt;Ansible Basics / Using Ansible to Install Elixir and Erlang&lt;/a&gt;.  This is essentially an Introduction to Ansible overview that culminates in a playbook to install Elixir / Erlang.&lt;/p&gt;
</description>
        <pubDate>Tue, 04 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/ansible/2016/10/04/ansible-basics-presentation-at-indy-elixir-meetup.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/ansible/2016/10/04/ansible-basics-presentation-at-indy-elixir-meetup.html</guid>
        
        <category>ansible</category>
        
        <category>elixir</category>
        
        
        <category>ansible</category>
        
      </item>
    
      <item>
        <title>Recommended Tool - httpstat</title>
        <description>&lt;p&gt;I ran across Dave Cheney’s httpstat tool recently and tried to get it working but I’m not a Go person so that failed.  I re-discovered it closing out a metric crap ton of browser tabs and thought “hm… I wonder if it is in brew yet”.  So a quick:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;brew install httpstat
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;gave it to me perfectly.  I can now do things like:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;httpstat http://dave.cheney.net/

HTTP/1.1 200 OK
Server: nginx/1.2.1
Date: Mon, 03 Oct 2016 08:46:43 GMT
Content-Type: text/html; charset=UTF-8
Transfer-Encoding: chunked
Connection: keep-alive
X-Powered-By: PHP/5.4.45-0+deb7u2
Link: &amp;lt;http://dave.cheney.net/wp-json/&amp;gt;; rel=&quot;https://api.w.org/&quot;

Body stored in: /var/folders/rf/3tfhwgrj1sl85y6rcs4x_s5c0000gn/T/tmpsGnFLB

  DNS Lookup   TCP Connection   Server Processing   Content Transfer
[    16ms    |      265ms     |       932ms       |       947ms      ]
             |                |                   |                  |
    namelookup:16ms           |                   |                  |
                        connect:281ms             |                  |
                                      starttransfer:1213ms           |
                                                                 total:2160ms
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here’s an example from one of my current sites (url omitted deliberately):&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sjohnson@ScottJohnsonMacbookAir:~/me/fuzzygroup/gocode$ httpstat http://banks.OMITTED.com/

HTTP/1.1 302 Found
Cache-Control: no-cache
Content-Type: text/html; charset=utf-8
Date: Mon, 03 Oct 2016 08:48:06 GMT
Location: http://banks.OMITTED.com/auth/login
Server: Apache/2.4.7 (Ubuntu)
Set-Cookie: _banks_session=MkhuMmJDWEM5bGp5YUFqNUxNNzRFMlNLUENwam1MODd6YU9HUEZ6MzRvdHQ5RVZFTTF2WC9OcHo3UVNEbm5uRlJlWDJRa1JvL1dFOXN2TEdHWlREL1NrVG9weGlCMXl5OUtyU29lR2VvMm5NQ0hBQU9xZlBKTUEva0RDVFBNdjBHOTI3eXY1dS9nYXVOTUJSd1F2R1d2MVpmdnhXUGt4VUkyOFhVR0hjTUtkTkZNTVlYb1kzTVVKOWIwWXhvNEIzVGRFYmhCWktoVnlOWStPeFU5dXg3TE5ma09VeC9qL0tWK1pQekVYb1ZBaz0tLXVFMHJEMDlEb3ROdGMxanRTQkxEeEE9PQ%3D%3D--51a7cd19b7d987a98bb6071c37c41be2f81cfb22; path=/; HttpOnly
Set-Cookie: _passenger_route=1007719246; Path=/
Status: 302 Found
X-Content-Type-Options: nosniff
X-Frame-Options: SAMEORIGIN
X-Powered-By: Phusion Passenger 5.0.30
X-Request-Id: ae887d90-9484-484a-be35-e13bf3454c3d
X-Runtime: 0.002985
X-XSS-Protection: 1; mode=block
transfer-encoding: chunked
Connection: keep-alive

Body stored in: /var/folders/rf/3tfhwgrj1sl85y6rcs4x_s5c0000gn/T/tmp3wlc7H

  DNS Lookup   TCP Connection   Server Processing   Content Transfer
[    527ms   |      66ms      |       73ms        |        1ms       ]
             |                |                   |                  |
    namelookup:527ms          |                   |                  |
                        connect:593ms             |                  |
                                      starttransfer:666ms            |
                                                                 total:667ms
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Looking at this very clearly shows me that the single biggest slow down here is actually dns.  Go figure.  If I was optimizing for performance, I would never have thought to investigate a half second of DNS delay.&lt;/p&gt;

&lt;p&gt;Thank you &lt;a href=&quot;http://dave.cheney.net/&quot;&gt;Dave Cheney&lt;/a&gt;!&lt;/p&gt;
</description>
        <pubDate>Mon, 03 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/tools/2016/10/03/recommend-tool-httpstat.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/tools/2016/10/03/recommend-tool-httpstat.html</guid>
        
        <category>httpstat</category>
        
        <category>tools</category>
        
        
        <category>tools</category>
        
      </item>
    
      <item>
        <title>Ansible Tutorial 02 - Understanding How Failures Are Handled</title>
        <description>&lt;p&gt;I just used Ansible to provision 8 new boxes and at the end I saw this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PLAY RECAP *********************************************************************
ficrawler10                : ok=53   changed=18   unreachable=0    failed=0
ficrawler3                 : ok=53   changed=18   unreachable=0    failed=0
ficrawler4                 : ok=53   changed=27   unreachable=0    failed=0
ficrawler5                 : ok=15   changed=1    unreachable=0    failed=1
ficrawler6                 : ok=53   changed=18   unreachable=0    failed=0
ficrawler7                 : ok=53   changed=18   unreachable=0    failed=0
ficrawler8                 : ok=53   changed=18   unreachable=0    failed=0
ficrawler9                 : ok=53   changed=18   unreachable=0    failed=0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;If you notice the box ficrawler5 has a state of failed=1 and this made me wonder:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What happened?&lt;/li&gt;
  &lt;li&gt;What happend after that failure?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;RUNNING HANDLER [mtpereira.passenger : apache restart] &lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;*
changed: [ficrawler5]&lt;/p&gt;

&lt;p&gt;PLAY RECAP &lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;&lt;strong&gt;**&lt;/strong&gt;***
ficrawler10                : ok=48   changed=6    unreachable=0    failed=0
ficrawler3                 : ok=48   changed=6    unreachable=0    failed=0
ficrawler4                 : ok=48   changed=6    unreachable=0    failed=0
ficrawler5                 : ok=53   changed=18   unreachable=0    failed=0
ficrawler6                 : ok=48   changed=6    unreachable=0    failed=0
ficrawler7                 : ok=48   changed=6    unreachable=0    failed=0
ficrawler8                 : ok=48   changed=6    unreachable=0    failed=0
ficrawler9                 : ok=48   changed=6    unreachable=0    failed=0&lt;/p&gt;

&lt;p&gt;d&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;TASK [aws_cloudwatch_memory : add command to cron] *****************************
skipping: [ficrawler3]
skipping: [ficrawler4]
skipping: [ficrawler5]
skipping: [ficrawler6]
skipping: [ficrawler7]
skipping: [ficrawler8]
skipping: [ficrawler9]
skipping: [ficrawler10]

TASK [dockersj : command] ******************************************************
changed: [ficrawler3]
 [WARNING]: Consider using 'become', 'become_method', and 'become_user' rather than running sudo

changed: [ficrawler7]
changed: [ficrawler6]
changed: [ficrawler4]
changed: [ficrawler8]
changed: [ficrawler9]
changed: [ficrawler10]
fatal: [ficrawler5]: FAILED! =&amp;gt; {&quot;changed&quot;: true, &quot;cmd&quot;: &quot;sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D&quot;, &quot;delta&quot;: &quot;0:02:00.060733&quot;, &quot;end&quot;: &quot;2016-10-03 17:05:26.068764&quot;, &quot;failed&quot;: true, &quot;rc&quot;: 2, &quot;start&quot;: &quot;2016-10-03 17:03:26.008031&quot;, &quot;stderr&quot;: &quot;gpg: requesting key 2C52609D from hkp server p80.pool.sks-keyservers.net\ngpg: keyserver timed out\ngpg: keyserver receive failed: keyserver error&quot;, &quot;stdout&quot;: &quot;Executing: gpg --ignore-time-conflict --no-options --no-default-keyring --homedir /tmp/tmp.Tz2C7bntoi --no-auto-check-trustdb --trust-model always --keyring /etc/apt/trusted.gpg --primary-keyring /etc/apt/trusted.gpg --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D&quot;, &quot;stdout_lines&quot;: [&quot;Executing: gpg --ignore-time-conflict --no-options --no-default-keyring --homedir /tmp/tmp.Tz2C7bntoi --no-auto-check-trustdb --trust-model always --keyring /etc/apt/trusted.gpg --primary-keyring /etc/apt/trusted.gpg --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D&quot;], &quot;warnings&quot;: [&quot;Consider using 'become', 'become_method', and 'become_user' rather than running sudo&quot;]}

TASK [dockersj : Install docker] ***********************************************
ok: [ficrawler3] =&amp;gt; (item=[u'apt-transport-https', u'ca-certificates', u'docker', u'python-pip'])
ok: [ficrawler4] =&amp;gt; (item=[u'apt-transport-https', u'ca-certificates', u'docker', u'python-pip'])
ok: [ficrawler6] =&amp;gt; (item=[u'apt-transport-https', u'ca-certificates', u'docker', u'python-pip'])
ok: [ficrawler8] =&amp;gt; (item=[u'apt-transport-https', u'ca-certificates', u'docker', u'python-pip'])
ok: [ficrawler7] =&amp;gt; (item=[u'apt-transport-https', u'ca-certificates', u'docker', u'python-pip'])
ok: [ficrawler10] =&amp;gt; (item=[u'apt-transport-https', u'ca-certificates', u'docker', u'python-pip'])
ok: [ficrawler9] =&amp;gt; (item=[u'apt-transport-https', u'ca-certificates', u'docker', u'python-pip'])
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;git@github.com:appdatallc/honeybadger.git&lt;/p&gt;
</description>
        <pubDate>Mon, 03 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/2016/10/03/ansible-tutorial-understanding-how-failures-are-handled.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/2016/10/03/ansible-tutorial-understanding-how-failures-are-handled.html</guid>
        
        
      </item>
    
      <item>
        <title>Rails Post Mortem - An Analysis of Breaking the Build</title>
        <description>&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Making this blog post public as opposed to an internal document might ruffle some feathers.  I’d like to point out here that no has been called out by name and at least part of the responsibility trail here is &lt;strong&gt;mine&lt;/strong&gt; and I have no issues with accepting that.  The only way to learn from our mistakes is honesty  and this post was written in that spirit.  It is how all of us get better at our jobs.&lt;/p&gt;

&lt;p&gt;I often tell my kids that when something goes wrong I care less about what went wrong and more about responsibility, specifically, whether or not you accept responsibility for it.  When something goes wrong accepting the responsibility for it, if it was actually your fault, to &lt;strong&gt;me&lt;/strong&gt;, is a big deal.  If you don’t accept responsibility for your mistakes then you cannot learn from them.&lt;/p&gt;

&lt;p&gt;I recently had the situation where a new hire broke the build.  And he broke it after 5 pm on a friday when mission critical work had to be done over the weekend. Sigh.  And, of course, he was offline when I found out so it fell on me to untangle it.&lt;/p&gt;

&lt;h1 id=&quot;mistake-01-mine---accepting-the-change-on-a-friday&quot;&gt;Mistake 01: Mine - Accepting the Change on a Friday&lt;/h1&gt;

&lt;p&gt;It was the end of the week and I’d been busy and heads down all week on devops stuff.  I wanted to get his changes merged so I did take the change without my normal level of “it’s a friday; deny, deny, deny and then deny some more” commentary.  I should never, &lt;strong&gt;never&lt;/strong&gt; have taken changes from anyone other than myself on a Friday afternoon.  Why?  Because, ultimately I’m in charge.  And when a crawl blows up partway through it is on me to fix it.  No one here carries pagers or is expected, other than myself, to be up in the middle of the night dealing with crap.&lt;/p&gt;

&lt;h1 id=&quot;mistake-02-his---over-scoping-the-work&quot;&gt;Mistake 02: His - Over Scoping the Work&lt;/h1&gt;

&lt;p&gt;The individual in question had a ticket in his queue that read “Figure out what gems in gemfile we should throw out”.  This is a classic learning exercise that I often give to new hires.  Gemfile is often a bit like Mos Eisley in a Rails project - a wretched hive of scum and villany.  Gems accrete there – you need a tool for a one off hack and a gem gets added.  And then its not used and the one off hack goes away.  But the gem never goes away.&lt;/p&gt;

&lt;p&gt;He did the analysis but then he decided to re-organize the Gemfile and alphabetize it.  And this was at the core of the problem.  I asked for analysis.  I didn’t ask for change specifically because I wanted to make that change gently, carefully and on my own.  Now I could absolutely have pushed back and said “Nope!  Don’t want it; didn’t ask for it; redo.”  But that would kind of be a jerk move. He clearly put thought and effort into this so as a person who manages people its better for their growth and development to follow the process end to end even when you think it might be a damn disaster waiting to happen.&lt;/p&gt;

&lt;p&gt;Now, as old engineers are wont do, we tell tales and we bitch about parts of software that we find odious.  Personally I’m not a fan of Gemfile and the whole gem stack in general in Rails.  Of all the things that give me issues in Rails, I find the overall fragility of the Gem stack and bundler to be the absolute worst part.  I know for a fact that he’s heard this rant.  However, whether or not he listened is unclear…&lt;/p&gt;

&lt;h1 id=&quot;mistake-03-his---moving-things-from-main-to-development-test-groups&quot;&gt;Mistake 03: His - Moving Things From Main to Development, Test Groups&lt;/h1&gt;

&lt;p&gt;The first mistake that was made was his decision to move things from the main context in Gemfile to solely development and test.  The gem in question was pry and, for some reason, it not being present broke the running system.  His defense was “I’ve never seen an installation where pry needed to be in production”.  That’s fine but the reality with big complex software systems is that understanding side effects of changes is hard.  And when your boss has specifically called out the area in which you &lt;strong&gt;chose&lt;/strong&gt; to make complex changes, you need to approach it with caution.&lt;/p&gt;

&lt;h1 id=&quot;mistake-04-his---introducing-things-not-present-prior-in-gemfile&quot;&gt;Mistake 04: His - Introducing Things Not Present Prior in Gemfile&lt;/h1&gt;

&lt;p&gt;When I saw pry in the Gemfile, I initially thought that he had introduced it and I pushed back on it.  Nope.  He was right – pry was part of the system.  It was an innocuous “gem ‘pry’” on or about line #65 and I was the one who had to add it once upon a time.  I’ve never been a pry fan despite its relative hotness within the community.  Now when he saw pry and moved it into the development and test groups, he also added pry&lt;/p&gt;

&lt;p&gt;The person making the change introduced two additional, pry-rails and pry-byebug.  I don’t know what these do and the system is now breaking so I commented them out immediately.  And was that conservative of me?  Yes.  And was that reactionary of me?  Sure.  Maybe these are great gems that will rock my world but when a) the system is breaking and b) the goal was find out what’s not used, adding new gems shouldn’t happen.&lt;/p&gt;

&lt;h1 id=&quot;mistake-05-his---mysqlplus&quot;&gt;Mistake 05: His - Mysqlplus&lt;/h1&gt;

&lt;p&gt;One of the best bits of work that this person has done for us so far is he got the mysqlplus gem working again.  Why we need this crufty old bit of code is irrelevant (or the subject of another blog post) but we absolutely do need it.  And where I couldn’t make it work in Ruby 2.3.1 and Dv couldn’t make it work, he pulled it off and that was absolutely, &lt;strong&gt;stellar&lt;/strong&gt;, &lt;strong&gt;amazing&lt;/strong&gt;, &lt;strong&gt;wonderful&lt;/strong&gt; work.  I simply cannot say enough good things about this.  Unfortunately when he refactored Gemfile it was &lt;em&gt;commented out&lt;/em&gt; and it not being there promptly broke all of our crawlers.  This was essentially a copy and paste refactor issue.  When he started the Gemfile project he hadn’t yet done the mysqlplus work so the gem, which at that point in time was broken, was commented out.  And, unfortunately, despite the good work he had done, stayed commented out.&lt;/p&gt;

&lt;p&gt;The reason that it broke our crawlers is is that our crawlers are based on Rails but have their own dependency load structure so how they interact with Gemfile is complex.  And they also rely on this bit of trickery:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class Mysql; alias :query :async_query; end
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;That takes the async_query method in mysqlplus and dynamically replaces query with it.  This eliminates blocking at the query level and improves our threaded performance by roughly 50%.  And because this is dynamically injected, when something isn’t present in Gemfile, there’s no way to know except for actually executing the code.&lt;/p&gt;

&lt;p&gt;Now this is the point about complex software systems – when you don’t fully understand them – you need to approach &lt;strong&gt;dangerous changes with care&lt;/strong&gt;.  He may not have perceived Gemfile as dangerous but I made damn sure that the rant was given because I do know the danger of messing with Gemfile.  The bottom line here is that you don’t change global things without a hell of a lot of care.  And you certainly don’t change it on a Friday afternoon.  And, remember, I accepted the changes and that was my error.&lt;/p&gt;

&lt;h1 id=&quot;mistake-06-mine-no-monitoring-on-parts-of-our-infrastructure&quot;&gt;Mistake 06: Mine No Monitoring on Parts of our Infrastructure&lt;/h1&gt;

&lt;p&gt;Another mistake that I made was when our new AWS bits were setup, I didn’t immediately set up monitoring on a few production urls.  Since this is mainly an internal system which produces data that is ingested by Tableau, monitoring has never been a priority.  Again that’s on me.  If I had had monitoring setup I would have found at 3 on a Friday instead of at 5.  And since he would still have been online all of this would have been easier.&lt;/p&gt;

&lt;h1 id=&quot;mistakes-other&quot;&gt;Mistakes Other&lt;/h1&gt;

&lt;p&gt;There was at least one other issue related to the Curses gem but I don’t think its particularly relevant here.  I had been in the middle of doing ansible work on devops and I saw our Ansible work failing and went sideways debugging it thinking the issue was me when it was really the lack of the curses gem.&lt;/p&gt;

&lt;h1 id=&quot;some-things-are-debatable-other-things-are-not&quot;&gt;Some Things are Debatable; Other Things Are Not&lt;/h1&gt;

&lt;p&gt;When this topic came up on a slack chat between this individual and myself, he gave me a lot of push back like the “I’ve never seen pry in production”.  And I’ll definitely admit that some technical topics are debatable.  Perhaps there is something critically wrong with our code that pry is needed in production.  Or maybe it was something else and adding pry causes another dependency to come in which fixed it.  I’m not 100% certain because I had production systems that needed to get running again and simply reversing a few of his changes was the most expedient way to do that.  So while we can debate aspects of his changes, what isn’t debatable, is this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;He chose to make changes above and beyond the requested scope of work – which was analysis&lt;/li&gt;
  &lt;li&gt;The production, running system entirely broke – website, backend, etc&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To me this is fairly incontrovertible – you broke the build.  Now this isn’t a huge deal to me:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;New hires break things and no data was lost.&lt;/li&gt;
  &lt;li&gt;We lost about an hour and a half of crawling time&lt;/li&gt;
  &lt;li&gt;I resolved the issues in less than 30 minutes and had us up and running again before dinner&lt;/li&gt;
  &lt;li&gt;It took longer to write this post mortem than it did to fix the issues&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In closing I also should state that the alphabetized Gemfile is better organized and will be better for maintenance long term.  He also did a great job of preserving the cruft that was there previously which illustrated history and intent and I do appreciate that.  I simply should have been more diligent before I accepted these changes.  We lack a staging server for this project and I will ticket for myself the task of getting one built so we have a place to tackle sweeping changes like these.&lt;/p&gt;
</description>
        <pubDate>Sun, 02 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/software_engineering/2016/10/02/rails-an-analysis-of-breaking-the-build.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/software_engineering/2016/10/02/rails-an-analysis-of-breaking-the-build.html</guid>
        
        <category>rails</category>
        
        <category>software_engineering</category>
        
        
        <category>software_engineering</category>
        
      </item>
    
      <item>
        <title>AWS Tutorial 13 - Adding Idempotency to Our CloudWatch Monitoring Playbook</title>
        <description>&lt;p&gt;In Tutorial 11 we used an Ansible playbook to set up CloudWatch memory monitoring on a series of Ubuntu EC2 instances.  This worked perfectly – &lt;strong&gt;once&lt;/strong&gt;.  I noticed, after I published the blog post, that if I tried to re-run the Ansible script playbook that it fail on a second run.  Initially I chalked this up to plain old randomness but then I actually &lt;strong&gt;thought&lt;/strong&gt; about it and it all came into focus.&lt;/p&gt;

&lt;h1 id=&quot;ansible-is-all-about-idempotency-and-this-was-not&quot;&gt;Ansible is All About Idempotency and This Was Not&lt;/h1&gt;

&lt;p&gt;http://docs.ansible.com/ansible/stat_module.html
https://raymii.org/s/tutorials/Ansible_-_Only_if_a_file_exists_or_does_not_exist.html&lt;/p&gt;

&lt;p&gt;http://www.caphrim.net/ansible/2015/05/25/be-careful-with-unarchive.html&lt;/p&gt;

</description>
        <pubDate>Sun, 02 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/aws/2016/10/02/aws-tutorial-13-adding-idempotency-to-our-cloudwatch-monitoring-playbook.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/aws/2016/10/02/aws-tutorial-13-adding-idempotency-to-our-cloudwatch-monitoring-playbook.html</guid>
        
        <category>aws</category>
        
        <category>ansible</category>
        
        <category>cloudwatch</category>
        
        
        <category>aws</category>
        
      </item>
    
      <item>
        <title>AWS Tutorial 12 - Using Ansible to Quickly Fix Your Server's TCP Connections</title>
        <description>&lt;p&gt;The bulk of my coding is actually back end coding and I spent a lot of time dealing with network programming issues.  We’ve been running for years in a data center that I put together and every box was finely tuned.  Unfortunately due to the massive issues surrounding Chef, we were never able to maintain boxes automatically so every server became a unique snowflake – well set up and such but I have no idea now what changes we made to tune each server over the years.&lt;/p&gt;

&lt;p&gt;And while we still have that data center active, we’re now crawling on our AWS boxes and much happier but we’re still working the kinks out.  This morning I started seeing this appear:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Cannot assign requested address.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;It was appearing in the context of our Redis connections.  And, sure enough, we had a routine which was creating a handle to redis every, single, time it was handling a url.  That’s bad.  So the easy fix was to pass the connection in from a higher level.  But even after that it was still an issue.  Some quick research brought me to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/10980850/solveredis-localhost6379-cannot-assign-requested-address&quot;&gt;https://stackoverflow.com/questions/10980850/solveredis-localhost6379-cannot-assign-requested-address&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://redis4you.com/articles.php?id=012&amp;amp;name=redis&quot;&gt;http://redis4you.com/articles.php?id=012&amp;amp;name=redis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Apparently the recommended solution is to fix a running box with:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;echo 1 &amp;gt; /proc/sys/net/ipv4/tcp_tw_reuse
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;and put the same fix into:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; /etc/rc.local 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;how-to-ansible-ize-this&quot;&gt;How to Ansible-ize This&lt;/h1&gt;

&lt;p&gt;Given that we have a bunch of AWS nodes setup, I don’t really want to make this change manually so let’s script it with Ansible and run it as a role.  Here’s what to do for the directory where your Ansible stuff resides:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;mkdir -p roles/machine_setup_tcp_tw_reuse/tasks&lt;/li&gt;
  &lt;li&gt;touch roles/machine_setup_tcp_tw_reuse/tasks/main.yml&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In your main.yml file you want this code:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# this sets it for the machine permanently after the machine restarts
- name: update /etc/rc.local for tcp_tw_reuse (faster tcp recycling) on machines which are servers 
  lineinfile: dest=/etc/rc.local regexp=&quot;^echo 1 &amp;gt; &quot;  line=&quot;echo 1 &amp;gt; /proc/sys/net/ipv4/tcp_tw_reuse&quot;
  
# this fixes the current machine state
- name: execute the fix on the currently running machine instance
  shell: &quot;echo 1 &amp;gt; /proc/sys/net/ipv4/tcp_tw_reuse&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;In your main playbook.yml you want to call this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- hosts: all
  become: yes
  remote_user: ubuntu
  roles:
- { role: machine_setup_tcp_tw_reuse, tags: machine_setup_tcp_tw_reuse}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;how-to-run-this&quot;&gt;How to Run this&lt;/h1&gt;

&lt;p&gt;You can run this using the following syntax:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ansible-playbook -i inventories/production_actual playbook.yml --tags &quot;machine_setup_tcp_tw_reuse&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;how-to-verify-the-fix&quot;&gt;How to Verify the Fix&lt;/h1&gt;

&lt;p&gt;To verify this, you can do what I did:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ssh into a box&lt;/li&gt;
  &lt;li&gt;cat /proc/sys/net/ipv4/tcp_tw_reuse&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you see a 1 there then the fix actually worked.&lt;/p&gt;

&lt;h1 id=&quot;notes&quot;&gt;Notes&lt;/h1&gt;

&lt;p&gt;The reason for the small level of granularity on this role is that I’m now using Ansible to fix issues on production running hosts.  And I wanted to be able to run &lt;strong&gt;just&lt;/strong&gt; this role.  Ansible has tagging which I do believe would let me have this embedded within my overall machine_setup task but this felt safer since I’m still a noob at Ansible.&lt;/p&gt;
</description>
        <pubDate>Sun, 02 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/aws/2016/10/02/aws-tutorial-12-using-ansible-to-quickly-fix-your-server-s-tcp-connections.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/aws/2016/10/02/aws-tutorial-12-using-ansible-to-quickly-fix-your-server-s-tcp-connections.html</guid>
        
        <category>aws</category>
        
        <category>ansible</category>
        
        <category>redis</category>
        
        
        <category>aws</category>
        
      </item>
    
      <item>
        <title>AWS Tutorial 11 - An Ansible Role for Installing AWS Cloud Watch Monitoring On Ubuntu</title>
        <description>&lt;p&gt;As I’ve written here earlier, Ansible is a provisioning and management tool that you can use to enable better automated provisioning of your AWS machines.  While I am &lt;a href=&quot;https://fuzzygroup.github.io/blog/aws/2016/09/06/aws-i-was-wrong-dead-wrong.html&quot;&gt;absolutely in love with AWS&lt;/a&gt;, one thing that I do think that CloudWatch got wrong is that there is no memory graphs when you use CloudWatch to monitor your machines.  Given that I write threaded applications all the time, knowing how my memory utilization looks is a vital diagnostic tool.  And while there is a way to do this, it requires a fair bit of systems administration to accomplish it since it requires code to be installed on every server to be monitored.&lt;/p&gt;

&lt;p&gt;Since we need to make a change to every box we have and to all new boxes we will create, who are we going to call?  Ansible!!!  That’s right – in this tutorial we’re going to use Ansible to write a playbook and role for:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;downloading required modules&lt;/li&gt;
  &lt;li&gt;downloading the code&lt;/li&gt;
  &lt;li&gt;installing the code&lt;/li&gt;
  &lt;li&gt;inserting our AWS keys&lt;/li&gt;
  &lt;li&gt;creating a cron job&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;creating-our-structure&quot;&gt;Creating our Structure&lt;/h1&gt;

&lt;p&gt;While Ansible is flexible in how things can be structured, I use a standard approach.  All of the code here is available on my github (link at the end) but I find that writing it all out helps my understanding at least.  Here’s how to create the structure that I use for Ansible.  All of this assumes you are already in a project directory where you want to store this.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mkdir inventories
touch inventories/production
mkdir -p roles/aws_cloudwatch_memory/tasks
mkdir -p roles/aws_cloudwatch_memory/vars
touch roles/aws_cloudwatch_memory/tasks/main.yml
touch roles/roles/aws_cloudwatch_memory/vars/main.yml
# note - if you want to encrypt your aws keys that don't do the next step and do it below under Ansible Vault
touch ansible.cfg
touch playbook.yml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;core-ansible-concepts-inventory-playbook-role-var&quot;&gt;Core Ansible Concepts: Inventory, Playbook, Role, Var&lt;/h1&gt;

&lt;p&gt;Like many automation products, Ansible is built around some core concepts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Inventory - a list of the machine resources to create, update or destroy&lt;/li&gt;
  &lt;li&gt;Playbook - a list of the roles to apply to each machine resource&lt;/li&gt;
  &lt;li&gt;Role - what to do with a machine.  This can be very complex including tasks, variables, files to copy to and from, services to restart and so on.&lt;/li&gt;
  &lt;li&gt;Var - a list of variables to use in your role.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;the-inventory&quot;&gt;The Inventory&lt;/h1&gt;

&lt;p&gt;In the inventory file you want a format very similar to an old fashioned .ini file.  Here’s what mine looks like:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[web]
fiworker2    ansible_ssh_host=ec2-52-41-237-52.us-west-2.compute.amazonaws.com        ansible_ssh_private_key_file=/Users/sjohnson/.ssh/fi_nav_sitecrawl.pem
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The syntax I’m using is human_readable_name  ansible_ssh_host=  ansible_ssh_private_key_file=&lt;/p&gt;

&lt;p&gt;While you can generate the inventory file automatically with code, I don’t have a ton of AWS instances yet so I’ve just listed them manually.&lt;/p&gt;

&lt;h1 id=&quot;the-playbook&quot;&gt;The Playbook&lt;/h1&gt;

&lt;p&gt;Here’s the playbook:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- hosts: all
  become: yes
  remote_user: ubuntu
  roles:
    - { role: aws_cloudwatch_memory, tags: aws_cloudwatch_memory}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The way to read this is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;run the playbook on all hosts&lt;/li&gt;
  &lt;li&gt;run the playbook as sudo&lt;/li&gt;
  &lt;li&gt;run the playbook with the remote user ubuntu&lt;/li&gt;
  &lt;li&gt;run the role aws_cloudwatch_memory&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;the-role&quot;&gt;The Role&lt;/h1&gt;

&lt;p&gt;Here’s the role:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;---
  
- name: Install CloudWatch libraries
  apt: pkg=
       state=installed
  with_items:
    - unzip
    - libwww-perl
    - libdatetime-perl

- name: download scripts
  get_url: url=http://aws-cloudwatch.s3.amazonaws.com/downloads/CloudWatchMonitoringScripts-1.2.1.zip dest=/tmp/CloudWatchMonitoringScripts.zip

- name: chown the file and make it writeable
  file: path=/tmp/CloudWatchMonitoringScripts.zip mode=0755  #owner=ubuntu group=ubuntu 

- name: unzip the scripts
  # note - unarchive should work but it fails; maybe an ansible issue?  shell: to the rescue!
  #unarchive: src=/tmp/CloudWatchMonitoringScripts.zip dest=/tmp/
  shell: &quot;cd /tmp &amp;amp;&amp;amp; unzip /tmp/CloudWatchMonitoringScripts.zip&quot;

- name: delete archive
  file: path=/tmp/CloudWatchMonitoringScripts.zip state=absent

- name: set Access key in credentials file
  replace: dest=/tmp/aws-scripts-mon/awscreds.template regexp='AWSAccessKeyId=' replace='AWSAccessKeyId=' backup=yes

- name: set Secret key in credentials file
  replace: dest=/tmp/aws-scripts-mon/awscreds.template regexp='AWSSecretKey=' replace='AWSSecretKey=' backup=yes

- name: move directory out of /tmp
  command: mv /tmp/aws-scripts-mon/ /root/ creates=/root/aws-scripts-mon/

- name: add command to cron
  lineinfile: dest=/etc/crontab insertafter=EOF line=&quot;* * * * * root /root/aws-scripts-mon/mon-put-instance-data.pl --mem-util --mem-used --mem-avail --aws-credential-file=/root/aws-scripts-mon/awscreds.template&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;using-ansible-vault-for-the-vars-file&quot;&gt;Using Ansible Vault for the vars file&lt;/h1&gt;

&lt;p&gt;Within the roles directory there is a vars directory and a file main.yml within it.  This file will contain our variables that define our AWS access key and AWS secret.  Given that this file will likely be checked into version control, there’s value in encrypting those variables.  The tool Ansible Vault is used for that.  Here’s how:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Use the command:  ansible-vault create roles/aws_cloudwatch_memory/vars/main.yml&lt;/li&gt;
  &lt;li&gt;This will ask your for a password.  Enter one and confirm it and then you’ll be launched into an editor where you can put in your keys.&lt;/li&gt;
  &lt;li&gt;Exit the editor and it will save your now encrypted data.  You can then edit it later with: ansible-vault edit roles/aws_cloudwatch_memory/vars/main.yml&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;More on the Ansible Vault is available on the &lt;a href=&quot;http://docs.ansible.com/ansible/playbooks_vault.html&quot;&gt;docs.ansible.com site&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The vars file needs to look something like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ec2_access_key: &quot;foo&quot;
ec2_secret_key: &quot;bar&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Obviously these would be replaced with real values.  By storing this file in rolename/vars/main.yml location and format, Ansible knows to load this file automatically when the role is executed.&lt;/p&gt;

&lt;h1 id=&quot;the-ansiblecfg-file&quot;&gt;The ansible.cfg file&lt;/h1&gt;

&lt;p&gt;You may, or may not, need a ansible.cfg file.  This is an ASCII file that defines how to handle ssh connectivity.  Here’s mine:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[ssh_connection]
ssh_user = vagrant
scp_if_ssh = True
control_path = %(directory)s/%%h-%%r
ansible_ssh_private_key_file = /Users/sjohnson/.ssh/fi_nav_sitecrawl.pem
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;I’m not, at the time of this writing, a true Ansible expert so I suspect there’s redundancy in my cfg file but when I run without it, I’m unable to connect to AWS and I think it’s due to the control_path setting being required due to the length of the EC2 host names.&lt;/p&gt;

&lt;h1 id=&quot;running-this&quot;&gt;Running This&lt;/h1&gt;

&lt;p&gt;Here’s all you need to do to run this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ansible-playbook -i inventories/production playbook.yml
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;If you encrypted your keys then you’ll be prompted for the password.  If you want to store the password in a local file on your machine then you can always do it this way:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ansible-playbook -i inventories/production playbook.yml --vault-password-file ~/.vault_pass.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;code-on-git&quot;&gt;Code on Git&lt;/h1&gt;

&lt;p&gt;All of this is published on my &lt;a href=&quot;https://github.com/fuzzygroup/ansible_cloud_watch_memory_monitoring&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;p&gt;Here are some great references&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://gist.github.com/weirdbricks/3e0d0e3428f3d683ccfa&quot;&gt;https://gist.github.com/weirdbricks/3e0d0e3428f3d683ccfa&lt;/a&gt;  This is the gist I started from; it was for Redhat / CentOS and used Yum&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/mon-scripts.html&quot;&gt;http://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/mon-scripts.html&lt;/a&gt;  This is the canonical documentation&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.krishnachaitanya.ch/2016/03/monitor-ec2-memory-usage-using-aws.html&quot;&gt;http://blog.krishnachaitanya.ch/2016/03/monitor-ec2-memory-usage-using-aws.html&lt;/a&gt; Good tutorial&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 01 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/aws/2016/10/01/aws-tutorial-11-an-ansible-role-for-installing-aws-cloud-watch-monitoring-on-ubuntu.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/aws/2016/10/01/aws-tutorial-11-an-ansible-role-for-installing-aws-cloud-watch-monitoring-on-ubuntu.html</guid>
        
        <category>ansible</category>
        
        <category>aws</category>
        
        <category>cloudwatch</category>
        
        
        <category>aws</category>
        
      </item>
    
      <item>
        <title>AWS Tutorial 10 - Diagnosing SSH Failures or When Ping Works But SSH Fails</title>
        <description>&lt;p&gt;I just had the issue where a Capistrano deploy onto our AWS cluster of boxes failed.  This let me into the following process of debugging:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Can I ping each box?  Yes!&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Can I ssh into each box?  No!  The box we name ficrawler2 was unable to be ssh’d into and gave this error:&lt;/p&gt;

    &lt;p&gt;ssh ficrawler2
ssh_exchange_identification: read: Operation timed out&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;My next action was to look at the instance in the web console and discover that it was actually reachable from the perspective of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;System reachability check passed&lt;/li&gt;
  &lt;li&gt;Instance reachability check passed&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;center left&quot;&gt;&lt;img src=&quot;/blog/assets/aws/aws_tutorial_10_01.png&quot; alt=&quot;aws_tutorial_10_01.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This makes me think that SSH itself went down but external network metrics like ping remained up.  Next step up is to reboot the box.  And I did that and the problem persisted.  This led me to thinking that there’s a lower level problem here, possibly network layer?&lt;/p&gt;

&lt;p&gt;Now from my ssh config tutorial you might know that my ssh config file defined ficrawler2.  Here are the particulars:&lt;/p&gt;

&lt;p&gt;Host ficrawler2
    Hostname ec2-54-68-16-169.us-west-2.compute.amazonaws.com
    User ubuntu
    IdentityFile /Users/sjohnson/.ssh/fi_nav_sitecrawl.pem
    Port 22&lt;/p&gt;

&lt;p&gt;So this lets us construct a debuggable ssh connect line:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh -i &quot;/Users/sjohnson/.ssh/fi_nav_sitecrawl.pem&quot; ubuntu@54.68.16.169 -vv
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The result of the ssh -i line above will be a very long string of ssh commands showing what happened.&lt;/p&gt;

&lt;p&gt;Unfortunately by the time I did the research to figure this out and setup this blog post, ssh returned and I’m left scratching my head more than a bit.&lt;/p&gt;

&lt;h1 id=&quot;lessons-learned&quot;&gt;Lessons Learned&lt;/h1&gt;

&lt;p&gt;Here’s what we now know:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A box can be ping’able but not ssh’able&lt;/li&gt;
  &lt;li&gt;Next time I may want to not reboot so quickly&lt;/li&gt;
  &lt;li&gt;A reboot doesn’t necessarily clear it up so the underlying box might actually have been fine&lt;/li&gt;
  &lt;li&gt;I need to write the ssh test line faster next time&lt;/li&gt;
  &lt;li&gt;It is very unclear how AWS cloud watch can be used to test for a box that is unable to be ssh’d into; that may not be viable (monitoring it could actually be construed as an attack)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;update-1&quot;&gt;Update 1&lt;/h1&gt;

&lt;p&gt;This has continued to happen and I was able to capture the diagnostic output:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh -i &quot;/Users/sjohnson/.ssh/fi_nav_sitecrawl.pem&quot; ubuntu@52.89.105.4 -vv
OpenSSH_6.9p1, LibreSSL 2.1.8
debug1: Reading configuration data /Users/sjohnson/.ssh/config
debug1: Reading configuration data /etc/ssh/ssh_config
debug1: /etc/ssh/ssh_config line 20: Applying options for *
debug1: /etc/ssh/ssh_config line 102: Applying options for *
debug2: ssh_connect: needpriv 0
debug1: Connecting to 52.89.105.4 [52.89.105.4] port 22.
debug1: Connection established.
debug1: key_load_public: No such file or directory
debug1: identity file /Users/sjohnson/.ssh/fi_nav_sitecrawl.pem type -1
debug1: key_load_public: No such file or directory
debug1: identity file /Users/sjohnson/.ssh/fi_nav_sitecrawl.pem-cert type -1
debug1: Enabling compatibility mode for protocol 2.0
debug1: Local version string SSH-2.0-OpenSSH_6.9
ssh_exchange_identification: read: Connection reset by peer
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;update-2---the-response-from-aws-tech-support&quot;&gt;Update 2 - The Response from AWS Tech Support&lt;/h1&gt;

&lt;p&gt;Good Day,&lt;/p&gt;

&lt;p&gt;I understand that you are unable to access some of your instances via ssh at random times. Please correct me if I miss understood.&lt;/p&gt;

&lt;p&gt;Are you still experiencing the issue, or was the problem resolved after the reboot? I’ve noticed that all the instances with the name “crawler” was started around the same time (2016-10-03 14:25:38 UTC ). Did you have the same issue on all of these instances?&lt;/p&gt;

&lt;p&gt;Normally when an instance is inaccessible via ssh, it could indicate a network error or high CPU utilization on the instance. I had a look at the instance metrics for CPU and networking, and all seems to be within acceptable ranges. I can confirm that there are no failures or events on the underlying hardware.&lt;/p&gt;

&lt;p&gt;I understand that you want to investigate the cause of the issue and prevent it from happening again.&lt;/p&gt;

&lt;p&gt;The best place to start with troubleshooting is to have a look at the OS log files. For Ubuntu; you can have a look in the /var/log/syslog file, or the output of the dmesg command. Please have a look for any warnings or error messages around the time that you’ve experienced the issues.&lt;/p&gt;

&lt;p&gt;What error message did you get when you tried to ssh to the instances?&lt;/p&gt;

&lt;p&gt;Were you able to consume any other service that was running on these instances? For example could you still access the web page or MySQL?&lt;/p&gt;

&lt;p&gt;Did you try to access the instances from the internet or from another instance on the same network range?&lt;/p&gt;

&lt;p&gt;Can you perform a traceroute to the instances now, and again when you are seeing the issue? This can help identify network issues.&lt;/p&gt;

&lt;p&gt;I also see that your security group, sg-DFDDFD, allows ssh access from the world (0.0.0.0/0). Leaving port 22 open to the world is a security risk as it leaves your instances vulnerable for attack. I would recommend that you remove this inbound rule and only allow ssh access from trusted IP addresses.&lt;/p&gt;

&lt;p&gt;If you want to eliminate manual intervention when an instance fails, you can have a look at Auto Scaling. This will automatically start new instances or stop faulty ones when health checks fails. You can reference the below links for more information about Auto Scaling if you’re interested.&lt;/p&gt;

&lt;p&gt;https://aws.amazon.com/autoscaling/
http://docs.aws.amazon.com/autoscaling/latest/userguide/GettingStartedTutorial.html&lt;/p&gt;

&lt;p&gt;Best regards,&lt;/p&gt;

&lt;p&gt;Stefan F.
Amazon Web Services
We value your feedback. Please rate my response using the link below.&lt;/p&gt;

</description>
        <pubDate>Sat, 01 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/aws/2016/10/01/aws-tutorial-10-diagnosing-ssh-failures-or-when-ping-works-but-ssh-fails.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/aws/2016/10/01/aws-tutorial-10-diagnosing-ssh-failures-or-when-ping-works-but-ssh-fails.html</guid>
        
        <category>aws</category>
        
        <category>ssh</category>
        
        
        <category>aws</category>
        
      </item>
    
      <item>
        <title>Using Ansible to Drive Down Hosting Costs</title>
        <description>&lt;p&gt;Ever since the Fall of 2014 I have been trapped in an &lt;strong&gt;dysfunctional relationship&lt;/strong&gt; that I have been unable to leave.  No I’m not talking about a spouse, a boyfriend or a girlfriend.  I’m talking about my hosting company where all my Rails applications live.  And, while I’m talking about Rails, it doesn’t have to be Rails.  It could be PHP, Python, Go, Elixir or anything.&lt;/p&gt;

&lt;p&gt;Here is what I refer to the &lt;strong&gt;&lt;em&gt;economic paradox of hosting&lt;/em&gt;&lt;/strong&gt;:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;On the day you arrange to use hardware from a hosting company you should be paying the MOST ever for your hardware.&lt;/li&gt;
  &lt;li&gt;Your bills almost always go UP not DOWN.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The issue at hand here is that your hosting company knows that the longer you have a box with them, the more valuable that box becomes to you.  And the paradox is that the value of hardware falls over time.  That 24 gig of RAM box that you contracted for in 2014?  Well it should likely be a 36 gig of RAM box in 2015.  And it would be if you bought it again.  But you didn’t buy it again – you stayed with the machine you had – and your hosting company knows this.  So even tho the machine you’re renting today is worth less than it was when you started with it, your price per month hasn’t gone done.&lt;/p&gt;

&lt;h1 id=&quot;servers-should-never-be-unique-snowflakes&quot;&gt;Servers Should Never Be Unique Snowflakes&lt;/h1&gt;

&lt;p&gt;One of the single best concepts that I’ve learned from cloud computing and all the time I’ve spent doing AWS is that servers should never be unique snowflakes. Servers should be identical resources that you just have.  They should be something that you &lt;strong&gt;generate&lt;/strong&gt; and build dynamically as needed.  Need a web server – just generate one.  Need a worker box?  Just generate another one.  And, you know what, even if you have your own infrastructure, its &lt;strong&gt;still true&lt;/strong&gt;.&lt;/p&gt;

&lt;h1 id=&quot;ansible-versus-chef&quot;&gt;Ansible Versus Chef&lt;/h1&gt;

&lt;p&gt;I’ve spent the past week deeply immersed in devops using Ansible.  Ansible is a declarative approach to machine configuration and it is far, far beyond procedural approaches to machine configuration like puppet or chef – the tools I had used previously.  In 2014 I and one other engineer used Chef to provision a data center for 3 applications and over a 45 day period we never actually finished.  We took Chef as far as we were able to and then we had to finish the process manually and every time we needed to make a change to a box, after things were “setup”, we had to do it manually.  Here’s a comment from the other engineer:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;with chef, I had no idea after all that time, where I should put what file
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And here was my comment:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Chef was a f***ing disaster.  Make that my bad decision of 2014.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;In about 4 days of on and off work I have not only duplicated every single bit of the chef provisioning work that I had done previously but:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Its testable using vagrant&lt;/li&gt;
  &lt;li&gt;Its repeatable&lt;/li&gt;
  &lt;li&gt;All the tools I rely on are there&lt;/li&gt;
  &lt;li&gt;I can add new boxes just by modifying a single inventory file&lt;/li&gt;
  &lt;li&gt;Even things I used to have to do manually I can now automate&lt;/li&gt;
  &lt;li&gt;I’ve improved security my adopting elements of the &lt;a href=&quot;https://12factor.net&quot;&gt;12 factor approach&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;It works&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;how-does-this-bring-down-our-costs&quot;&gt;How Does this Bring Down Our Costs?&lt;/h1&gt;

&lt;p&gt;Well if machines aren’t unique snowflakes, if they are things you can regenerate then you have the ability to better negotiate your rates.  When you’re prepared to go elsewhere, you’ll have the confidence to actually explore your alternatives.  I’ve never even considered moving from the hosting company I went to in 2014 purely because of the amount of effort it would entail.  Now that I can programmatically build the infrastructure I need?  You can bet that I’ll either be asking for lower rates or moving on.&lt;/p&gt;
</description>
        <pubDate>Fri, 30 Sep 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/ansible/2016/09/30/using-ansible-to-drive-down-hosting-costs.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/ansible/2016/09/30/using-ansible-to-drive-down-hosting-costs.html</guid>
        
        <category>ansible</category>
        
        <category>hosting</category>
        
        
        <category>ansible</category>
        
      </item>
    
  </channel>
</rss>
