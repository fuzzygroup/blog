<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>FuzzyBlog</title>
    <description>Scott Johnson writing about the usual array of nerd stuff: AWS / Ansible / Ruby / Rails / Elixir / Misc / Hyde.
</description>
    <link>http://fuzzyblog.io//blog/</link>
    <atom:link href="http://fuzzyblog.io//blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 24 May 2017 14:21:25 -0400</pubDate>
    <lastBuildDate>Wed, 24 May 2017 14:21:25 -0400</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>10 Things Software Engineering Daily Taught Me</title>
        <description>&lt;p&gt;Software Engineering Daily is my absolute favorite podcast and it has replaced almost all my daily listens – no more Major Spoilers, very limited Geek History Lessons, etc.  And the main reason is 
## Homomorphic Encryption&lt;/p&gt;

&lt;h2 id=&quot;indie-hacking-exists&quot;&gt;Indie Hacking Exists!&lt;/h2&gt;

&lt;p&gt;That indie hacking is a thing&lt;/p&gt;

&lt;p&gt;SE Daily - Learned&lt;/p&gt;

&lt;p&gt;Software Psychology&lt;/p&gt;

&lt;p&gt;Subtle Engineering Complexitits - transition of&lt;/p&gt;

&lt;p&gt;a distributed system of services is much harder in its debugging characteristics than a monolith – its much harder to put in breakpoints&lt;/p&gt;

&lt;p&gt;17:03&lt;/p&gt;

</description>
        <pubDate>Tue, 16 May 2017 12:18:16 -0400</pubDate>
        <link>http://fuzzyblog.io//blog/2017/05/16/10-things-software-engineering-daily-taught-me.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/2017/05/16/10-things-software-engineering-daily-taught-me.html</guid>
        
        
      </item>
    
      <item>
        <title>Adding Cron to a Dockerized Rails Application Using Clockwork</title>
        <description>&lt;p&gt;If you talk to any computer scientist they will easily tell you that 50 plus years into the computer age, scheduling is NOT a solved problem.  Even something as simple as cron which is decades old can still be challenging under different environments (example - cron and RVM is a bloody nightmare).  And then when you add containers into the mix, well …  In this blog post I outline how I’m handling a daily scheduled process using Docker and Clockwork (a cron like gem for Ruby).&lt;/p&gt;

&lt;h1 id=&quot;why-is-cron-and-docker-a-problem&quot;&gt;Why is Cron and Docker a Problem&lt;/h1&gt;

&lt;p&gt;Docker represents a simplified computing environment where you generally don’t have a full Linux stack – instead the model is generally a single root process.  Now there are people who challenge that approach, notably the good folks at Phusion, but this is generally regarded as a best practice.  So you’re not your own application stack and then cron as well.&lt;/p&gt;

&lt;h1 id=&quot;enter-clockwork&quot;&gt;Enter Clockwork&lt;/h1&gt;

&lt;p&gt;Clockwork is a long standing Ruby gem which acts as a persistent daemon with its own scheduler that executes a simple DSL allow your models to be easily executed.  Here’s an example:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;every(1.day, 'Midnight.job -- PageArchive.update_everything', :at =&amp;gt; '00:00') do |job|
  PageArchive.update_everything
end
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Unlike traditional cron syntax, I’ve never found an issue with reading the Clockwork dsl, this says:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;every day&lt;/li&gt;
  &lt;li&gt;execute at midnight&lt;/li&gt;
  &lt;li&gt;run PageArchive.update_everything&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;adding-clockwork-to-your-rails-application&quot;&gt;Adding Clockwork to your Rails Application&lt;/h1&gt;

&lt;p&gt;Here are the steps to add clockwork to your Rails application:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Add the clockwork gem to your Gemfile:&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;gem ‘clockwork’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;Create a clock.rb file in lib:&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;touch lib/clock.rb&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Write one or more clockwork expressions in clock.rb.  Here’s an example from my application:&lt;/p&gt;

    &lt;p&gt;require ‘clockwork’
include Clockwork&lt;/p&gt;

    &lt;p&gt;require File.expand_path(‘../../config/boot’, &lt;strong&gt;FILE&lt;/strong&gt;)&lt;/p&gt;

    &lt;p&gt;require File.expand_path(‘../../config/environment’, &lt;strong&gt;FILE&lt;/strong&gt;)&lt;/p&gt;

    &lt;p&gt;require ‘clockwork’&lt;/p&gt;

    &lt;p&gt;include Clockwork&lt;/p&gt;

    &lt;p&gt;module Clockwork&lt;/p&gt;

    &lt;p&gt;every(1.day, ‘Midnight.job – PageArchive.update_everything’, :at =&amp;gt; ‘03:58’) do |job|
    PageArchive.update_everything
  end&lt;/p&gt;

    &lt;p&gt;every(1.week, ‘Weekly Job – PageArchive.update_bing’, :at =&amp;gt; ‘00:00’) do |job|
    PageArchive.update_bing
  end&lt;/p&gt;

    &lt;p&gt;end&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;To test this you can just use the command line:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;bundle exec clockwork lib/clock.rb&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Once you set that running then you need to simply watch it to make sure that tasks execute.  Yes, provided that your syntax is correct, they certainly should but I’ve seen enough scheduled jobs fail over the years that I always feel better when I actually see them run.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you were previously using a Rake task to run your daily jobs then you need to refactor that as something like a class method that can be called from the Rake task.  This allows you to continue using the Rake task but also make your code easily executable from Clockwork.&lt;/p&gt;

&lt;h1 id=&quot;the-dockerfile&quot;&gt;The Dockerfile&lt;/h1&gt;

&lt;p&gt;In this example I have a simple Rails app which exists to populate a page archive database consisting of data harvested daily from the Internet.  Here’s the Dockerfile:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;FROM ruby:2.3.1-alpine

RUN apk update &amp;amp;&amp;amp; apk add build-base nodejs mariadb-dev tzdata

RUN mkdir /app
WORKDIR /app

COPY Gemfile Gemfile.lock ./
RUN bundle install --binstubs

COPY . .

CMD bundle exec clockwork lib/clock.rb
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The secret to making the scheduling work is to execute the clockwork executable as the root command in the container. This causes the Clockwork executable to be launched when the container initializes.  At that point Clockwork will run the command until it finishes and then remain running, waiting for its next invocation.&lt;/p&gt;

&lt;h1 id=&quot;conclusion-and-issues&quot;&gt;Conclusion and Issues&lt;/h1&gt;

&lt;p&gt;As you can see, when you have a scheduling process as the root process in your container, it provides an easy way to handle your scheduled job needs and Clockwork really does make it easy.  Still this doesn’t mean that scheduling for your application is necessarily solved:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What if your needs are large enough that you have to have multiple machines?&lt;/li&gt;
  &lt;li&gt;How do you log issues with the scheduled jobs?&lt;/li&gt;
  &lt;li&gt;What happens when a deploy occurs while your container is running a job?  How do you ensure that the day’s work actually got processed?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;multiple-machines&quot;&gt;Multiple Machines&lt;/h2&gt;

&lt;p&gt;If I needed to have multiple machines involved, I would likely implement some kind of a work queue where they scheduler is solely responsible for setting up a queue of the work to be done and then containers on other machines are responsible for processing the data in the queue.  This approach is also useful for the deploy issue covered below.&lt;/p&gt;

&lt;h2 id=&quot;logging-issues-with-scheduled-jobs&quot;&gt;Logging Issues with Scheduled Jobs&lt;/h2&gt;

&lt;p&gt;There are enough issues with containers and logs that addressing it here is really out of the scope of this blog post.  I did want to point it out, however, as logging around scheduled jobs is usually necessary and needs to be thought through.&lt;/p&gt;

&lt;h2 id=&quot;deploy-conflicts&quot;&gt;Deploy Conflicts&lt;/h2&gt;

&lt;p&gt;There are at least three strategies that I’d use for handling deploy conflicts:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Start your jobs early and simply don’t deploy while they are running.  This is the least desirable strategy but it does actually work provided the execution time of the job is only a few hours (i.e. until when people need to deploy).  Obviously this works poorly with a globally distributed labor pool and a CI server that deploys code automatically.&lt;/li&gt;
  &lt;li&gt;Change the code so that jobs become idempotent i.e. the job knows that a particular data item can be processed, for example, only once per day and then allow the scheduled process to be run multiple times per day.  This decreases the chance of a deploy shutting things down fully for an entire day since statistically it becomes less likely that you’ll conflict with something every single time that it is running allowing at least one of the runs to complete.&lt;/li&gt;
  &lt;li&gt;Use the multiple machines strategy mentioned above so that you have a work queue and multiple asynchronous processing engines on the data.  As long as the queue is atomic in nature this avoids duplication issues and the additional parallelism that multiple containers bring should process the data more quickly thereby leading to fewer deploy conflicts.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Of each of these strategies, the third is likely the best but incurs the most application level changes.  Please keep in mind that you can iteratively evolve your application towards the right strategy for your needs.&lt;/p&gt;

</description>
        <pubDate>Thu, 11 May 2017 05:02:25 -0400</pubDate>
        <link>http://fuzzyblog.io//blog/rails/2017/05/11/adding-cron-to-a-dockerized-rails-application-using-clockwork.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/rails/2017/05/11/adding-cron-to-a-dockerized-rails-application-using-clockwork.html</guid>
        
        <category>rails</category>
        
        <category>docker</category>
        
        <category>cron</category>
        
        <category>clockwork</category>
        
        
        <category>rails</category>
        
      </item>
    
      <item>
        <title>Adding Cron to a Dockerized Rails Application Using Clockwork</title>
        <description>&lt;p&gt;If you talk to any computer scientist they will easily tell you that 50 plus years into the computer age, scheduling is NOT a solved problem.  Even something as simple as cron which is decades old can still be challenging under different environments (example - cron and RVM is a bloody nightmare).  And then when you add containers into the mix, well …  In this blog post I outline how I’m handling a daily scheduled process using Docker and Clockwork (a cron like gem for Ruby).&lt;/p&gt;

&lt;h1 id=&quot;why-is-cron-and-docker-a-problem&quot;&gt;Why is Cron and Docker a Problem&lt;/h1&gt;

&lt;p&gt;Docker represents a simplified computing environment where you generally don’t have a full Linux stack – instead the model is generally a single root process.  Now there are people who challenge that approach, notably the good folks at Phusion, but this is generally regarded as a best practice.  So you’re not your own application stack and then cron as well.&lt;/p&gt;

&lt;h1 id=&quot;enter-clockwork&quot;&gt;Enter Clockwork&lt;/h1&gt;

&lt;p&gt;Clockwork is a long standing Ruby gem which acts as a persistent daemon with its own scheduler that executes a simple DSL allow your models to be easily executed.  Here’s an example:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;every(1.day, 'Midnight.job -- PageArchive.update_everything', :at =&amp;gt; '00:00') do |job|
  PageArchive.update_everything
end
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Unlike traditional cron syntax, I’ve never found an issue with reading the Clockwork dsl, this says:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;every day&lt;/li&gt;
  &lt;li&gt;execute at midnight&lt;/li&gt;
  &lt;li&gt;run PageArchive.update_everything&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;adding-clockwork-to-your-rails-application&quot;&gt;Adding Clockwork to your Rails Application&lt;/h1&gt;

&lt;p&gt;Here are the steps to add clockwork to your Rails application:&lt;/p&gt;

&lt;p&gt;Add the clockwork gem to your Gemfile:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;gem ‘clockwork’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Create a clock.rb file in lib:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;touch lib/clock.rb&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Write one or more clockwork expressions in clock.rb.  Here’s an example from my application:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;require 'clockwork'
include Clockwork

require File.expand_path('../../config/boot', __FILE__)

require File.expand_path('../../config/environment', __FILE__)

require 'clockwork'

include Clockwork

module Clockwork

  every(1.day, 'Midnight.job -- PageArchive.update_everything', :at =&amp;gt; '03:58') do |job|
    PageArchive.update_everything
  end

  every(1.week, 'Weekly Job -- PageArchive.update_bing', :at =&amp;gt; '00:00') do |job|
    PageArchive.update_bing
  end

end
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;To test this you can just use the command line:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;bundle exec clockwork lib/clock.rb&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Once you set that running then you need to simply watch it to make sure that tasks execute.  Yes, provided that your syntax is correct, they certainly should but I’ve seen enough scheduled jobs fail over the years that I always feel better when I actually see them run.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you were previously using a Rake task to run your daily jobs then you need to refactor that as something like a class method that can be called from the Rake task.  This allows you to continue using the Rake task but also make your code easily executable from Clockwork.&lt;/p&gt;

&lt;h1 id=&quot;the-dockerfile&quot;&gt;The Dockerfile&lt;/h1&gt;

&lt;p&gt;In this example I have a simple Rails app which exists to populate a page archive database consisting of data harvested daily from the Internet.  Here’s the Dockerfile:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;FROM ruby:2.3.1-alpine

RUN apk update &amp;amp;&amp;amp; apk add build-base nodejs mariadb-dev tzdata

RUN mkdir /app
WORKDIR /app

COPY Gemfile Gemfile.lock ./
RUN bundle install --binstubs

COPY . .

CMD bundle exec clockwork lib/clock.rb
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The secret to making the scheduling work is to execute the clockwork executable as the root command in the container. This causes the Clockwork executable to be launched when the container initializes.  At that point Clockwork will run the command until it finishes and then remain running, waiting for its next invocation.&lt;/p&gt;

&lt;h1 id=&quot;conclusion-and-issues&quot;&gt;Conclusion and Issues&lt;/h1&gt;

&lt;p&gt;As you can see, when you have a scheduling process as the root process in your container, it provides an easy way to handle your scheduled job needs and Clockwork really does make it easy.  Still this doesn’t mean that scheduling for your application is necessarily solved:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What if your needs are large enough that you have to have multiple machines?&lt;/li&gt;
  &lt;li&gt;How do you log issues with the scheduled jobs?&lt;/li&gt;
  &lt;li&gt;What happens when a deploy occurs while your container is running a job?  How do you ensure that the day’s work actually got processed?&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;multiple-machines&quot;&gt;Multiple Machines&lt;/h2&gt;

&lt;p&gt;If I needed to have multiple machines involved, I would likely implement some kind of a work queue where they scheduler is solely responsible for setting up a queue of the work to be done and then containers on other machines are responsible for processing the data in the queue.  This approach is also useful for the deploy issue covered below.&lt;/p&gt;

&lt;h2 id=&quot;logging-issues-with-scheduled-jobs&quot;&gt;Logging Issues with Scheduled Jobs&lt;/h2&gt;

&lt;p&gt;There are enough issues with containers and logs that addressing it here is really out of the scope of this blog post.  I did want to point it out, however, as logging around scheduled jobs is usually necessary and needs to be thought through.&lt;/p&gt;

&lt;h2 id=&quot;deploy-conflicts&quot;&gt;Deploy Conflicts&lt;/h2&gt;

&lt;p&gt;There are at least three strategies that I’d use for handling deploy conflicts:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Start your jobs early and simply don’t deploy while they are running.  This is the least desirable strategy but it does actually work provided the execution time of the job is only a few hours (i.e. until when people need to deploy).  Obviously this works poorly with a globally distributed labor pool and a CI server that deploys code automatically.&lt;/li&gt;
  &lt;li&gt;Change the code so that jobs become idempotent i.e. the job knows that a particular data item can be processed, for example, only once per day and then allow the scheduled process to be run multiple times per day.  This decreases the chance of a deploy shutting things down fully for an entire day since statistically it becomes less likely that you’ll conflict with something every single time that it is running allowing at least one of the runs to complete.&lt;/li&gt;
  &lt;li&gt;Use the multiple machines strategy mentioned above so that you have a work queue and multiple asynchronous processing engines on the data.  As long as the queue is atomic in nature this avoids duplication issues and the additional parallelism that multiple containers bring should process the data more quickly thereby leading to fewer deploy conflicts.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Of each of these strategies, the third is likely the best but incurs the most application level changes.  Please keep in mind that you can iteratively evolve your application towards the right strategy for your needs.&lt;/p&gt;

</description>
        <pubDate>Thu, 11 May 2017 00:00:00 -0400</pubDate>
        <link>http://fuzzyblog.io//blog/rails/2017/05/11/adding-cron-to-a-dockerized-rails-application-using-clockwork.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/rails/2017/05/11/adding-cron-to-a-dockerized-rails-application-using-clockwork.html</guid>
        
        <category>rails</category>
        
        <category>docker</category>
        
        <category>cron</category>
        
        <category>clockwork</category>
        
        
        <category>rails</category>
        
      </item>
    
      <item>
        <title>Building a Rails API App Which Accepts Data from JavaScript</title>
        <description>&lt;p&gt;A friend recently described a web tracking problem to me and we discussed looking at it via Google Analytics or by rolling our own approach.  Google Analytics is tremendously powerful but I looked at this as a chance to improve my JavaScript skills which are, admittedly, not my strongest part of my technical skill set so I went with the roll my own approach.  As with most things I do, I’m writing this out in full to clarify my own thinking and understanding of the problem as well as to make this information publicly available.&lt;/p&gt;

&lt;h1 id=&quot;problem&quot;&gt;Problem&lt;/h1&gt;

&lt;p&gt;The problem at hand was to record tracking data as people viewed pages on an e-commerce web site.  The goal was to correlate the tracking data and try and resolve the per visitor url paths that were traversed.  I also wanted to experiment with browser fingerprinting so I used the FingerprintJS2 library.&lt;/p&gt;

&lt;h1 id=&quot;solution&quot;&gt;Solution&lt;/h1&gt;

&lt;p&gt;The solution was two fold:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;JavaScript that runs in the browser and executes an HTTP get with the details of the url that the user visited&lt;/li&gt;
  &lt;li&gt;A Rails API server that accepts the details of the url that was visited and logs it to a database&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;part-1-javascript&quot;&gt;Part 1: JavaScript&lt;/h1&gt;

&lt;p&gt;I’m not a JavaScript expert by any means so this js code was largely pulled together from StackOverflow and other sources (references are at the end).  I ended up writing this twice, first starting with jQuery and then realizing that for something embeddable you really want to eliminate every dependency – so getting rid of jQuery itself is a desirable goal.&lt;/p&gt;

&lt;h2 id=&quot;browser-fingerprinting&quot;&gt;Browser Fingerprinting&lt;/h2&gt;

&lt;p&gt;A browser fingerprint is an SHA / MD5 style hash which reflects a unique profile of a browser based on the browser’s uniquely exposed capabilities, platform, fonts and other attributes.  While not necessarily as unique as a fingerprint, browser fingerprint is actually a robust approach to tracking a user and since it is based on readily available &lt;a href=&quot;https://github.com/Valve/fingerprintjs2&quot;&gt;open source libraries&lt;/a&gt;, it isn’t something that needs to be developed from scratch.  And, happily, it even gets good marks on my new &lt;a href=&quot;http://shouldigem.com/report_cards/146?url=https%3A%2F%2Fgithub.com%2FValve%2Ffingerprintjs2&quot;&gt;Should I Gem&lt;/a&gt; tool.&lt;/p&gt;

&lt;p&gt;Here’s all it takes to calculate a browser fingerprint:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;!-- bring in the library --&amp;gt;
&amp;lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/fingerprintjs2/1.5.1/fingerprint2.min.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;!-- the hash will be in the variable result --&amp;gt;
&amp;lt;script type=&quot;text/javascript&quot;&amp;gt;
    new Fingerprint2().get(function(result, components){
    }
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now that we know how to calculate a browser fingerprint, the next step is the sending it to our API service either by jQuery or a native XHR call.&lt;/p&gt;

&lt;h2 id=&quot;the-jquery-approach&quot;&gt;The jQuery Approach&lt;/h2&gt;

&lt;p&gt;Here’s the jQuery code:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/fingerprintjs2/1.5.1/fingerprint2.min.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script type=&quot;text/javascript&quot;&amp;gt;
    new Fingerprint2().get(function(result, components){
 
    $(document).ready(function(){

         $.post('http://localhost:3820/api/log_it', {
           &quot;api_key&quot;: &quot;foobarbaz&quot;,
           &quot;url&quot;: window.location.href,
           &quot;fingerprint&quot;: result
         }, function(serverResponse){
         })

     })
 
   });
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;the-xhr-approach&quot;&gt;The XHR Approach&lt;/h2&gt;

&lt;p&gt;Here’s the XHR code:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;script type=&quot;text/javascript&quot; src=&quot;https://cdnjs.cloudflare.com/ajax/libs/fingerprintjs2/1.5.1/fingerprint2.min.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script type=&quot;text/javascript&quot;&amp;gt;
    new Fingerprint2().get(function(result, components){
      var xhr = new XMLHttpRequest();
      var dest_url = &quot;http://localhost:3820/api/log_it?&quot; + &quot;api_key=&quot; + &quot;foobarbaz&quot; + &quot;&amp;amp;&quot; + &quot;url=&quot; + window.location.href + &quot;&amp;amp;&quot; + &quot;fingerprint=&quot; + result;
      xhr.open('GET', dest_url);
      xhr.onreadystatechange = function(e) {
        if(xhr.readyState === 4)
          console.log(&quot;got result: &quot;, xhr.responseText);
      };
      xhr.send();
   });
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;part-2-rails-api-server&quot;&gt;Part 2: Rails API Server&lt;/h1&gt;

&lt;p&gt;I’ve become an increasing fan of microservices as an architectural paradigm and Rails API servers are something I now generate regularly.  Here’s how I did that:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;rails new –api tracking_api –database=mysql –skip-spring –skip-listen –skip-sprockets&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You’ll notice that I’m skipping spring and listen which gets rid of the &lt;a href=&quot;http://fuzzyblog.io/blog/osx/2017/03/20/getting-around-osx-bash-fork-issues.html&quot;&gt;disaster that is the evented file watcher on OSX&lt;/a&gt; / &lt;a href=&quot;https://github.com/puma/puma-dev/issues/56&quot;&gt;Github Issue&lt;/a&gt; (this causes huge issues with overly aggressive process launching).&lt;/p&gt;

&lt;h2 id=&quot;getting-past-cors-restrictions&quot;&gt;Getting Past CORS Restrictions&lt;/h2&gt;

&lt;p&gt;Once this is done we need to add the rack-cors gem with:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;gem ‘rack-cors’&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;in the Gemfile.  In case you’ve been following what I’ve done with &lt;a href=&quot;http://www.shouldigem.com&quot;&gt;ShouldIGem.com&lt;/a&gt;, you might be curious how rack-cors fared – it got an &lt;a href=&quot;http://shouldigem.com/report_cards/141?url=https%3A%2F%2Fgithub.com%2Fcyu%2Frack-cors&quot;&gt;A&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The rack-cors gem addresses the problems with Cross Origin Scripting (CORS) by allowing domain X to post or get to domain Y.  While there are a bunch of other approaches to getting around CORS, the rack-cors gem was by far the best solution I found.&lt;/p&gt;

&lt;p&gt;Note: There are security implications if you open rack-cors to everything; please keep that in mind.&lt;/p&gt;

&lt;h2 id=&quot;writing-the-api&quot;&gt;Writing the Api&lt;/h2&gt;

&lt;p&gt;After a bundle install, I generated an Api controller with:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;bundle exec rails g controller api&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I then wrote a simple method to capture the data and save it to a PageView object in the database:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class ApiController &amp;lt; ApplicationController
  
  def log_it
    PageView.create_page_view(params[:fingerprint], request.remote_ip, params[:url], request.user_agent)
  end

end
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;I then needed to write a route for this as follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Rails.application.routes.draw do
  get '/api/log_it', to: 'api#log_it'
end
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The PageView object is simply an ActiveRecord model which logs the view to the database and it is simple enough that I’m not going to cover it here.&lt;/p&gt;

&lt;p&gt;Note: This is a simplified controller.  I have deliberately omitted handling the api key parameter which limits calls against the API to only those with valid API keys.&lt;/p&gt;

&lt;h2 id=&quot;testing-this-with-wget-or-curl&quot;&gt;Testing this with Wget or Curl&lt;/h2&gt;

&lt;p&gt;As I wrote about previously, I’m a huge believer in using curl or wget to test APIs.  Here is a simple wget statement that exercises the API as you tail a log file to make sure everything works:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;wget “http://localhost:3820/api/log_it?api_key=foobarbaz&amp;amp;url=http%3A%2F%2Flocalhost%3A3400%2F&amp;amp;fingerprint=e82eaadd”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;testing-this-from-the-browser&quot;&gt;Testing this From the Browser&lt;/h2&gt;

&lt;p&gt;To test this from the browser just embed it in an HTML page and tail the logs on the API service.  Here’s what those logs look like:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Started GET &quot;/api/log_it?api_key=foobarbaz&amp;amp;url=http://localhost:3400/&amp;amp;fingerprint=e82eaadd998e1aae0309b781029f8edb&quot; for 127.0.0.1 at 2017-05-09 18:35:32 -0400
Processing by ApiController#log_it as */*
  Parameters: {&quot;api_key&quot;=&amp;gt;&quot;hyde314159&quot;, &quot;url&quot;=&amp;gt;&quot;http://localhost:3400/&quot;, &quot;fingerprint&quot;=&amp;gt;&quot;e82eaadd998e1aae0309b781029f8edb&quot;}
   (0.2ms)  BEGIN
  SQL (0.4ms)  INSERT INTO `page_views` (`created_at`, `updated_at`, `date_created_at`, `fingerprint`, `ip_address`, `user_agent`, `url`, `url_base`) VALUES ('2017-05-09 22:35:32', '2017-05-09 22:35:32', '2017-05-09', 'e82eaadd998e1aae0309b781029f8edb', '127.0.0.1', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.96 Safari/537.36', 'http://localhost:3400/', 'localhost/')
   (0.8ms)  COMMIT
Completed 204 No Content in 4ms (ActiveRecord: 1.4ms)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h1&gt;

&lt;p&gt;This was an interesting exercise which taught me a bit of JavaScript, illustrated how to use the browser fingerprinting and finally taught me a way around CORS restrictions – the rack-cors gem.  Hopefully this blog post illustrated for you how to integrate external JavaScript with a Rails api.&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/38290552/using-rest-api-and-send-post-request&quot;&gt;http://stackoverflow.com/questions/38290552/using-rest-api-and-send-post-request&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/1034621/get-current-url-in-web-browser&quot;&gt;http://stackoverflow.com/questions/1034621/get-current-url-in-web-browser&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://test-cors.org/&quot;&gt;http://test-cors.org/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/monsur/test-cors.org&quot;&gt;https://github.com/monsur/test-cors.org&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/jpillora/xdomain&quot;&gt;https://github.com/jpillora/xdomain&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://learn.jquery.com/ajax/working-with-jsonp/&quot;&gt;https://learn.jquery.com/ajax/working-with-jsonp/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/29751115/how-to-enable-cors-in-rails-4-app&quot;&gt;http://stackoverflow.com/questions/29751115/how-to-enable-cors-in-rails-4-app&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/cyu/rack-cors&quot;&gt;https://github.com/cyu/rack-cors&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://stackoverflow.com/questions/20035101/no-access-control-allow-origin-header-is-present-on-the-requested-resource&quot;&gt;http://stackoverflow.com/questions/20035101/no-access-control-allow-origin-header-is-present-on-the-requested-resource&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 10 May 2017 00:00:00 -0400</pubDate>
        <link>http://fuzzyblog.io//blog/rails/2017/05/10/building-a-rails-api-app-which-accepts-data-from-javascript.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/rails/2017/05/10/building-a-rails-api-app-which-accepts-data-from-javascript.html</guid>
        
        <category>rails</category>
        
        <category>javascript</category>
        
        <category>api</category>
        
        <category>cors</category>
        
        <category>fingerprint</category>
        
        
        <category>rails</category>
        
      </item>
    
      <item>
        <title>AVP versus MVP</title>
        <description>
</description>
        <pubDate>Mon, 08 May 2017 18:47:10 -0400</pubDate>
        <link>http://fuzzyblog.io//blog/2017/05/08/avp-versus-mvp.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/2017/05/08/avp-versus-mvp.html</guid>
        
        
      </item>
    
      <item>
        <title>Building a Multitenant SAAS App with Rails, Docker, MySQL and the Apartment Gem</title>
        <description>&lt;h1 id=&quot;saas-and-provisioning&quot;&gt;SAAS and Provisioning&lt;/h1&gt;

&lt;p&gt;This document lays out the SAAS and provisioning aspects of SeiraWatch.&lt;/p&gt;

&lt;h1 id=&quot;types-of-saas-isolation&quot;&gt;Types of SAAS Isolation&lt;/h1&gt;

&lt;p&gt;At the heart of any SAAS app is isolating one user’s data from another.  There are several ways to do this but the simplest are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;scoping&lt;/li&gt;
  &lt;li&gt;schemaing&lt;/li&gt;
  &lt;li&gt;separating&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Scoping refers to bundling a user_id or account_id parameter with every single query so that you are always injecting the isolation with every query.  There are several disadvantages to this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Assumes that every db query is ActiveRecord and can be automagically done&lt;/li&gt;
  &lt;li&gt;Eliminates straight sql or pushes it down to the user&lt;/li&gt;
  &lt;li&gt;If something goes wrong User A gets access to User B’s data&lt;/li&gt;
  &lt;li&gt;Adds a tricky bit of Rails magic to what is literally the most complex part of your application (storage)&lt;/li&gt;
  &lt;li&gt;Pushes performance issues right onto the developer since every index has to incorporate user_id or account_id as well as all othe rthings&lt;/li&gt;
  &lt;li&gt;The core db will grow in size infiniitely leading to an ever more costly database server&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Schemaing means using the ability of Postgres to run multiple schemas per physical database.  This is dramatically better than scoping but also has disadvantages:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ties you irrevocably to Postgres&lt;/li&gt;
  &lt;li&gt;The core db will grow in size infiniitely leading to an ever more costly database server&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Separating means just what it sounds – every user or account gets a &lt;strong&gt;separate&lt;/strong&gt; database.  This is the approach that WordPress uses and its hard to argue with the sucess of WordPress.  While everything has its issues, I like the disavantages here best of all:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;More expensive since it means more physical databases but this is 2017 and we’re up to 64 bit servers now; we can get past this.&lt;/li&gt;
  &lt;li&gt;In a broken up, non-monolith this is intimidating to implement but its actually pretty easy once you get your head around it&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;provisioning-approach&quot;&gt;Provisioning Approach&lt;/h1&gt;

&lt;p&gt;In order to make the provisioning work we need to rely on the Apartment gem.  Apartment is a multitenancy gem which allows subdomain based tenancy so we can have a domain structure like this:&lt;/p&gt;

&lt;p&gt;www.seirawatch.com - the site
nickjj.seirawatch.com - nick’s account
fuzzygroup.seirawatch.com - scott’s account
…&lt;/p&gt;

&lt;p&gt;Each new customer will get to register a username and that will become their subdomain that they log in by.  We will end up running one seira_watch_web_app container which can be autoscaled (since each database connection is separate) for load and we only need to run enough initial capacity that at least one instance is always available.&lt;/p&gt;

&lt;p&gt;The way that the Apartment gem works is by changing the database it is using on the fly automatically based on the subdomain.  Here’s a peek at the logs from a test application:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# when I visited blog_1_development.lvmh.me:3000 (I started puma with -b lvmh.me:3000)
Started GET &quot;/&quot; for 127.0.0.1 at 2017-04-23 23:24:19 -0400
   (0.1ms)  use `apartment_development`
   (0.2ms)  SELECT DATABASE() as db
   (0.1ms)  use `blog_1_development`
Processing by Rails::WelcomeController#index as HTML
  Parameters: {&quot;internal&quot;=&amp;gt;true}
  Rendering /Users/sjohnson/.rvm/gems/ruby-2.3.1/gems/railties-5.0.2/lib/rails/templates/rails/welcome/index.html.erb
  Rendered /Users/sjohnson/.rvm/gems/ruby-2.3.1/gems/railties-5.0.2/lib/rails/templates/rails/welcome/index.html.erb (4.5ms)
Completed 200 OK in 11ms (Views: 7.1ms | ActiveRecord: 0.0ms)

  # when I visited foo.lvmh.me:3000 (I started puma with -b lvmh.me:3000)
   (0.5ms)  use `apartment_development`
Started GET &quot;/&quot; for 127.0.0.1 at 2017-04-23 23:24:23 -0400
   (0.6ms)  use `apartment_development`
   (0.3ms)  SELECT DATABASE() as db
   (0.2ms)  use `foo`
Processing by Rails::WelcomeController#index as HTML
  Parameters: {&quot;internal&quot;=&amp;gt;true}
  Rendering /Users/sjohnson/.rvm/gems/ruby-2.3.1/gems/railties-5.0.2/lib/rails/templates/rails/welcome/index.html.erb
  Rendered /Users/sjohnson/.rvm/gems/ruby-2.3.1/gems/railties-5.0.2/lib/rails/templates/rails/welcome/index.html.erb (3.3ms)
Completed 200 OK in 9ms (Views: 6.0ms | ActiveRecord: 0.0ms)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;adding-an-api-from-another-monolith-component&quot;&gt;Adding an API from Another Monolith Component&lt;/h2&gt;

&lt;p&gt;The way that Apartment works is that has a call:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Apartment::Tenant.create(tenant_name)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;what you invoke in order to create the “tenancy” database (think subdomain) and this either runs migrations or uses schema.rb to create a new database.  The problem is that if you’re NOT building a monolith you are running in a context AWAY from the schema you need to clone.  The solution is two fold:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Add an api for provisioning to the SAAS app which allows for two calls: create_db and add_user&lt;/li&gt;
  &lt;li&gt;The create_db call takes a single, unique, username, a fully validated string and then invokes Apartment::Tenant.create&lt;/li&gt;
  &lt;li&gt;The add_user method takes all the params for the user instance that we want on the model and builds the user_instance&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This will allow a user to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;sign up at the web site (or commerce portion) if I decide to decouple signup and commerce from the home page&lt;/li&gt;
  &lt;li&gt;goto the subdomain and be automatically prompted for login&lt;/li&gt;
  &lt;li&gt;normal cookie based login approaches will preserve the login for the period of time of the cookie&lt;/li&gt;
  &lt;li&gt;allows normal development to continue with something like bundle exec rails s -p3010 -b lvh.me and still allow the right database to be selected when I goto nickjj.lvh.me:3010&lt;/li&gt;
  &lt;li&gt;should work brilliantly with Docker as a deployment tech and allow Docker to be used to test locally the entire stack&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Issues:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We need to block the common domains that we don’t want a user to register like www, help, search, admin, etc (this can be done when the username is created with a Rails validator)&lt;/li&gt;
  &lt;li&gt;Exactly how we let fuzzygroup into the SAAS container but not www is unclear but I would expect that’s an nginx proxying thing&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;thoughts&quot;&gt;Thoughts?&lt;/h1&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/influitive/apartment&quot;&gt;Apartment Gem&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/wireframe/multitenant&quot;&gt;MultiTenant Gem&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://codecrate.com/2011/03/multitenant-locking-down-your-app-and.html&quot;&gt;MultiTenant Blog Post&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.quora.com/How-can-I-operate-a-DB-model-for-a-Rails-multi-tenant-application-with-a-multiple-database-model&quot;&gt;Quora&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/citusdata/activerecord-multi-tenant&quot;&gt;ActiveRecord-Multi-Tenant&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/ErwinM/acts_as_tenant&quot;&gt;ActsAsTenant&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://influitive.io/our-multi-tenancy-journey-with-postgres-schemas-and-apartment-6ecda151a21f&quot;&gt;Blog Post About Apartment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;creating-a-tenant&quot;&gt;Creating a Tenant&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Apartment::Tenant.create(‘fuzzygroup5’)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;the-initializer&quot;&gt;The Initializer&lt;/h1&gt;

&lt;p&gt;Shown below is the apartment.rb initializer.  The changes needed to enable db level tenancy are indicated by &lt;strong&gt;jsj&lt;/strong&gt; in the comments.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# You can have Apartment route to the appropriate Tenant by adding some Rack middleware.
# Apartment can support many different &quot;Elevators&quot; that can take care of this routing to your data.
# Require whichever Elevator you're using below or none if you have a custom one.
#
# require 'apartment/elevators/generic'
# require 'apartment/elevators/domain'
require 'apartment/elevators/subdomain'
# require 'apartment/elevators/first_subdomain'

#
# Apartment Configuration
#
Apartment.configure do |config|

  # Add any models that you do not want to be multi-tenanted, but remain in the global (public) namespace.
  # A typical example would be a Customer or Tenant model that stores each Tenant's information.
  #
  # config.excluded_models = %w{ Tenant }

  # In order to migrate all of your Tenants you need to provide a list of Tenant names to Apartment.
  # You can make this dynamic by providing a Proc object to be called on migrations.
  # This object should yield either:
  # - an array of strings representing each Tenant name.
  # - a hash which keys are tenant names, and values custom db config (must contain all key/values required in database.yml)
  #
  # config.tenant_names = lambda{ Customer.pluck(:tenant_name) }
  # config.tenant_names = ['tenant1', 'tenant2']
  # config.tenant_names = {
  #   'tenant1' =&amp;gt; {
  #     adapter: 'postgresql',
  #     host: 'some_server',
  #     port: 5555,
  #     database: 'postgres' # this is not the name of the tenant's db
  #                          # but the name of the database to connect to before creating the tenant's db
  #                          # mandatory in postgresql
  #   },
  #   'tenant2' =&amp;gt; {
  #     adapter:  'postgresql',
  #     database: 'postgres' # this is not the name of the tenant's db
  #                          # but the name of the database to connect to before creating the tenant's db
  #                          # mandatory in postgresql
  #   }
  # }
  # config.tenant_names = lambda do
  #   Tenant.all.each_with_object({}) do |tenant, hash|
  #     hash[tenant.name] = tenant.db_configuration
  #   end
  # end
  #
  
  # jsj - this needed to be turned OFF 
  ###config.tenant_names = lambda { ToDo_Tenant_Or_User_Model.pluck :database }

  #
  # ==&amp;gt; PostgreSQL only options

  # Specifies whether to use PostgreSQL schemas or create a new database per Tenant.
  # The default behaviour is true.
  #
  # config.use_schemas = true
  
  # jsj - this needed to be set to false
  # required for mysql / Rails 5:
  # https://github.com/influitive/apartment/issues/345#issuecomment-258733219
  config.use_schemas = false

  # Apartment can be forced to use raw SQL dumps instead of schema.rb for creating new schemas.
  # Use this when you are using some extra features in PostgreSQL that can't be respresented in
  # schema.rb, like materialized views etc. (only applies with use_schemas set to true).
  # (Note: this option doesn't use db/structure.sql, it creates SQL dump by executing pg_dump)
  #
  # config.use_sql = false

  # There are cases where you might want some schemas to always be in your search_path
  # e.g when using a PostgreSQL extension like hstore.
  # Any schemas added here will be available along with your selected Tenant.
  #
  # config.persistent_schemas = %w{ hstore }

  # &amp;lt;== PostgreSQL only options
  #

  # By default, and only when not using PostgreSQL schemas, Apartment will prepend the environment
  # to the tenant name to ensure there is no conflict between your environments.
  # This is mainly for the benefit of your development and test environments.
  # Uncomment the line below if you want to disable this behaviour in production.
  #
  # config.prepend_environment = !Rails.env.production?
end

# Setup a custom Tenant switching middleware. The Proc should return the name of the Tenant that
# you want to switch to.
# Rails.application.config.middleware.use 'Apartment::Elevators::Generic', lambda { |request|
#   request.host.split('.').first
# }

# Rails.application.config.middleware.use 'Apartment::Elevators::Domain'

# jsj - this needed to be set
Rails.application.config.middleware.use 'Apartment::Elevators::Subdomain'
# Rails.application.config.middleware.use 'Apartment::Elevators::FirstSubdomain'
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

</description>
        <pubDate>Mon, 08 May 2017 18:46:08 -0400</pubDate>
        <link>http://fuzzyblog.io//blog/rails/2017/05/08/building-a-multitenant-saas-app-with-rails-docker-mysql-and-the-apartment-gem.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/rails/2017/05/08/building-a-multitenant-saas-app-with-rails-docker-mysql-and-the-apartment-gem.html</guid>
        
        <category>rails</category>
        
        <category>saas</category>
        
        <category>mysql</category>
        
        <category>multitenant</category>
        
        <category>docker</category>
        
        <category>saas</category>
        
        <category>mysql</category>
        
        
        <category>rails</category>
        
      </item>
    
      <item>
        <title>Deploying a Rails app to AWS with Docker Swarm</title>
        <description>&lt;p&gt;Historically I’ve deployed Rails apps via Vlad or Capistrano and, honestly, deployment is always one of the &lt;strong&gt;worst&lt;/strong&gt; parts of Rails.  I decided recently that I was just plain tired of classical deployment and I wanted to move to deploying via the new Docker Swarm.  I’m in an interesting position where I need to launching N things over the next few months and thought of struggling with Capistrano every time I want to make something publicly available is, honestly, more than I can bear.  I’m looking at Docker and Docker Swarm from the perspective of there &lt;strong&gt;has&lt;/strong&gt; to be a better way.&lt;/p&gt;

&lt;h1 id=&quot;application-description&quot;&gt;Application Description&lt;/h1&gt;

&lt;p&gt;In order to teach myself this new style of deployment, I didn’t want to use a toy application.  I wanted a real app that served a real purpose so I came up with the idea of a web app which evaluates a gem from GitHub and answers the question of “Should I (use this) Gem?”.  I call it &lt;a href=&quot;http://www.shouldigem.com/&quot;&gt;ShouldIGem&lt;/a&gt; and it is live on the web in a minimal state.&lt;/p&gt;

&lt;p&gt;This would give me a:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;rails app&lt;/li&gt;
  &lt;li&gt;that uses network i/o&lt;/li&gt;
  &lt;li&gt;exercises a code base I’ve been building to illustrate possible issues&lt;/li&gt;
  &lt;li&gt;uses multiple AWS resources in a scalable way - micro instances and RDS&lt;/li&gt;
  &lt;li&gt;that uses Puma as a an application server&lt;/li&gt;
  &lt;li&gt;separates the different functional parts of a Rails app into different “containers” i.e. web, sidekiq, migrations, redis&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Even though most applications of Docker seem to use a CI server, I wanted to do this at least quasi manually so I had a better understanding of what’s actually happening under the hood.  By the end I mildly regretted not using a CI server but I suspect the effort to setup a CI server would have been similar and I would have learned far less.&lt;/p&gt;

&lt;p&gt;Surprisingly I didn’t actually have to do all that much development to pull this off.  Over the past several months, ever since I left my full time gig, I’ve been developing an HTML micro expression parsing engine and this is simply an application of it.&lt;/p&gt;

&lt;p&gt;I call this application &lt;em&gt;Should I Gem&lt;/em&gt; and it is online at &lt;a href=&quot;http://www.shouldigem.com/&quot;&gt;http://www.shouldigem.com/&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;thank-you&quot;&gt;Thank You&lt;/h1&gt;

&lt;p&gt;A good friend is Nick Janetakis who is a Docker Captain and has taught over 10,000 people how to use Docker.  His latest course is &lt;a href=&quot;https://diveintodocker.com/courses/dive-into-docker&quot;&gt;Dive Into Docker&lt;/a&gt;.  He pitched in on this and while I’m the humble scribe here, he’s been the steadfast advocate for Docker, pushing me towards it for almost a year now.  Thanks Nick – I couldn’t have done it without you.  Additional thank yous related to this project can be found on the &lt;a href=&quot;http://www.shouldigem.com/pages/about&quot;&gt;About Page&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;things-to-understand&quot;&gt;Things to Understand&lt;/h1&gt;

&lt;p&gt;When you go into Docker Swarm, you’re not in the same old one server, one process Rails world you are likely used to.  You’re moving into a brave new world of zero downtime deploys and to support that, ideally, you need 2 of everything – 2 web instances, 2 sidekiq instances and so on.  This brings with it an increase in resource usage (mostly ram) so keep that in mind.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Since this is all being paid for on my own dime, I initially put this up on a single machine; no matter, changing it to multiple machines with Docker Swarm is actually trivial.&lt;/p&gt;

&lt;h1 id=&quot;getting-your-application-deployed-under-docker-swarm&quot;&gt;Getting Your Application Deployed Under Docker Swarm&lt;/h1&gt;

&lt;h2 id=&quot;step-1-create-an-aws-rds-instance-for-the-database&quot;&gt;Step 1: Create an AWS RDS Instance for the Database&lt;/h2&gt;

&lt;p&gt;The very first thing I did to get started was to decide that I wanted my persistent storage absolutely separate from Docker.  Yes I do know that Docker’s volume support makes this less absolutely necessary than it once was but I’m pretty old school when it comes to the data side of the equation so I used AWS RDS.&lt;/p&gt;

&lt;p&gt;To do this, I used the standard AWS RDS web front end and then copied the configuration parameters to database.yml.  Yes I could have used environment variables or secrets or something else but database.yml is just fine for a private app where there is only one developer.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Now that I’ve thought this over a bit, I understand more why in the Docker world, there is such a focus on environment variables versus static values checked into version control.  Historically I’ve always worked in terms of full time staff but in the brave new world of contract developers and freelancers, it does make sense to pull configuration away from people (particularly true with credentials like AWS api keys which can be so easily exploited if they escape into the wild).&lt;/p&gt;

&lt;h2 id=&quot;step-2-build-an-aws-instance-for-the-server&quot;&gt;Step 2: Build an AWS Instance for the Server&lt;/h2&gt;

&lt;p&gt;When you start talking about containers and cloud stuff, you often lose sight of the fact that there still are &lt;strong&gt;physical servers&lt;/strong&gt; involved and you’re going to need one to run your containers on.  Thinking of containers as &lt;em&gt;a runtime layer for a software stack&lt;/em&gt; is what finally make me understand them well enough to commit to using containers in production.&lt;/p&gt;

&lt;p&gt;All I did here is build a t2.micro instance, nothing special at all.&lt;/p&gt;

&lt;h2 id=&quot;step-3-make-an-aws-security-group-and-set-up-aws-billing-alerts&quot;&gt;Step 3: Make an AWS Security Group and Set Up AWS Billing Alerts&lt;/h2&gt;

&lt;p&gt;Add your AWS instance to the same security group that was automatically created for your RDS instance.  Personally I’d recommend opening up the ICMP port for ping but that’s just me.&lt;/p&gt;

&lt;p&gt;If you don’t normally setup AWS Billing Alerts on your cloud stuff then I highly recommend it. AWS entirely lacks the concept of a hosting budget for experimental stuff like this but AWS will alert you when your spending goes over limits so that’s at least something.&lt;/p&gt;

&lt;h2 id=&quot;step-4-install-docker-locally-on-your-development-box&quot;&gt;Step 4: Install Docker Locally on Your Development box&lt;/h2&gt;

&lt;p&gt;If you don’t have Docker installed locally then you need to do this now.  These days this is so simple that I don’t think you need any more help than &lt;a href=&quot;http://www.docker.com/&quot;&gt;http://www.docker.com/&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;step-5-sign-up-for-dockerhub&quot;&gt;Step 5: Sign up for DockerHub&lt;/h2&gt;

&lt;p&gt;A key decision in any Docker strategy is where are your Docker Images stored.  This is called a &lt;em&gt;container registry&lt;/em&gt; and think of it as a git repo but for a &lt;strong&gt;compiled&lt;/strong&gt; artifact instead of source code.  AWS has their own registry called the AWS ECR (elastic container registry) but I decided to use Docker Hub instead.  The reason was that I figured that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Docker Swarm would naturally work better with something from Docker.&lt;/li&gt;
  &lt;li&gt;There are also issues with the AWS ECR and authentication needing to re-authenticate every 12 hours or so that I just plain didn’t want to tackle.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;steps&quot;&gt;Steps:&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Goto https://hub.docker.com/&lt;/li&gt;
  &lt;li&gt;Create an account.&lt;/li&gt;
  &lt;li&gt;Sign up for a paid account if you need more than one container (and you likely will).  It is only $7 per account for a micro account so it isn’t much money.&lt;/li&gt;
  &lt;li&gt;Create repositories for each of your containers.  Please note that since you haven’t set them up yet you may need to wait until later in the process on this.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;review&quot;&gt;Review&lt;/h3&gt;

&lt;p&gt;While I found DockerHub to be a bit pricey for what you get, it worked &lt;strong&gt;perfectly&lt;/strong&gt;.  I don’t think that I hit a single snag related to the container registry and that’s just plain awesome.  Recommended!&lt;/p&gt;

&lt;h2 id=&quot;step-6-install-docker-on-your-aws-instance&quot;&gt;Step 6: Install Docker on Your AWS Instance&lt;/h2&gt;

&lt;p&gt;Although Amazon offers an Amazon branded version of Linux complete with Docker, Ubuntu has been very, very good to me over the years so when I created my instance, I used Ubuntu which means I needed to manually install docker per the Linux Install instructions:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.docker.com/engine/installation/linux/ubuntu/#install-from-a-package&quot;&gt;1&lt;/a&gt; and &lt;a href=&quot;https://docs.docker.com/engine/installation/linux/linux-postinstall/#kernel-compatibility&quot;&gt;2&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here’s what you need to do once you are SSH’d into your Linux box:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt-get install     apt-transport-https     ca-certificates     curl     software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository    &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \
    $(lsb_release -cs) \
    stable&quot;
sudo apt-get install docker-ce
sudo docker run hello-world
sudo groupadd docker
sudo usermod -aG docker $USER
docker run hello-world
exit
sudo systemctl enable docker
docker login
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Enter your login credentials for Docker Hub when you type docker login and they will be saved, securely, to  this file:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;~/.docker/config.json
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;After you get Docker installed on your AWS instance, there are two final steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Create a directory where your application will live.  I called mine should_i_gem but yours will obviously be different so I have ~/should_i_gem as my path.&lt;/li&gt;
  &lt;li&gt;You need to initialize swarm mode as it is turned off by default.  Do this with:&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;docker swarm init&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;At the end of your docker swarm init command, you will get a message like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Swarm initialized: current node (zv7y6c7236mtjl4jv31kw1elb) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join \
    --token SWMTKN-1-4vpwpu2qiwkj7c5br92g8x8kchynw7evto5xm7n0fj46fj7e51-1yzi6jj84m19e9wylz7wvg55q \
    172.31.9.129:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This message is actually pretty important so make a note of it.  Personally all my Rails apps have a top level directory called docs where I can drop anything I need to ever come back to.  That’s a best practive that I’d recommend.&lt;/p&gt;

&lt;h2 id=&quot;step-7-get-your-application-ready-for-docker-ie-dockerizing-it&quot;&gt;Step 7: Get Your Application Ready for Docker i.e. “Dockerizing It”&lt;/h2&gt;

&lt;p&gt;The next step is to get your Rails application ready for Docker.  There are different ways to do this.  If you’re starting with a brand new app then I’d recommend that you use the &lt;a href=&quot;https://github.com/nickjj/orats&quot;&gt;ORATS&lt;/a&gt; gem as a generator since that builds all the Docker stuff for you but I’ll take you through the steps manually.&lt;/p&gt;

&lt;h3 id=&quot;the-files-you-need&quot;&gt;The Files You Need&lt;/h3&gt;

&lt;p&gt;You need:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Dockerfile&lt;/li&gt;
  &lt;li&gt;.dockerignore&lt;/li&gt;
  &lt;li&gt;docker-compose.yml&lt;/li&gt;
  &lt;li&gt;docker-compose.production.yml&lt;/li&gt;
  &lt;li&gt;.env&lt;/li&gt;
  &lt;li&gt;.env.production&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All of these files live in the root directory of your Rails app.  You’ll also likely need to change puma.rb in config.  Each of these files is described below.&lt;/p&gt;

&lt;h4 id=&quot;dockerfile&quot;&gt;Dockerfile&lt;/h4&gt;

&lt;p&gt;The Dockerfile tells Docker itself how to get it to build and how to run it.  Here’s what mine looked like:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;FROM ruby:2.3.1-alpine

RUN apk update &amp;amp;&amp;amp; apk add build-base nodejs mariadb-dev tzdata

RUN mkdir /app
WORKDIR /app

COPY Gemfile Gemfile.lock ./
RUN bundle install --binstubs

COPY . .

# The ENV variables simply need to be set for Rails to correctly pre-compile
# your assets. They do not need to be populated by real values.
RUN bundle exec rake RAILS_ENV=production DATABASE_URL=mysql2://user:pass@127.0.0.1/dbname SECRET_TOKEN=dummytoken assets:precompile

CMD puma -C config/puma.rb
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The FROM directive tells Docker what “software engine” to use.  In this case I’m using a Ruby 2.3.1 language implementation on top of the Alpine linux distro which is a tiny Linux just for containers.&lt;/p&gt;

&lt;p&gt;The first RUN command tells it to update and then build the best, nodejs and mariadb-dev and tzdata.  These are equivalent to doing a apt-get install on any Ubuntu system.&lt;/p&gt;

&lt;p&gt;The second RUN command makes a directory /app and then it is set as WORKDIR.  Please note that all these commands generally execute from where your Dockerfile is located.&lt;/p&gt;

&lt;p&gt;The first COPY command copies in Gemfile and Gemfile.lock and then runs bundler so that your gems are build in the runtime container.&lt;/p&gt;

&lt;p&gt;The second COPY command copies your code into the container.&lt;/p&gt;

&lt;p&gt;THE RUN bundle exec command sets up environment variables and handles asset compilation.&lt;/p&gt;

&lt;p&gt;And then CMD puma starts the web process.&lt;/p&gt;

&lt;h4 id=&quot;dockerignore&quot;&gt;.dockerignore&lt;/h4&gt;

&lt;p&gt;The .dockerignore file tells Docker what files to ignore.  For example .git shouldn’t ever be pushed to DockerHub and neither should tmp.  Generally speaking you want your Docker images to be as slim as possible since the larger they are, they longer they take to download.&lt;/p&gt;

&lt;p&gt;Here’s my .dockerignore:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;.git/
.dockerignore
.byebug_history
tmp/*
log/*
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We do want the tmp and log directories to exist in the runtime for our application so we exclude them as tmp/* so the files within them are excluded but not the directory.&lt;/p&gt;

&lt;h4 id=&quot;docker-composeyml&quot;&gt;docker-compose.yml&lt;/h4&gt;

&lt;p&gt;The docker-compose.yml tells Docker how to run all the different containers in your application.  If you think about a normal web application, even on a single server, there are actually different pieces like:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;web server&lt;/li&gt;
  &lt;li&gt;database server&lt;/li&gt;
  &lt;li&gt;sidekiq&lt;/li&gt;
  &lt;li&gt;redis&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here’s my docker-compose.yml:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;version: '3.1'

services:
  redis:
    image: 'redis:3.2-alpine'
    ports:
      - '6379'
    volumes:
      - 'redis:/var/lib/redis/data'

  web:
    depends_on:
      - 'redis'
    build: .
    env_file:
      - '.env'
    ports:
      - '3500:3500'
    volumes:
      - '.:/app'
  
  sidekiq: 
    depends_on: 
      - 'web'
    build: .
    env_file:
      - '.env'

    volumes:
      - '.:/app'
    command: &quot;bundle exec sidekiq -C config/sidekiq.yml.erb&quot;
  
volumes:
  redis: {}
  assets: {}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;There are a few different directives here:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;version - this tells Docker what version you want to run and since we want to use Swarm, it needs to be 3 or later.  I want the latest and that’s 3.1.&lt;/li&gt;
  &lt;li&gt;services - this is the top level grouping of each of the containers you’re going to create.&lt;/li&gt;
  &lt;li&gt;volumes - this exposes data from service to service.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The key thing here is the services so let’s start by looking at our Redis service:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;redis:
  image: 'redis:3.2-alpine'
  ports:
    - '6379'
  volumes:
    - 'redis:/var/lib/redis/data'
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;What this is telling us is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;name the service redis&lt;/li&gt;
  &lt;li&gt;base this on an image i.e. something from a repository (often DockerHub but not always); you find available images at &lt;a href=&quot;http://www.dockerhub.com&quot;&gt;DockerHub&lt;/a&gt; and there are thousands upon thousands of images&lt;/li&gt;
  &lt;li&gt;expose the port 6379 to other services&lt;/li&gt;
  &lt;li&gt;store your data at the specified volume location&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Our web service now starts to show how this all fits together:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;web:
  depends_on:
    - 'redis'
  build: .
  env_file:
    - '.env'
  ports:
    - '3500:3500'
  volumes:
    - '.:/app'
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;What this is telling us is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;web depends on Redis actually running&lt;/li&gt;
  &lt;li&gt;build the code from the current directory i.e. .&lt;/li&gt;
  &lt;li&gt;use the environment file .env&lt;/li&gt;
  &lt;li&gt;run on the port 3500 both internally to the service and external in the local environment&lt;/li&gt;
  &lt;li&gt;expose a volume at app&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now the sidekiq service brings it all home:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sidekiq: 
  depends_on: 
    - 'web'
  build: .
  env_file:
    - '.env'

  volumes:
    - '.:/app'
  command: &quot;bundle exec sidekiq -C config/sidekiq.yml.erb&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;What this is telling us is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;sidekiq depends on web&lt;/li&gt;
  &lt;li&gt;it is again going to build from the current directory&lt;/li&gt;
  &lt;li&gt;it will use the same env file and volumes&lt;/li&gt;
  &lt;li&gt;it will use a special command to run sidekiq when the container starts up&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you look at this sidekiq container it actually answers a common question that people have about Docker which is CRON based processing.  Let’s say you had a rake task that you wanted to run every day under Docker.  Just create a container which has an entry command of either cron or a scheduling gem like ClockWork and make it part of your stack.  Please bear in mind that if you’re launching multiple copies of your container then you’d need to allow for locking or whatever mechanism you needed to prevent concurrency issues.&lt;/p&gt;

&lt;h4 id=&quot;docker-composeproductionyml&quot;&gt;docker-compose.production.yml&lt;/h4&gt;

&lt;p&gt;Here is the &lt;strong&gt;production&lt;/strong&gt; version of my docker-compose file that is the one that will be located on the server to define our services and our swarm:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;version: '3.1'

services:
  redis:
    image: 'redis:3.2-alpine'
    ports:
      - '6379'
    volumes:
      - 'redis:/var/lib/redis/data'
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure

  web:
    depends_on:
      - 'redis'
    image: fuzzygroup/shouldigem_web
    env_file:
      - '.env'
      - '.env.production'
    ports:
      - '80:80'
    deploy:
      replicas: 2
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure


  
  sidekiq: 
    depends_on: 
      - 'web'
    image: fuzzygroup/shouldigem_web
    env_file:
      - '.env'
      - '.env.production'      
    command: &quot;bundle exec sidekiq -C config/sidekiq.yml.erb&quot;
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
volumes:
  redis: {}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;env&quot;&gt;.env&lt;/h4&gt;

&lt;p&gt;A .env file is a set of environment variables that Docker will cause to come into being in the environment that you are setting up.  Here’s my .env file:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;COMPOSE_PROJECT_NAME=&quot;should-i-gem&quot;
BIND_ON=0.0.0.0:3500
RAILS_MAX_THREADS=1
WEB_CONCURRENCY=1
ACTIVE_JOB_URL=redis://redis:6379/0
REDIS_CACHE_URL=redis://redis:6379/0
ACTIVE_JOB_QUEUE_PREFIX=jobs
LOG_LEVEL=debug
RAILS_ENV=development
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;envproduction&quot;&gt;.env.production&lt;/h4&gt;

&lt;p&gt;Here’s my .env.production:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;RAILS_MAX_THREADS=5
WEB_CONCURRENCY=5
RAILS_ENV=production
RAILS_SERVE_STATIC_FILES=true
BIND_ON=0.0.0.0:80
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;step-8-build-your-app-under-docker&quot;&gt;Step 8: Build Your App Under Docker&lt;/h2&gt;

&lt;p&gt;Your Rails app is run inside a container or series of containers as defined by your compose file.  The key step to getting your containers to run is that they need to be “built”.  This is done with the docker-compose tool:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;docker-compose build web&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;step-9-create-your-images-tag-them-and-push-them-to-docker-hub&quot;&gt;Step 9: Create Your Images, Tag Them and Push them to Docker Hub&lt;/h2&gt;

&lt;p&gt;Once you have built your docker images, they need to be pushed to the DockerHub where they can be pulled onto your server when you are ready to run them.  This is done with a command like this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;docker tag shouldigem_web fuzzygroup/shouldigem_web:latest&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;step-10-copy-the-docker-composeproductionyml-to-the-server&quot;&gt;Step 10: Copy the docker-compose.production.yml to the Server&lt;/h2&gt;

&lt;p&gt;In order to run your containers in production there are three files that need to go up to the server:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;.env&lt;/li&gt;
  &lt;li&gt;.env.production&lt;/li&gt;
  &lt;li&gt;.docker-compose.production.yml&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Technically these files only need to be copied up &lt;strong&gt;once&lt;/strong&gt; but because configurations change, I’d recommend that you think of these as &lt;em&gt;deployment artifacts&lt;/em&gt; that need to be copied up every time.  And because these things are external to your actual image they can’t be a part of them.&lt;/p&gt;

&lt;h2 id=&quot;step-11-actually-deploying&quot;&gt;Step 11: Actually Deploying&lt;/h2&gt;

&lt;p&gt;Deployment of a Rails app under Docker, the way I’ve done it, is actually a two step process:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Copy the three files in Step 10 to the server or servers (if you have N servers then they need to go up to all N servers).&lt;/li&gt;
  &lt;li&gt;Restart the Docker Swarm engine.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;a-tiny-bash-deployer-to-get-your-files-up&quot;&gt;A Tiny Bash Deployer to Get Your Files Up&lt;/h3&gt;

&lt;p&gt;Steps 8, 9 and 10 can all be rolled together into a simple bash script as follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# The Docker Specific Stuff&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#&lt;/span&gt;
docker-compose build web
docker tag shouldigem_web fuzzygroup/shouldigem_web:latest
docker push fuzzygroup/shouldigem_web:latest

&lt;span class=&quot;c&quot;&gt;#&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Setting up the remote box&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#&lt;/span&gt;
scp -i ~/.ssh/fuzzygroup2.pem .env  ubuntu@shouldigem.com:~/shouldigem
scp -i ~/.ssh/fuzzygroup2.pem .env.production  ubuntu@shouldigem.com:~/shouldigem
scp -i ~/.ssh/fuzzygroup2.pem docker-compose.production.yml ubuntu@shouldigem.com:~/shouldigem
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;restarting-docker-swarm&quot;&gt;Restarting Docker Swarm&lt;/h3&gt;

&lt;p&gt;Here’s the command to restart Docker Swarm:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;docker stack deploy -c docker-compose.production.yml –with-registry-auth shouldigem&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This has to be done after:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Your images have been built and pushed to Docker Hub&lt;/li&gt;
  &lt;li&gt;The .env and compose files are copied to all remote servers&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;two-discrete-steps-sucks-monkey-chunks&quot;&gt;Two Discrete Steps Sucks Monkey Chunks&lt;/h3&gt;

&lt;p&gt;Yes I’m clearly aware that two separate steps for deployment (and that this entirely ignores migrations) actually sucks monkey chunks.  I’ll roll all this into an Ansible deployer in the not too distant future.  And I’ll address migrations at that time.&lt;/p&gt;

&lt;h1 id=&quot;gotchas&quot;&gt;Gotchas&lt;/h1&gt;

&lt;p&gt;In getting this deployed, I only hit one real gotcha – I wanted to use Nginx to serve the 10 or so static assets (images, JS and CSS) that make up this application.  Due to the layers of isolation and the fact that Docker Swarm prevents use of the VOLUMES_FROM directive, I was simply unable to make this work.  There are various workarounds but none of them let me achieve my zero downtime goal so I ended up just using Puma to serve them for now.  At some point I’m sure that I or someone else will figure this out.&lt;/p&gt;

&lt;h1 id=&quot;conclusions-and-observations&quot;&gt;Conclusions and Observations&lt;/h1&gt;

&lt;p&gt;If you’re going to go down the container route then I strongly recommend that if at all possible, you do it with someone who has already done it.  Docker Swarm and Docker itself are highly impressive technologies but the levels of abstraction and isolation that you have to internalize are very hard to wrap your head around.&lt;/p&gt;

&lt;p&gt;You should be aware that there’s a whole additional post that I need to write – &lt;em&gt;Working with a Rails App Under Docker&lt;/em&gt; which discusses how you work with a Rails app under Docker and will cover things like logs, migrations, getting into console and so on.  Look for that in the next few days.&lt;/p&gt;

&lt;h1 id=&quot;recommended-reading&quot;&gt;Recommended Reading&lt;/h1&gt;

&lt;p&gt;Here are some good things to read&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.diveintodocker.com&quot;&gt;Dive Into Docker&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jbhannah.net/articles/rails-development-with-docker/&quot;&gt;J Hannah&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://leanpub.com/the-devops-2-1-toolkit&quot;&gt;Devops 2.1 Toolkit&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://diveintodocker.com/blog/comparing-virtual-machines-vs-docker-containers&quot;&gt;Containers versus Virtual machines&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Wed, 03 May 2017 19:32:30 -0400</pubDate>
        <link>http://fuzzyblog.io//blog/rails/2017/05/03/deploying-a-rails-app-to-aws-with-docker-swarm.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/rails/2017/05/03/deploying-a-rails-app-to-aws-with-docker-swarm.html</guid>
        
        <category>rails</category>
        
        <category>docker</category>
        
        <category>aws</category>
        
        <category>swarm</category>
        
        
        <category>rails</category>
        
      </item>
    
      <item>
        <title>Working With a Rails App Under Docker</title>
        <description>&lt;h1 id=&quot;working-with-a-rails-app-under-docker&quot;&gt;Working with a Rails App Under Docker&lt;/h1&gt;

&lt;p&gt;If you view Docker as similar to an operating system, and, yes, I know that’s not technically correct, then it makes sense that there are a &lt;strong&gt;lot&lt;/strong&gt; of commands that you need to know, just as you need to know a lot of commands to use an operating system.  In this section I’m going to give examples of each of the docker commands that I found myself using.&lt;/p&gt;

&lt;h2 id=&quot;finding-your-process---docker-ps&quot;&gt;Finding Your Process - docker ps&lt;/h2&gt;

&lt;p&gt;The docker ps command lists your running processes under Docker:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;docker ps&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker ps
CONTAINER ID        IMAGE                                                                                               COMMAND                  CREATED             STATUS              PORTS               NAMES
c268d4b67dd6        fuzzygroup/shouldigem_web@sha256:cb55863d2a41d97ee2de5bc42354dae03c8ac30780d86557560e1a373567f116   &quot;bundle exec sidek...&quot;   10 minutes ago      Up 10 minutes                           shouldigem_sidekiq.1.klojjb9cnni0ceuwqunaxhuke
7f04bfa41535        fuzzygroup/shouldigem_web@sha256:cb55863d2a41d97ee2de5bc42354dae03c8ac30780d86557560e1a373567f116   &quot;/bin/sh -c 'puma ...&quot;   10 minutes ago      Up 10 minutes                           shouldigem_web.1.r2m01ncqud8ynz2r0ui8fyvg5
34e2624d5691        redis@sha256:9cd405cd1ec1410eaab064a1383d0d8854d1eef74a54e1e4a92fb4ec7bdc3ee7                       &quot;docker-entrypoint...&quot;   28 minutes ago      Up 28 minutes       6379/tcp            shouldigem_redis.1.wf9ggadw7c8pusgreaheojyz5
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;In this case I want to look at the 2nd one – shouldigem_web.  I’ll need to capture the container id to my clipboard so I can use it to view logs in the next command.&lt;/p&gt;

&lt;h2 id=&quot;viewing-logs----docker-logs&quot;&gt;Viewing Logs – docker logs&lt;/h2&gt;

&lt;p&gt;The docker logs command views the logs from your running processes under Docker:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;docker logs 7f04bfa41535&lt;/td&gt;
      &lt;td&gt;more&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;running-rails-console&quot;&gt;Running Rails Console&lt;/h2&gt;

&lt;p&gt;I don’t know about other folks but, even in production, I’m intensely dependent on the Rails console, particularly at the early stages where nothing ever works right.  What you can do with Docker is connect to your Rails container with an interactive terminal flag (-it).  Start by using docker ps to get the process id and then:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker exec -it 7f04bfa41535 sh
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;That launches an old school sh terminal (I didn’t want the overhead of bash on my containers so I just left it with sh).  If you run an ls -l then this will all look familiar:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/app # ls -l
total 104
-rw-r--r--    1 root     root           489 Apr 27 18:30 Dockerfile
-rw-r--r--    1 root     root          1522 Apr 27 14:03 Gemfile
-rw-r--r--    1 root     root          8737 Apr 27 14:11 Gemfile.lock
-rw-r--r--    1 root     root          3963 Apr 24 21:34 Guardfile
-rw-r--r--    1 root     root           534 Apr 26 19:16 README
-rw-r--r--    1 root     root           534 Apr 26 19:17 README.md
-rw-r--r--    1 root     root           227 Apr 24 21:31 Rakefile
drwxr-xr-x   10 root     root          4096 Apr 25 07:05 app
drwxr-xr-x    2 root     root          4096 Apr 24 21:35 bin
drwxr-xr-x    5 root     root          4096 Apr 26 15:06 config
-rw-r--r--    1 root     root           130 Apr 24 21:31 config.ru
drwxr-xr-x    3 root     root          4096 Apr 24 22:40 db
-rwxr-xr-x    1 root     root           687 Apr 27 19:01 deploy.sh
drwxr-xr-x    3 root     root          4096 Apr 27 14:44 docker
-rw-r--r--    1 root     root          1464 Apr 27 19:04 docker-compose.production.yml
-rw-r--r--    1 root     root          1013 Apr 27 15:46 docker-compose.yml
drwxr-xr-x    2 root     root          4096 Apr 27 13:17 docs
drwxr-xr-x    5 root     root          4096 Apr 24 21:34 lib
drwxr-xr-x    2 root     root          4096 Apr 24 21:34 log
drwxr-xr-x    4 root     root          4096 Apr 27 19:05 public
drwxr-xr-x    6 root     root          4096 Apr 24 22:37 spec
drwxr-xr-x    6 root     root          4096 Apr 27 19:05 tmp
-rw-r--r--    1 root     root          1283 Apr 27 18:36 ubuntu@ec2-52-14-213-243.us-east-2.compute.amazonaws.com
drwxr-xr-x    3 root     root          4096 Apr 24 21:31 vendor
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Yes Virginia – that’s a Rails app and you can just use bundle exec rails c:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/app # bundle exec rails c
Loading production environment (Rails 5.0.2)
irb(main):001:0&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;docker stack ps shouldigem&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ID            NAME                  IMAGE                             NODE             DESIRED STATE  CURRENT STATE               ERROR  PORTS
wd1jlbwgx7m0  shouldigem_sidekiq.1  fuzzygroup/shouldigem_web:latest  ip-172-31-9-129  Running        Running 3 minutes ago
xclwhnvhg9mm  shouldigem_web.1      fuzzygroup/shouldigem_web:latest  ip-172-31-9-129  Running        Running 3 minutes ago
ugwqfsaqnsc3  shouldigem_sidekiq.1  fuzzygroup/shouldigem_web:latest  ip-172-31-9-129  Shutdown       Shutdown 3 minutes ago
2lzgsunoay0y  shouldigem_web.1      fuzzygroup/shouldigem_web:latest  ip-172-31-9-129  Shutdown       Shutdown 3 minutes ago
r2m01ncqud8y   \_ shouldigem_web.1  fuzzygroup/shouldigem_web:latest  ip-172-31-9-129  Shutdown       Shutdown 9 minutes ago
klojjb9cnni0  shouldigem_sidekiq.1  fuzzygroup/shouldigem_web:latest  ip-172-31-9-129  Shutdown       Shutdown 9 minutes ago
seegap6xlfy1  shouldigem_web.1      fuzzygroup/shouldigem_web:latest  ip-172-31-9-129  Shutdown       Shutdown about an hour ago
akgkzn8ytfcc  shouldigem_sidekiq.1  fuzzygroup/shouldigem_web:latest  ip-172-31-9-129  Shutdown       Shutdown about an hour ago
wf9ggadw7c8p  shouldigem_redis.1    redis:3.2-alpine                  ip-172-31-9-129  Running        Running 2 hours ago
sp16ukp44u3e  shouldigem_sidekiq.1  fuzzygroup/shouldigem_web:latest  ip-172-31-9-129  Shutdown       Shutdown 2 hours ago
o9kbzy6ojbat  shouldigem_web.1      fuzzygroup/shouldigem_web:latest  ip-172-31-9-129  Shutdown       Shutdown 2 hours ago
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;docker stack services shouldigem&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ID            NAME                MODE        REPLICAS  IMAGE
f9dpr1o77x16  shouldigem_web      replicated  1/1       fuzzygroup/shouldigem_web:latest
idhahasrpax2  shouldigem_sidekiq  replicated  1/1       fuzzygroup/shouldigem_web:latest
zejrjetcdzgy  shouldigem_redis    replicated  1/1       redis:3.2-alpine
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;docker-compose build web&lt;/p&gt;

&lt;p&gt;docker tag shouldigem_web fuzzygroup/shouldigem_web&lt;/p&gt;

&lt;p&gt;docker push fuzzygroup/shouldigem_web&lt;/p&gt;
</description>
        <pubDate>Wed, 03 May 2017 19:28:49 -0400</pubDate>
        <link>http://fuzzyblog.io//blog/2017/05/03/working-with-a-rails-app-under-docker.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/2017/05/03/working-with-a-rails-app-under-docker.html</guid>
        
        
      </item>
    
      <item>
        <title>A Tale of Two (rails) Caches</title>
        <description>&lt;p&gt;2.3.1 :039 &amp;gt; seconds = Benchmark.realtime do
2.3.1 :040 &amp;gt;     results = PageGithubProject.fetch(“https://github.com/nickjj/orats”)
2.3.1 :041?&amp;gt;   end
1.3151520000537857
2.3.1 :042 &amp;gt; seconds = Benchmark.realtime do
2.3.1 :043 &amp;gt;     seconds = Benchmark.realtime do^C
2.3.1 :043 &amp;gt; reload!
Reloading…
true
2.3.1 :044 &amp;gt; seconds = Benchmark.realtime do
2.3.1 :045 &amp;gt;     results = PageGithubProject.fetch(“https://github.com/nickjj/orats”)
2.3.1 :046?&amp;gt;   end
1.1567529999883845&lt;/p&gt;

&lt;p&gt;importance of an abstract class&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;if html_page_body.nil?
  #
  # Cache variables
  #
  use_cache = true
  cache_duration = 1.hour
  cache = ActiveSupport::Cache::MemoryStore.new(expires_in: cache_duration)
  #cache = ActiveSupport::Cache::FileStore.new(expires_in: cache_duration)
  
  if self.fetch_mechanism == &quot;javascript&quot;
    #
    cache_key = TextCommon.sha_it(&quot;javascript_page_fetcher__#{@url}&quot;)        
    html_page_body = nil
    html_page_body = cache.read(cache_key) if use_cache
    if html_page_body
      status = :ok
      page = UrlCommon.create_mechanize_page_from_html(url, html_page_body)
      html_page_body = nil # this is a big ass (200k to 500k) string so get rid of it immediately
    elsif html_page_body.nil?
      status, page = JavaScriptPageFetcher.fetch(@url, true)
      cache.write(cache_key, page.body, expires_in: cache_duration) if use_cache
    end
  else
    cache_key = TextCommon.sha_it(&quot;mechanize_page_fetcher__#{@url}&quot;)        
    html_page_body = nil
    html_page_body = cache.read(cache_key) if use_cache
    if html_page_body
      status = :ok
      page = UrlCommon.create_mechanize_page_from_html(url, html_page_body)
      html_page_body = nil # this is a big ass (200k to 500k) string so get rid of it immediately
    elsif html_page_body.nil?
      status, page = UrlCommon.get_page(@url)
      cache.write(cache_key, page.body, expires_in: cache_duration) if use_cache
    end
  end
else
  #
  # No caching at all here; data comes in from an alternate path (memoize / reuse previous operation)
  #
  status = :ok
  page = UrlCommon.create_mechanize_page_from_html(url, html_page_body)
end

https://apidock.com/rails/ActiveSupport/Cache/Store/fetch

https://apidock.com/rails/v4.2.7/ActiveSupport/Cache/Store/read

http://stackoverflow.com/questions/5614389/anyone-know-of-a-caching-plugin-for-ruby-mechanize

https://github.com/vcr/vcr

http://stackoverflow.com/questions/11608127/writing-a-caching-version-of-mechanize


with caching:

Total parsers tested: 20
  Total urls tested: 137
Total time: 157.58553899999242

w/o caching
Total parsers tested: 20
  Total urls tested: 137
Total time: 179.80213199998252
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 02 May 2017 08:05:30 -0400</pubDate>
        <link>http://fuzzyblog.io//blog/2017/05/02/a-tale-of-two-rails-caches.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/2017/05/02/a-tale-of-two-rails-caches.html</guid>
        
        
      </item>
    
      <item>
        <title>Understanding the Docker Magic Eval Statement</title>
        <description>&lt;p&gt;eval “$(docker-machine env)”
that should be enough for your eval command btw
that auto-grabs the “default” machine
which you can verify with: docker-machine ls
you would use eval “$(docker-machine env foobar)” , if you had another machine with the name foobar
ah.
Nick Janetakis (nick.janetakis@gmail.com)
and it’s not magic at all hehe
it just sets up a bunch of ENV variables to configure your docker client to connect to the docker daemon
Just so you know once you get on a black list you often cannot get off since there’s no one in charge of them.  They’re often amateur efforts that get rolled up into other things
Nick Janetakis (nick.janetakis@gmail.com)
if someone watched the docker toolbox lecture you would know this!
you can actually run:  docker-machine env , as is
and it prints out a bunch of stuff – that’s what the eval command does for you
it takes that output and executes as “real” bash code&lt;/p&gt;
</description>
        <pubDate>Sat, 29 Apr 2017 08:12:39 -0400</pubDate>
        <link>http://fuzzyblog.io//blog/2017/04/29/understanding-the-docker-magic-eval-statement.html</link>
        <guid isPermaLink="true">http://fuzzyblog.io//blog/2017/04/29/understanding-the-docker-magic-eval-statement.html</guid>
        
        
      </item>
    
  </channel>
</rss>
