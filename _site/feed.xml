<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>FuzzyBlog</title>
    <description>Scott Johnson writing about the usual array of nerd stuff.  Ruby / Rails / Elixir.
</description>
    <link>https://fuzzygroup.github.io/blog/</link>
    <atom:link href="https://fuzzygroup.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 18 Oct 2016 15:41:21 -0400</pubDate>
    <lastBuildDate>Tue, 18 Oct 2016 15:41:21 -0400</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>AWS Quickie - Making Your Boxes Pingable</title>
        <description>&lt;p&gt;http://stackoverflow.com/questions/21981796/cannot-ping-aws-ec2-instance&lt;/p&gt;

&lt;p&gt;You have to edit the Security Group to which your EC2 instance belongs and allow access (or alternatively create a new one and add the instance to it).&lt;/p&gt;

&lt;p&gt;By default everything is denied. The exception you need to add to the Security Group depends on the service you need to make available to the internet.&lt;/p&gt;

&lt;p&gt;If it is a webserver you will need to allow access to port 80 for 0.0.0.0/0 (which means every IP address).&lt;/p&gt;

&lt;p&gt;To allow pinging the instance you need to enable ICMP traffic.&lt;/p&gt;
</description>
        <pubDate>Tue, 18 Oct 2016 08:18:34 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/2016/10/18/aws-quickie-making-your-boxes-pingable.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/2016/10/18/aws-quickie-making-your-boxes-pingable.html</guid>
        
        
      </item>
    
      <item>
        <title>Add a gitignore to your Jekyll Installation</title>
        <description>
</description>
        <pubDate>Tue, 18 Oct 2016 08:16:14 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/2016/10/18/add-a-gitignore-to-your-jekyll-installation.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/2016/10/18/add-a-gitignore-to-your-jekyll-installation.html</guid>
        
        
      </item>
    
      <item>
        <title>Test</title>
        <description>
</description>
        <pubDate>Tue, 18 Oct 2016 08:09:11 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/2016/10/18/test.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/2016/10/18/test.html</guid>
        
        
      </item>
    
      <item>
        <title>Life Beyond the Retina Display</title>
        <description>
</description>
        <pubDate>Mon, 17 Oct 2016 13:49:50 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/2016/10/17/life-beyond-the-retina-display.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/2016/10/17/life-beyond-the-retina-display.html</guid>
        
        
      </item>
    
      <item>
        <title>Adapting your Rails Tmux Development Flow to a Docker Development Flow</title>
        <description>&lt;p&gt;I first experimented with Docker back in summer of 2014 when I was bringing up a new data center and experimenting with development tools.  My buddy &lt;a href=&quot;http://dasari.me&quot;&gt;Dv&lt;/a&gt; remembers this all too well. This was back in the days where compose was still called fig and nothing actually worked all that well.  And since it didn’t work all that well, I quickly noped away.  But, even then, Docker had the feel of something important, something seminal.  Fast forward two years and Docker is all the rage and a bright luminary in the tech world.&lt;/p&gt;

&lt;p&gt;As a long time engineer, and yes you can translate that to “old guy”, I’m naturally conservative.  And, as such, I haven’t moved to Docker as part of my primary development flow.  To this point I’ve been using Docker as a way to treat applications as APIs and I’ve had a lot of success with that.  However, after a recent &lt;a href=&quot;https://fuzzygroup.github.io/blog/ruby/2016/10/15/brew-xz-and-nokogiri-and-tmux-an-unmitigated-disaster.html&quot;&gt;unmitigated disaster&lt;/a&gt;, involving the wonderful but troubled Nokogiri, I’m far more willing to explore Docker.&lt;/p&gt;

&lt;p&gt;In this blog post I’m going to use my open source &lt;a href=&quot;https://github.com/fuzzygroup/aws_monitor&quot;&gt;AWS Monitor&lt;/a&gt; codebase as the example.  This is a Rails application that is basically a Rake task which monitors a series of Ansible hosts to make sure that you can ssh into them.  It was written as part of my &lt;a href=&quot;https://fuzzygroup.github.io/blog/tag.html#ssh&quot;&gt;AWS / SSH hell period&lt;/a&gt; where I had a large application on AWS where the SSH servers would stay alive no longer than about 30 minutes.&lt;/p&gt;

&lt;h1 id=&quot;my-personal-development-flow&quot;&gt;My Personal Development Flow&lt;/h1&gt;

&lt;p&gt;I have a personal development flow that could essentially be described as “Lots and lots of terminal windows”.  I use a terminal window to represent each of the “stages” of Rails development:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;running server&lt;/li&gt;
  &lt;li&gt;generic command line&lt;/li&gt;
  &lt;li&gt;command line for deploy&lt;/li&gt;
  &lt;li&gt;rails console&lt;/li&gt;
  &lt;li&gt;test results&lt;/li&gt;
  &lt;li&gt;database sql window&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I used to manage all this with tabs in a terminal window but as I added more and more rails projects to my workflow that tended not to scale up.  Now my approach is to use the combination of &lt;a href=&quot;https://tmux.github.io&quot;&gt;Tmux&lt;/a&gt; and &lt;a href=&quot;https://github.com/tmuxinator/tmuxinator&quot;&gt;Tmuxinator&lt;/a&gt;, two open source projects.  Tmux acts as a virtual window manager allowing one terminal to front any number of character applications and Tmuxinator acts as an easy to use configuration manager for Tmux.  Here’s a picture of my typical approach to development:&lt;/p&gt;

&lt;p&gt;tmux_rails_dev_flow.png&lt;/p&gt;

&lt;p&gt;#&lt;/p&gt;
</description>
        <pubDate>Mon, 17 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/docker/2016/10/17/adapting-your-rails-tmux-development-flow-to-a-docker-development-flow.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/docker/2016/10/17/adapting-your-rails-tmux-development-flow-to-a-docker-development-flow.html</guid>
        
        <category>rails</category>
        
        <category>docker</category>
        
        <category>tmux</category>
        
        
        <category>docker</category>
        
      </item>
    
      <item>
        <title>Thinking About a Ruby Driven AWS Lambda Approach Using Code that Writes Code</title>
        <description>&lt;p&gt;So I have a computing problem to solve where the amount of data to process vastly exceeds even my desire to spin up EC2 instances.  I really do actually enjoy &lt;a href=&quot;https://fuzzygroup.github.io/blog/tag.html#ansible&quot;&gt;Ansible&lt;/a&gt; but at some point you have to cry to the heavens and shout out “There must be a better way!”.  This is literally an “oh crap” moment when I realized exactly the scale of the problem.&lt;/p&gt;

&lt;p&gt;Note: I’m not at liberty here to give specifics so I’m talking in generalities quite a bit in this post.  Apologies.&lt;/p&gt;

&lt;p&gt;AWS has a lot of tools that can be applied to big data process but two come to mind:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/emr/&quot;&gt;Elastic Map Reduce&lt;/a&gt; or EMR&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/lambda/&quot;&gt;Lambda&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;EMR is older and harder to use so I’m going to avoid it for now in favor of the new hotness – &lt;strong&gt;Lambda&lt;/strong&gt;.  Here’s the brag statement about Lambda:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Run code without thinking about servers.
Pay for only the compute time you consume.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;That’s a pretty compelling statement to make and it is actually close to a holy grail of distributed computing.&lt;br /&gt;
I have a big data problem that:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Involves about 15,000 unique domains that need to be checked against an index of data&lt;/li&gt;
  &lt;li&gt;Where if the domain is a match a secondary request needs to be made and several data points extracted from an api&lt;/li&gt;
  &lt;li&gt;The results of #2 need to be posted to an API that we control&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For valid separation of concerns issues the data fed into 1 is separate from the code in 1 (its driven by a separate git repo).  And all of our code is in Ruby which is not a supported Lambda language.  This raises some actual issues in terms of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How do we make this work&lt;/li&gt;
  &lt;li&gt;How do we get our existing ruby code to run in Lambda&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There is an interesting approach to packaging up our existing ruby code using Traveling Ruby and then run that &lt;a href=&quot;https://www.krautcomputing.com/blog/2016/02/29/how-to-run-ruby-scripts-on-aws-lambda-using-ansible/&quot;&gt;package on Lambda&lt;/a&gt;.  But before we goto that level of effort perhaps we need to examine the metrics on the codebase in question:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rake stats
+----------------------+--------+--------+---------+---------+-----+-------+
| Name                 |  Lines |    LOC | Classes | Methods | M/C | LOC/M |
+----------------------+--------+--------+---------+---------+-----+-------+
| Controllers          |      3 |      3 |       1 |       0 |   0 |     0 |
| Helpers              |      2 |      2 |       0 |       0 |   0 |     0 |
| Jobs                 |      2 |      2 |       1 |       0 |   0 |     0 |
| Models               |      3 |      3 |       1 |       0 |   0 |     0 |
| Mailers              |      4 |      4 |       1 |       0 |   0 |     0 |
| Channels             |      8 |      8 |       2 |       0 |   0 |     0 |
| Javascripts          |     29 |      4 |       0 |       1 |   0 |     2 |
| Libraries            |    480 |    366 |      12 |      38 |   3 |     7 |
| Tasks                |      7 |      6 |       0 |       0 |   0 |     0 |
| Controller tests     |      0 |      0 |       0 |       0 |   0 |     0 |
| Helper tests         |      0 |      0 |       0 |       0 |   0 |     0 |
| Model tests          |      0 |      0 |       0 |       0 |   0 |     0 |
| Mailer tests         |      0 |      0 |       0 |       0 |   0 |     0 |
| Integration tests    |      0 |      0 |       0 |       0 |   0 |     0 |
| Lib specs            |    270 |    231 |       0 |       1 |   0 |   229 |
+----------------------+--------+--------+---------+---------+-----+-------+
| Total                |    808 |    629 |      18 |      40 |   2 |    13 |
+----------------------+--------+--------+---------+---------+-----+-------+
  Code LOC: 398     Test LOC: 231     Code to Test Ratio: 1:0.6
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;So we’re actually only talking about 12 classes, 38 methods and 366 LOC.  So this isn’t large at all.  We know that one approach to running this is running it as packaged ruby.  Another approach would be &lt;em&gt;code that writes code&lt;/em&gt; but before we talk about this, let’s talk about the execution context.&lt;/p&gt;

&lt;p&gt;This application needs to run every time period from 2013 to present.  And depending on the results from our initial prototype, that will be either monthly or quarterly.  So if this is quarterly we need to run it 12 times - (4 in 2013, 4 in 2015, 4 in 2016) and if its monthly then we need to run it 36 times.  And we’ll need to run it monthly going forward.  And, each time, the input data is different.&lt;/p&gt;

&lt;h1 id=&quot;code-that-writes-code&quot;&gt;Code that Writes Code&lt;/h1&gt;

&lt;p&gt;There are lots of different approaches to code that writes code – generators, real AI and template based approaches.  For this I would use a template based approach as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Port the Ruby code to JavaScript using a single file approach as much as possible.&lt;/li&gt;
  &lt;li&gt;Locate the input data we need to send to the initial api near the top as essentially a global array of values.  For test purposes you only need to use 1 or 2; only enough to prove the concept.&lt;/li&gt;
  &lt;li&gt;Convert the code in #2 to a template just as Rails uses, say, an ERB template (you can actually use ERB in other contexts than views).&lt;/li&gt;
  &lt;li&gt;Treat the underlying ruby code as a systems automation tool which:&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;operates over an array of dates from the past to the present&lt;/li&gt;
  &lt;li&gt;keeps track of what has been submitted to AWS Lambda&lt;/li&gt;
  &lt;li&gt;Reads the template in #3 and fills in the data based on the internal api.&lt;/li&gt;
  &lt;li&gt;packages everything per the &lt;a href=&quot;http://docs.aws.amazon.com/lambda/latest/dg/nodejs-create-deployment-pkg.html&quot;&gt;Lambda spec&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;uses the &lt;a href=&quot;http://docs.aws.amazon.com/sdkforruby/api/Aws/Lambda/Client.html&quot;&gt;AWS Lambda Ruby APIs&lt;/a&gt; to submit the job&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With this approach while we’re not using Lambda to actually execute our Ruby code, we’re getting the same result, using Lambda’s native JavaScript / node support but still using our overall Ruby framework to run everything and manage the process.  And this will have the advantage of generating an auditable code base that we can dig into if we find any problems.&lt;/p&gt;
</description>
        <pubDate>Sun, 16 Oct 2016 13:34:50 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/aws/2016/10/16/thinking-about-a-ruby-driven-aws-lambda-approach-for-big-data-computing.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/aws/2016/10/16/thinking-about-a-ruby-driven-aws-lambda-approach-for-big-data-computing.html</guid>
        
        <category>aws</category>
        
        <category>ruby</category>
        
        <category>lambda</category>
        
        <category>software_engineering</category>
        
        
        <category>aws</category>
        
      </item>
    
      <item>
        <title>Understanding Systems By Observation - Dropbox</title>
        <description>&lt;p&gt;One of the best bits of computer science I ever learned, I learned in 1989 from my first business partner, Brian Giedt.  We were at a Society for Technical Communications (stc) conference on Technical Documentation and my partner was trying to impress a pretty girl.  And I watch him look at an animation product and pretty much instantly &lt;strong&gt;grok&lt;/strong&gt; how it was doing the animation.  Where I saw a pretty flow of images, he looked at it and understood how the animation was being done.  That was the very first time I saw someone really understand something about the &lt;em&gt;internals&lt;/em&gt; from its &lt;em&gt;externals&lt;/em&gt;.  And once I knew it was possible – I’ve striven to do it as often as I can.  Very often, if you set up the right set of circumstances, you’ll realize exactly how something has to be implemented internally.&lt;/p&gt;

&lt;p&gt;Let’s use Dropbox as an example.  We all know that Dropbox transfers the content you put in it to all other machines you have hooked up to it.  And that’s a simple 1 to many transfer.  But how does Dropbox work when you already have content in it and you re-arrange it?  Does it resend everything or does it figure out what it has to do and send a command stream to do it instead?&lt;/p&gt;

&lt;p&gt;A few minutes ago I:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;created a folder within a folder in Dropbox&lt;/li&gt;
  &lt;li&gt;moved about 15 gb of video files in initial folder to the new folder&lt;/li&gt;
  &lt;li&gt;checked on my iPad about a minute later&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And all the files I moved were in the new folder already.  Here’s what this tells me&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;There’s no way that Dropbox deleted and re-transmitted the files in that time; it is simply impossible&lt;/li&gt;
  &lt;li&gt;What Dropbox has to be doing is sending commands that amount to move THIS from HERE to THERE&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The best I’ve seen to do this is you set up conditions that you know can’t be argued with by physical constraints.  I knew that 15 gb of video data was a big arse chunk of data.  If I had used say a megabyte, well, I wouldn’t have really known if it was a full bandwidth re-arrange or a command stream.  By setting up such a large test, well, I knew something smarter had to be going on.&lt;/p&gt;
</description>
        <pubDate>Sun, 16 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/software_engineering/2016/10/16/understanding-systems-by-observation-dropbox.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/software_engineering/2016/10/16/understanding-systems-by-observation-dropbox.html</guid>
        
        <category>software_engineering</category>
        
        
        <category>software_engineering</category>
        
      </item>
    
      <item>
        <title>Thinking About a Ruby Driven AWS Lambda Approach for Big Data Computing</title>
        <description>&lt;p&gt;So I have a computing problem to solve where the amount of data to process vastly exceeds even my desire to spin up EC2 instances.  I really do actually enjoy &lt;a href=&quot;https://fuzzygroup.github.io/blog/tag.html#ansible&quot;&gt;Ansible&lt;/a&gt; but at some point you have to cry to the heavens and shout out “There must be a better way!”.  This is literally an “oh crap” moment when I realized exactly the scale of the problem.&lt;/p&gt;

&lt;p&gt;Note: I’m not at liberty here to give specifics so I’m talking in generalities quite a bit in this post.  Apologies.&lt;/p&gt;

&lt;p&gt;AWS has a lot of tools that can be applied to big data process but two come to mind:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/emr/&quot;&gt;Elastic Map Reduce&lt;/a&gt; or EMR&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://aws.amazon.com/lambda/&quot;&gt;Lambda&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;EMR is older and harder to use so I’m going to avoid it for now in favor of the new hotness – &lt;strong&gt;Lambda&lt;/strong&gt;.  Here’s the brag statement about Lambda:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Run code without thinking about servers.
Pay for only the compute time you consume.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;That’s a pretty compelling statement to make and it is actually close to a holy grail of distributed computing.&lt;br /&gt;
I have a big data problem that:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Involves about 15,000 unique domains that need to be checked against an index of data&lt;/li&gt;
  &lt;li&gt;Where if the domain is a match a secondary request needs to be made and several data points extracted from an api&lt;/li&gt;
  &lt;li&gt;The results of #2 need to be posted to an API that we control&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For valid separation of concerns issues the data fed into 1 is separate from the code in 1 (its driven by a separate git repo).  And all of our code is in Ruby which is not a supported Lambda language.  This raises some actual issues in terms of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How do we make this work&lt;/li&gt;
  &lt;li&gt;How do we get our existing ruby code to run in Lambda&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There is an interesting approach to packaging up our existing ruby code using Traveling Ruby and then run that &lt;a href=&quot;https://www.krautcomputing.com/blog/2016/02/29/how-to-run-ruby-scripts-on-aws-lambda-using-ansible/&quot;&gt;package on Lambda&lt;/a&gt;.  But before we goto that level of effort perhaps we need to examine the metrics on the codebase in question:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rake stats
+----------------------+--------+--------+---------+---------+-----+-------+
| Name                 |  Lines |    LOC | Classes | Methods | M/C | LOC/M |
+----------------------+--------+--------+---------+---------+-----+-------+
| Controllers          |      3 |      3 |       1 |       0 |   0 |     0 |
| Helpers              |      2 |      2 |       0 |       0 |   0 |     0 |
| Jobs                 |      2 |      2 |       1 |       0 |   0 |     0 |
| Models               |      3 |      3 |       1 |       0 |   0 |     0 |
| Mailers              |      4 |      4 |       1 |       0 |   0 |     0 |
| Channels             |      8 |      8 |       2 |       0 |   0 |     0 |
| Javascripts          |     29 |      4 |       0 |       1 |   0 |     2 |
| Libraries            |    480 |    366 |      12 |      38 |   3 |     7 |
| Tasks                |      7 |      6 |       0 |       0 |   0 |     0 |
| Controller tests     |      0 |      0 |       0 |       0 |   0 |     0 |
| Helper tests         |      0 |      0 |       0 |       0 |   0 |     0 |
| Model tests          |      0 |      0 |       0 |       0 |   0 |     0 |
| Mailer tests         |      0 |      0 |       0 |       0 |   0 |     0 |
| Integration tests    |      0 |      0 |       0 |       0 |   0 |     0 |
| Lib specs            |    270 |    231 |       0 |       1 |   0 |   229 |
+----------------------+--------+--------+---------+---------+-----+-------+
| Total                |    808 |    629 |      18 |      40 |   2 |    13 |
+----------------------+--------+--------+---------+---------+-----+-------+
  Code LOC: 398     Test LOC: 231     Code to Test Ratio: 1:0.6
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;So we’re actually only talking about 12 classes, 38 methods and 366 LOC.  So this isn’t large at all.  We know that one approach to running this is running it as packaged ruby.  Another approach would be &lt;em&gt;code that writes code&lt;/em&gt; but before we talk about this, let’s talk about the execution context.&lt;/p&gt;

&lt;p&gt;This application needs to run every time period from 2013 to present.  And depending on the results from our initial prototype, that will be either monthly or quarterly.  So if this is quarterly we need to run it 12 times - (4 in 2013, 4 in 2015, 4 in 2016) and if its monthly then we need to run it 36 times.  And we’ll need to run it monthly going forward.  And, each time, the input data is different.&lt;/p&gt;

&lt;h1 id=&quot;code-that-writes-code&quot;&gt;Code that Writes Code&lt;/h1&gt;

&lt;p&gt;There are lots of different approaches to code that writes code – generators, real AI and template based approaches.  For this I would use a template based approach as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Port the Ruby code to JavaScript using a single file approach as much as possible.&lt;/li&gt;
  &lt;li&gt;Locate the input data we need to send to the initial api near the top as essentially a global array of values.  For test purposes you only need to use 1 or 2; only enough to prove the concept.&lt;/li&gt;
  &lt;li&gt;Convert the code in #2 to a template just as Rails uses, say, an ERB template (you can actually use ERB in other contexts than views).&lt;/li&gt;
  &lt;li&gt;Treat the underlying ruby code as a systems automation tool which:&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;operates over an array of dates from the past to the present&lt;/li&gt;
  &lt;li&gt;keeps track of what has been submitted to AWS Lambda&lt;/li&gt;
  &lt;li&gt;Reads the template in #3 and fills in the data based on the internal api.&lt;/li&gt;
  &lt;li&gt;packages everything per the &lt;a href=&quot;http://docs.aws.amazon.com/lambda/latest/dg/nodejs-create-deployment-pkg.html&quot;&gt;Lambda spec&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;uses the &lt;a href=&quot;http://docs.aws.amazon.com/sdkforruby/api/Aws/Lambda/Client.html&quot;&gt;AWS Lambda Ruby APIs&lt;/a&gt; to submit the job&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With this approach while we’re not using Lambda to actually execute our Ruby code, we’re getting the same result, using Lambda’s native JavaScript / node support but still using our overall Ruby framework to run everything and manage the process.  And this will have the advantage of generating an auditable code base that we can dig into if we find any problems.&lt;/p&gt;
</description>
        <pubDate>Sun, 16 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/aws/2016/10/16/thinking-about-a-ruby-driven-aws-lambda-approach-for-big-data-computing.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/aws/2016/10/16/thinking-about-a-ruby-driven-aws-lambda-approach-for-big-data-computing.html</guid>
        
        <category>aws</category>
        
        <category>ruby</category>
        
        <category>lambda</category>
        
        <category>software_engineering</category>
        
        
        <category>aws</category>
        
      </item>
    
      <item>
        <title>AWS Tutorial 19 - Back to the Basics, Let's Talk AMIs and EC2 basics</title>
        <description>&lt;p&gt;I just used Hyde to examine my blog and I realized that I have written almost 20,000 words on AWS since 8/23/16 (note some of that is still unfinished and in draft form).  Using my standard writer metric of 250 words per page, that’s 78 printed pages.  Wow.  And, alas, I realize that there are still things I haven’t written about.  And some of them are the sort of basic things that you either just ignore or that you accept by rote - “I know, we’ll use Ubuntu, we love Ubuntu!”.  And, yes, that would be me.  So let’s take a deeper dive here at some of the basic options when you build an EC2 instance.&lt;/p&gt;

&lt;h1 id=&quot;what-is-an-ec2-instance&quot;&gt;What is an EC2 Instance?&lt;/h1&gt;

&lt;p&gt;An EC2 instance is just a server in Amazon’s cloud.  And, from what I can tell, pretty much everything AWS offers comes down to a server somehow.  When you build an EC2 instance you have to base it on an operating system which is called an AMI and there are a bunch of options that define what AMI you want to pick:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Quick Start - the most popular options&lt;/li&gt;
  &lt;li&gt;My AMIs - these are amis that you have saved from a machine you already built&lt;/li&gt;
  &lt;li&gt;AWS Marketplace - these are commercial offerings from vendors&lt;/li&gt;
  &lt;li&gt;Community AMIs - these are generally open source AMIs and the number is enormous – more than 50,000 when I checked&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here’s a picture of the initial EC2 instance selection web page:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/aws/aws_ami_ec2.png&quot; alt=&quot;aws_ami_ec2.png.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are a few basic options that you really want to keep in mind:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Linux Distro&lt;/strong&gt;.  This is important but can’t be written in a bullet point so it is discussed below.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;32 / 64 bit&lt;/strong&gt;.  There’s no real reason to not go 64 bit.  And if you have a reason then you should be writing this not reading it.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Virtualization Type&lt;/strong&gt;.  This should always be HVM as PVM is being phased out.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Root Device Type&lt;/strong&gt;.  This should pretty much always be set to EBS.  EBS allows you to turn off the volume without losing the data on the instance and thus allows you to resize your instance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;the-linux-distro-question&quot;&gt;The Linux Distro Question&lt;/h1&gt;

&lt;p&gt;Asking anyone in the Open Source world what is the best Linux flavor or “distro” (that’s short for distribution) is a bit like asking someone their favorite color – the answer is always different and always subjective.  And while there are differences, in the end, it is all Linux and if you can use one Linux then you can use a different Linux.  I know there are serious Linux folk that read this line and are gnashing their teeth and I apologize.&lt;/p&gt;

&lt;p&gt;Personally I’ve used at different times:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Red Hat&lt;/li&gt;
  &lt;li&gt;Gentoo (I even had a whole data center of more than 100 Gentoo boxes)&lt;/li&gt;
  &lt;li&gt;Ubuntu 12&lt;/li&gt;
  &lt;li&gt;Ubuntu 14&lt;/li&gt;
  &lt;li&gt;Mandriva&lt;/li&gt;
  &lt;li&gt;Suse&lt;/li&gt;
  &lt;li&gt;Debian&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And I’m pretty sure there were some others; that’s just want I can remember using.  The short answer is you want to pick a Linux distribution that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;matches what you want to do&lt;/li&gt;
  &lt;li&gt;is well supported&lt;/li&gt;
  &lt;li&gt;is something you understand&lt;/li&gt;
  &lt;li&gt;has a package manager that you can deal with&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;the-amazon-linux-distribution&quot;&gt;The Amazon Linux Distribution&lt;/h1&gt;

&lt;p&gt;Interestingly Amazon has their own Linux distribution.  I don’t have a ton of experience with it yet but I’m keenly interested in it and I really like their focus on performance.&lt;/p&gt;

&lt;p&gt;Pros:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Good support for Docker&lt;/li&gt;
  &lt;li&gt;Good support for at least somewhat modern development tools; Ruby, PHP and Python all installed right from the start&lt;/li&gt;
  &lt;li&gt;Good package support for the basics - mysql, postgres, etc&lt;/li&gt;
  &lt;li&gt;AWS command line tools installed standard&lt;/li&gt;
  &lt;li&gt;Good support for the AWS ECS&lt;/li&gt;
  &lt;li&gt;Cool text mode EC2 login logo that makes me smile whenever I see it&lt;/li&gt;
  &lt;li&gt;They seem to really care about performance.  The 2016.09 release notes specifically call out the &lt;a href=&quot;https://aws.amazon.com/amazon-linux-ami/2016.09-release-notes/&quot;&gt;7 seconds of boot time&lt;/a&gt; that they cut out.  Sounds silly but its a big deal when you have a lot of machines.  And given that they write the billing rules, they could easily use that 7 seconds in their favor.  The fact that they don’t gives me an incredible amount of confidence in AWS’s billing practices.  Go AWS!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cons:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It can’t run anywhere but Amazon.&lt;/li&gt;
  &lt;li&gt;It can’t run on Vagrant for local development&lt;/li&gt;
  &lt;li&gt;Yum / RPM as package managers; this is a personal choice but I vastly prefer apt-get&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;how-important-is-this-with-automated-provisioning&quot;&gt;How Important Is this With Automated Provisioning?&lt;/h1&gt;

&lt;p&gt;In the days where you configured Linux manually, picking the right distribution was actually quite important.  Thanks to automated provisioning tools like Ansible, I’m not so sure now.  I’ve already used Ansible to move from one version of Linux to another and its just not that hard.  If you write your Ansible playbook properly and abstract things like the username into variables, you can modify it pretty easily to go between distros.&lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;/h1&gt;

&lt;p&gt;In the end you likely want to pick:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A well supported Linux distro.  I’d recommend either Ubuntu, RedHat or the Amazon Linux AMI&lt;/li&gt;
  &lt;li&gt;64 Bit&lt;/li&gt;
  &lt;li&gt;HVM Virtualization&lt;/li&gt;
  &lt;li&gt;EBS Root Device&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Sun, 16 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/aws/2016/10/16/aws-tutorial-19-back-to-the-basics-let-s-talk-amis.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/aws/2016/10/16/aws-tutorial-19-back-to-the-basics-let-s-talk-amis.html</guid>
        
        <category>aws</category>
        
        <category>ami</category>
        
        <category>linux</category>
        
        <category>ec2</category>
        
        
        <category>aws</category>
        
      </item>
    
      <item>
        <title>AWS Tutorial 18 - When You've Lost Your Web Server, How to Find an AWS Resource</title>
        <description>&lt;p&gt;I find myself, at the time of this writing, in the middle of an embarrassing situtation for a web professional.  You see, the situation is this:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;I wrote a new feature&lt;/li&gt;
  &lt;li&gt;I deployed my new feature&lt;/li&gt;
  &lt;li&gt;I refreshed my page&lt;/li&gt;
  &lt;li&gt;My feature isn’t there&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Great Googly Moogly!  I’ve lost my web server!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Let me explain one of the things about cloud hosting that’s disconcerting.  When you first move to the cloud, your impulse is to organize your computing resources the way you used to.  So if you used to have say 3 clusters of powerful machines, that’s what you do.  Then you realize just how mind blowingly powerful a platform like AWS actually is and you start to think about &lt;strong&gt;Single Purpose Servers&lt;/strong&gt;.  A single purpose server is just what it sounds like – it does one thing.  And that’s fantastic because it makes trouble shooting so much easier.  When a server does only one thing, well, its easy to know if its broken.  And that’s great but do you know what the side effect of that is?  You don’t have a handful of servers anymore, you have a lot.  Me?  I’ve got over &lt;strong&gt;20&lt;/strong&gt; right now.  And somewhere in there is my web server.  But I can’t find it.  In this tutorial we’re going to quickly and easily figure this out.&lt;/p&gt;

&lt;h1 id=&quot;start-with-a-hypothesis&quot;&gt;Start with a Hypothesis&lt;/h1&gt;

&lt;p&gt;As normal we’re going to start with a theory - that is one of these three boxes:  fimariadb, ficrawler1, ficrawler2.  So our diagnostic dance, crude tho it may be, is:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;ssh into one of the boxes&lt;/li&gt;
  &lt;li&gt;sudo su -&lt;/li&gt;
  &lt;li&gt;apache2ctl stop&lt;/li&gt;
  &lt;li&gt;reload the page&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If the page comes up, well, we know it wasn’t that one box.  So you then lather, rinse, repeat for each of the other 2 boxes.  And, at the end, we’re going to find out that it was none of these.&lt;/p&gt;

&lt;p&gt;You might be saying “Hey wait a minute – why would a web front end be on a box that does crawling?”  Well I’m still feeling all this out and I initially went for the old model where every box could do everything.  And that was a bad decision but I still have to live it for at least a little while longer.&lt;/p&gt;

&lt;h1 id=&quot;formulate-a-new-hypothesis---lets-use-ping&quot;&gt;Formulate a New Hypothesis - Let’s Use Ping!&lt;/h1&gt;

&lt;p&gt;Since our first plan failed, we need a new plan.  The program ping is a basic IP networking tool which lets us send a packet to a destination and if it answers, well, that means its alive.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ping banks.finavd.com
PING web-1166333941.us-west-2.elb.amazonaws.com (52.41.182.115): 56 data bytes
64 bytes from 52.41.182.115: icmp_seq=0 ttl=47 time=67.589 ms
64 bytes from 52.41.182.115: icmp_seq=1 ttl=47 time=67.301 ms
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Ah ha!  We have an ip address of 52.41.182.115.  I know! I know!  I know!  I’ll just search for that ip address on EC2 dashboard.  And it will fail.  Now the smart kids in the back are already chuckling to themselves and they know the answer.&lt;/p&gt;

&lt;h1 id=&quot;hypothesis-3-elb-is-being-used&quot;&gt;Hypothesis 3: ELB Is Being Used&lt;/h1&gt;

&lt;p&gt;If you look at the url that responded, NOT the ip address, the answer is revealed:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;web-1166333941.us-west-2.elb.amazonaws.com
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;You see the text string “.elb.”?  That means that a piece of software called an Elastic Load Balancer is sitting in front of the http request and distributing the load out to one or more EC2 instances.  If you’ve ever used HAProxy, well, ELB is that only far, far better.  Let’s goto the AWS Console and select the Load Balancers option from the choices on the left:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/aws/aws_elb_01_overview.png&quot; alt=&quot;aws_elb_01_overview.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Here we’ll see an overview of all of our load balancers and their basic settings.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/blog/assets/aws/aws_elb_02_instances.png&quot; alt=&quot;aws_elb_02_instances.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Clicking the instances tab shows us where the HTTP request is being sent.  We can now goto the ec2 console and figure out what we need.  If you put the machine names into your &lt;a href=&quot;https://fuzzygroup.github.io/blog/aws/2016/09/20/aws-tutorial-08-using-ssh-s-config-file-with-your-aws-boxes.html&quot;&gt;SSH Config as I recommended&lt;/a&gt; then you might not even need to goto the console.  In my case I just needed to know the names worker2 and worker2a and I know that they’re in my ssh config file and I can just add those boxes to my Capistrano deploy process.  And the “bug” is fixed!&lt;/p&gt;

&lt;h1 id=&quot;conclusion-and-suggestion&quot;&gt;Conclusion and Suggestion&lt;/h1&gt;

&lt;p&gt;I know that it must seem like I’m a bit of a buffoon – how can you lost a web server after all?  Well, things do happen when you move fast.  You start with one plan and then it doesn’t work and before you know it you have something working but its not where you originally planned.  And you mean to fix it but you get busy and then the next &lt;a href=&quot;https://fuzzygroup.github.io/blog/aws/2016/10/01/aws-tutorial-10-diagnosing-ssh-failures-or-when-ping-works-but-ssh-fails.html&quot;&gt;crisis&lt;/a&gt; happens and you’re not even in the same head space any more.  And by the time you return to it over 10 days have passed.&lt;/p&gt;

&lt;p&gt;Here are some suggestions for setting up your AWS architecture to avoid this kind of silliness:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Name things well.&lt;/li&gt;
  &lt;li&gt;Name things logically.&lt;/li&gt;
  &lt;li&gt;Use the key value options when you set up your EC2 servers.  For example, having keys for both name and role might have helped.&lt;/li&gt;
  &lt;li&gt;Remember that there are often abstractions around everything.&lt;/li&gt;
  &lt;li&gt;Try and use single purpose servers from the start.  Yes the number of discrete servers increases complexity but their very single purpose nature makes debugging vastly easier.  And keep in mind that Amazon offers free servers.  Even a t2.micro free instance has 1 gig of ram and 8 gigs of storage.  I know that sounds funny but travel back in your head 5 years and that’s a beefy server and its &lt;strong&gt;FREE&lt;/strong&gt;.  If you’re just running something small, say Redis, Memcached, sendmail, etc that might be enough for a lot of applications.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 16 Oct 2016 00:00:00 -0400</pubDate>
        <link>https://fuzzygroup.github.io/blog/aws/2016/10/16/aws-tutorial-18-when-you-ve-lost-you-web-server-how-to-find-an-aws-resource.html</link>
        <guid isPermaLink="true">https://fuzzygroup.github.io/blog/aws/2016/10/16/aws-tutorial-18-when-you-ve-lost-you-web-server-how-to-find-an-aws-resource.html</guid>
        
        <category>aws</category>
        
        
        <category>aws</category>
        
      </item>
    
  </channel>
</rss>
